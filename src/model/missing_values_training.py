# src/model/missing_values_training.py

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

def prepare_data(train_sample, feature_metadata):
    """Prepare data by separating features into numeric and categorical, and defining imputation strategies."""
    numeric_features = [f for f, meta in feature_metadata['features'].items() if meta['classified_data_type'] == 'numerical']
    categorical_features = [f for f, meta in feature_metadata['features'].items() if meta['classified_data_type'] == 'categorical']

    numeric_transformer = SimpleImputer(strategy='mean')
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ])
    return preprocessor, numeric_features, categorical_features

def train_model(X_train, y_train, preprocessor):
    """Train the RandomForest model with the given preprocessor."""
    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(random_state=42))
    ])
    model.fit(X_train, y_train)
    return model

def extract_feature_importance(model, numeric_features, categorical_features):
    """Extract feature importance from the trained model."""
    feature_importances = model.named_steps['classifier'].feature_importances_
    features = numeric_features + list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))
    importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
    importance_df = importance_df.sort_values(by='Importance', ascending=False)
    return importance_df

def train_model_and_extract_feature_importance(X_train, y_train, numeric_features, categorical_features, feature_metadata):
    """Train the model and extract feature importance."""
    preprocessor, numeric_features, categorical_features = prepare_data(X_train, feature_metadata)
    model = train_model(X_train, y_train, preprocessor)
    importance_df = extract_feature_importance(model, numeric_features, categorical_features)
    return importance_df






# # src/model/missing_values_training.py

# import pandas as pd
# from sklearn.impute import SimpleImputer
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.model_selection import train_test_split

# def prepare_data(train_sample, feature_metadata):
#     """Prepare data by separating features into numeric and categorical, and defining imputation strategies."""
#     numeric_features = [f for f, meta in feature_metadata['features'].items() if meta['classified_data_type'] == 'numerical']
#     categorical_features = [f for f, meta in feature_metadata['features'].items() if meta['classified_data_type'] == 'categorical']

#     numeric_transformer = SimpleImputer(strategy='mean')
#     categorical_transformer = Pipeline(steps=[
#         ('imputer', SimpleImputer(strategy='most_frequent')),
#         ('onehot', OneHotEncoder(handle_unknown='ignore'))
#     ])

#     preprocessor = ColumnTransformer(
#         transformers=[
#             ('num', numeric_transformer, numeric_features),
#             ('cat', categorical_transformer, categorical_features)
#         ])
#     return preprocessor, numeric_features, categorical_features

# def train_model(X_train, y_train, preprocessor):
#     """Train the RandomForest model with the given preprocessor."""
#     model = Pipeline(steps=[
#         ('preprocessor', preprocessor),
#         ('classifier', RandomForestClassifier(random_state=42))
#     ])
#     model.fit(X_train, y_train)
#     return model

# def extract_feature_importance(model, numeric_features, categorical_features):
#     """Extract feature importance from the trained model."""
#     feature_importances = model.named_steps['classifier'].feature_importances_
#     features = numeric_features + list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))
#     importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
#     importance_df = importance_df.sort_values(by='Importance', ascending=False)
#     return importance_df

