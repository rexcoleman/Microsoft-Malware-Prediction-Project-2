# src/validation/validate_intermediate_data.py

import os
import sys
import pandas as pd
import logging
from tqdm.notebook import tqdm
from typing import Tuple, List, Dict

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def validate_columns(df: pd.DataFrame, original_columns: List[str], dropped_columns: List[str], added_columns: List[str]) -> bool:
    """
    Validate that the columns in the output DataFrame are as expected: original columns minus dropped columns plus added columns.

    Parameters:
    df (pd.DataFrame): The DataFrame to validate.
    original_columns (List[str]): The original column names.
    dropped_columns (List[str]): The columns that were dropped.
    added_columns (List[str]): The columns that were added.

    Returns:
    bool: True if the validation passes, False otherwise.
    """
    expected_columns = set(original_columns) - set(dropped_columns) | set(added_columns)
    actual_columns = set(df.columns)

    if expected_columns == actual_columns:
        logging.info("Column validation successful.")
        return True
    else:
        missing_columns = expected_columns - actual_columns
        unexpected_columns = actual_columns - expected_columns

        logging.error(f"Column validation failed.")
        logging.error(f"Missing columns: {missing_columns}")
        logging.error(f"Unexpected columns: {unexpected_columns}")
        logging.error(f"Expected columns: {expected_columns}")
        logging.error(f"Actual columns: {actual_columns}")
        
        return False


def validate_row_consistency(original_df: pd.DataFrame, processed_df: pd.DataFrame) -> bool:
    """
    Validate that the number of rows in the processed DataFrame matches the number of rows in the original DataFrame.

    Parameters:
    original_df (pd.DataFrame): The original input DataFrame.
    processed_df (pd.DataFrame): The processed output DataFrame.

    Returns:
    bool: True if the row counts match, False otherwise.
    """
    if original_df.shape[0] == processed_df.shape[0]:
        logging.info("Row consistency validation successful.")
        return True
    else:
        logging.error(f"Row consistency validation failed. Original rows: {original_df.shape[0]}, Processed rows: {processed_df.shape[0]}")
        return False


