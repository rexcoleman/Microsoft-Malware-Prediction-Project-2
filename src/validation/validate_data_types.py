# src/validation/validate_data_types.py


import os
import sys
import pandas as pd
import logging
from typing import Dict
from src.feature_engineering.data_types import get_type_mapping
from src.utils.metadata_operations import extract_classified_data_type

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def validate_data_types(df: pd.DataFrame, metadata: Dict[str, Dict[str, str]]) -> bool:
    """
    Validate that the DataFrame columns have the correct data types according to the metadata.

    Parameters:
    df (pd.DataFrame): The DataFrame to validate.
    metadata (Dict[str, Dict[str, str]]): The metadata dictionary containing the classified data type for each feature.

    Returns:
    bool: True if all data types are as expected, otherwise raises a ValueError.
    """
    type_mapping = get_type_mapping()

    try:
        for column in df.columns:
            classified_data_type = extract_classified_data_type(metadata, column)
            if classified_data_type in type_mapping:
                expected_dtype = type_mapping[classified_data_type]
                actual_dtype = str(df[column].dtype)
                
                # Allow for Int64 (nullable integer) types when expecting int64
                if expected_dtype == 'int64' and actual_dtype == 'Int64':
                    expected_dtype = 'Int64'
                
                if actual_dtype != expected_dtype:
                    logging.error(f"Column '{column}' has dtype '{actual_dtype}', expected '{expected_dtype}'.")
                    raise ValueError(f"Data type mismatch for column '{column}': expected {expected_dtype}, got {actual_dtype}.")
            else:
                logging.warning(f"Classified data type '{classified_data_type}' for column '{column}' not recognized.")
        logging.info("All data types validated successfully.")
        return True
    except Exception as e:
        logging.error(f"Error validating data types: {e}")
        raise





# def validate_data_types(df: pd.DataFrame, metadata: Dict[str, Dict[str, str]]) -> bool:
#     """
#     Validate that the DataFrame columns have the correct data types according to the metadata.

#     Parameters:
#     df (pd.DataFrame): The DataFrame to validate.
#     metadata (Dict[str, Dict[str, str]]): The metadata dictionary containing the classified data type for each feature.

#     Returns:
#     bool: True if all data types are as expected, otherwise raises a ValueError.
#     """
#     type_mapping = get_type_mapping()

#     try:
#         for column in df.columns:
#             classified_data_type = extract_classified_data_type(metadata, column)
#             if classified_data_type in type_mapping:
#                 expected_dtype = type_mapping[classified_data_type]
#                 actual_dtype = str(df[column].dtype)
#                 if actual_dtype != expected_dtype:
#                     logging.error(f"Column '{column}' has dtype '{actual_dtype}', expected '{expected_dtype}'.")
#                     raise ValueError(f"Data type mismatch for column '{column}': expected {expected_dtype}, got {actual_dtype}.")
#             else:
#                 logging.warning(f"Classified data type '{classified_data_type}' for column '{column}' not recognized.")
#         logging.info("All data types validated successfully.")
#         return True
#     except Exception as e:
#         logging.error(f"Error validating data types: {e}")
#         raise