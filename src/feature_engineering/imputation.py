# src/feature_engineering/imputation.py

import yaml
import pandas as pd
from tqdm.notebook import tqdm
from src.config_loader import load_paths
from src.feature_engineering.utils import classify_data_type, load_feature_metadata

def parse_missing_percentage(missing_value_str):
    return float(''.join(filter(lambda x: x.isdigit() or x == '.', missing_value_str)))

def define_imputation_strategies(feature_metadata):
    imputation_strategies = {
        'numerical_features': {},
        'categorical_features': {},
        'binary_features': {}
    }

    for feature, metadata in feature_metadata['features'].items():
        data_type = classify_data_type(metadata)
        missing_percentage = parse_missing_percentage(metadata['missing_values'])

        if data_type == 'numerical':
            if missing_percentage < 5.0:
                imputation_strategies['numerical_features'][feature] = 'mean'
            elif 5.0 <= missing_percentage < 20.0:
                imputation_strategies['numerical_features'][feature] = 'median'
            else:
                imputation_strategies['numerical_features'][feature] = 'mode'
        elif data_type == 'categorical':
            if missing_percentage < 5.0:
                imputation_strategies['categorical_features'][feature] = 'mode'
            else:
                imputation_strategies['categorical_features'][feature] = 'Unknown'
        elif data_type == 'binary':
            imputation_strategies['binary_features'][feature] = 'mode'

    return imputation_strategies

def save_imputation_strategies(imputation_strategies):
    paths = load_paths()
    with open(paths['config']['imputation_strategies'], 'w') as file:
        file.write("# config/imputation_strategies.yaml\n\n")
        yaml.dump(imputation_strategies, file)

def drop_features(data, metadata):
    """
    Identify and drop features flagged for dropping.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame from which to drop features.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - pd.DataFrame: DataFrame with features dropped.
    - list: List of dropped features.
    """
    features_to_drop = [feature for feature, details in metadata['features'].items() 
                        if details.get('imputation', {}).get('imputation_strategy') == 'Drop']
    data.drop(columns=features_to_drop, inplace=True)
    return data, features_to_drop

def extract_imputation_data(metadata, features_to_drop):
    """
    Extract imputation strategy information into a list of dictionaries.
    
    Parameters:
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with imputation data.
    """
    imputation_data = []
    for feature, details in metadata['features'].items():
        if feature not in features_to_drop:
            imputation_strategy = details.get('imputation', {}).get('imputation_strategy', 'None')
            missing_percentage = details.get('missing_values', {}).get('percentage', None)
            classified_data_type = details.get('classified_data_type', 'Unknown')
            if missing_percentage is not None:
                feature_info = {
                    'Feature': feature,
                    'Classification': classified_data_type,
                    'Imputation Strategy': imputation_strategy,
                    'Missing Percentage (%)': missing_percentage
                }
                imputation_data.append(feature_info)
    return pd.DataFrame(imputation_data)

def label_missing_values(data, metadata, features_to_drop):
    """
    Label missing values for reference in future analysis.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame to label missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with missing values labeled.
    - list: List of essential missing value indicators.
    """
    essential_missing_indicators = []
    for feature, details in tqdm(metadata['features'].items(), desc="Labeling missing values"):
        if feature not in features_to_drop:
            missing_percentage = details.get('missing_values', {}).get('percentage', None)
            if missing_percentage and missing_percentage > 5:
                data[f'{feature}_is_missing'] = data[feature].isnull().astype(int)
                essential_missing_indicators.append(f'{feature}_is_missing')
    return data, essential_missing_indicators

def impute_missing_values(data, metadata, features_to_drop):
    """
    Impute missing values according to the imputation strategy.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame to impute missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with missing values imputed.
    """
    for feature, details in tqdm(metadata['features'].items(), desc="Imputing missing values"):
        if feature not in features_to_drop:
            imputation_strategy = details.get('imputation', {}).get('imputation_strategy', 'None')
            if imputation_strategy == 'Mode':
                mode_value = data[feature].mode()[0]
                data[feature].fillna(mode_value, inplace=True)
            elif imputation_strategy == 'Median':
                median_value = data[feature].median()
                data[feature].fillna(median_value, inplace=True)
            elif imputation_strategy == 'Mean':
                mean_value = data[feature].mean()
                data[feature].fillna(mean_value, inplace=True)
            # Add other imputation strategies as needed
    return data

def convert_data_types(data, metadata):
    """
    Convert columns to their correct types based on metadata after imputation.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with imputed values.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - pd.DataFrame: DataFrame with converted data types.
    """
    for feature, details in tqdm(metadata['features'].items(), desc="Converting data types"):
        if feature in data.columns:
            technical_data_type = details.get('technical_data_type', None)
            if technical_data_type:
                if technical_data_type == 'int':
                    data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('Int64')
                elif technical_data_type == 'float':
                    data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('float64')
                elif technical_data_type == 'object':
                    data[feature] = data[feature].astype('object')
                elif technical_data_type == 'datetime':
                    data[feature] = pd.to_datetime(data[feature], errors='coerce')
    return data

def save_feature_data_types(data, output_path):
    """
    Save the feature names and updated data types to a JSON file.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with processed data.
    - output_path (str): Path to save the feature data types JSON file.
    """
    feature_data_types = [
        {'Feature': feature, 'Technical Data Type': str(data[feature].dtype)}
        for feature in data.columns
    ]
    save_json_file(feature_data_types, output_path)


















# # src/feature_engineering/imputation.py

# import yaml
# from src.config_loader import load_paths
# from src.feature_engineering.utils import load_feature_metadata, save_feature_metadata, classify_data_type

# def parse_missing_percentage(missing_value_str):
#     # Remove any non-numeric characters and convert to float
#     return float(''.join(filter(lambda x: x.isdigit() or x == '.', missing_value_str)))

# def define_imputation_strategies(feature_metadata):
#     imputation_strategies = {
#         'numerical_features': {},
#         'categorical_features': {},
#         'binary_features': {}
#     }

#     for feature, metadata in feature_metadata['features'].items():
#         data_type = classify_data_type(metadata)
#         missing_percentage = parse_missing_percentage(metadata['missing_values'])

#         if data_type == 'numerical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['numerical_features'][feature] = 'mean'
#             elif 5.0 <= missing_percentage < 20.0:
#                 imputation_strategies['numerical_features'][feature] = 'median'
#             else:
#                 imputation_strategies['numerical_features'][feature] = 'mode'

#         elif data_type == 'categorical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['categorical_features'][feature] = 'mode'
#             else:
#                 imputation_strategies['categorical_features'][feature] = 'Unknown'

#         elif data_type == 'binary':
#             imputation_strategies['binary_features'][feature] = 'mode'

#     return imputation_strategies

# def save_imputation_strategies(imputation_strategies):
#     paths = load_paths()
#     with open(paths['config']['imputation_strategies'], 'w') as file:
#         file.write("# config/imputation_strategies.yaml\n\n")
#         yaml.dump(imputation_strategies, file)
