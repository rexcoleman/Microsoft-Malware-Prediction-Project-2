# src/feature_engineering/imputation.py

import os
import yaml
import logging
import pandas as pd
from tqdm.notebook import tqdm
from IPython.display import display, HTML
from src.config_loader import load_paths
from src.utils.file_operations import save_dataframe
from src.feature_engineering.utils import classify_data_type, load_feature_metadata

def parse_missing_percentage(missing_value_str):
    return float(''.join(filter(lambda x: x.isdigit() or x == '.', missing_value_str)))

def define_imputation_strategies(feature_metadata):
    imputation_strategies = {
        'numerical_features': {},
        'categorical_features': {},
        'binary_features': {}
    }

    for feature, metadata in feature_metadata['features'].items():
        data_type = classify_data_type(metadata)
        missing_percentage = parse_missing_percentage(metadata['missing_values'])

        if data_type == 'numerical':
            if missing_percentage < 5.0:
                imputation_strategies['numerical_features'][feature] = 'mean'
            elif 5.0 <= missing_percentage < 20.0:
                imputation_strategies['numerical_features'][feature] = 'median'
            else:
                imputation_strategies['numerical_features'][feature] = 'mode'
        elif data_type == 'categorical':
            if missing_percentage < 5.0:
                imputation_strategies['categorical_features'][feature] = 'mode'
            else:
                imputation_strategies['categorical_features'][feature] = 'Unknown'
        elif data_type == 'binary':
            imputation_strategies['binary_features'][feature] = 'mode'

    return imputation_strategies

def save_imputation_strategies(imputation_strategies):
    paths = load_paths()
    with open(paths['config']['imputation_strategies'], 'w') as file:
        file.write("# config/imputation_strategies.yaml\n\n")
        yaml.dump(imputation_strategies, file)

def drop_features(data, metadata):
    """
    Identify and drop features flagged for dropping.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame from which to drop features.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - pd.DataFrame: DataFrame with features dropped.
    - list: List of dropped features.
    """
    features_to_drop = [feature for feature, details in metadata['features'].items() 
                        if details.get('imputation', {}).get('imputation_strategy') == 'Drop']
    data.drop(columns=features_to_drop, inplace=True)
    return data, features_to_drop

def extract_imputation_data(metadata, features_to_drop):
    """
    Extract imputation strategy information into a list of dictionaries.
    
    Parameters:
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with imputation data.
    """
    imputation_data = []
    for feature, details in metadata['features'].items():
        if feature not in features_to_drop:
            imputation_strategy = details.get('imputation', {}).get('imputation_strategy', 'None')
            missing_percentage = details.get('missing_values', {}).get('percentage', None)
            classified_data_type = details.get('classified_data_type', 'Unknown')
            if missing_percentage is not None:
                feature_info = {
                    'Feature': feature,
                    'Classification': classified_data_type,
                    'Imputation Strategy': imputation_strategy,
                    'Missing Percentage (%)': missing_percentage
                }
                imputation_data.append(feature_info)
    return pd.DataFrame(imputation_data)

def label_missing_values(data, metadata, features_to_drop):
    """
    Label missing values for reference in future analysis.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame to label missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with missing values labeled.
    - list: List of essential missing value indicators.
    """
    essential_missing_indicators = []
    for feature, details in tqdm(metadata['features'].items(), desc="Labeling missing values"):
        if feature not in features_to_drop:
            missing_percentage = details.get('missing_values', {}).get('percentage', None)
            if missing_percentage and missing_percentage > 5:
                data[f'{feature}_is_missing'] = data[feature].isnull().astype(int)
                essential_missing_indicators.append(f'{feature}_is_missing')
    return data, essential_missing_indicators

def impute_missing_values(data, metadata, features_to_drop):
    """
    Impute missing values according to the imputation strategy.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame to impute missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (list): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with missing values imputed.
    """
    for feature, details in tqdm(metadata['features'].items(), desc="Imputing missing values"):
        if feature not in features_to_drop:
            imputation_strategy = details.get('imputation', {}).get('imputation_strategy', 'None')
            if imputation_strategy == 'Mode':
                mode_value = data[feature].mode()[0]
                data[feature].fillna(mode_value, inplace=True)
            elif imputation_strategy == 'Median':
                median_value = data[feature].median()
                data[feature].fillna(median_value, inplace=True)
            elif imputation_strategy == 'Mean':
                mean_value = data[feature].mean()
                data[feature].fillna(mean_value, inplace=True)
            # Add other imputation strategies as needed
    return data

def convert_data_types(data, metadata):
    """
    Convert columns to their correct types based on metadata after imputation.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with imputed values.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - pd.DataFrame: DataFrame with converted data types.
    """
    for feature, details in tqdm(metadata['features'].items(), desc="Converting data types"):
        if feature in data.columns:
            technical_data_type = details.get('technical_data_type', None)
            if technical_data_type:
                if technical_data_type == 'int':
                    data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('Int64')
                elif technical_data_type == 'float':
                    data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('float64')
                elif technical_data_type == 'object':
                    data[feature] = data[feature].astype('object')
                elif technical_data_type == 'datetime':
                    data[feature] = pd.to_datetime(data[feature], errors='coerce')
    return data

def save_feature_data_types(data, output_path):
    """
    Save the feature names and updated data types to a JSON file.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with processed data.
    - output_path (str): Path to save the feature data types JSON file.
    """
    feature_data_types = [
        {'Feature': feature, 'Technical Data Type': str(data[feature].dtype)}
        for feature in data.columns
    ]
    save_json_file(feature_data_types, output_path)


# src/feature_engineering/imputation.py

import os
import pandas as pd
import logging
from IPython.display import display, HTML
from src.utils.file_operations import save_dataframe

def create_imputation_strategy_table(metadata, high_missing_values_df, moderate_missing_values_df):
    """
    Create the imputation strategy table based on feature data.

    Parameters:
    metadata (dict): Metadata dictionary.
    high_missing_values_df (pd.DataFrame): DataFrame of high missing values features.
    moderate_missing_values_df (pd.DataFrame): DataFrame of moderate missing values features.

    Returns:
    pd.DataFrame: DataFrame containing imputation strategy data.
    """
    imputation_data = []
    for feature, details in metadata['features'].items():
        missing_percentage = details.get('missing_values', {}).get('percentage', None)
        classification = details.get('classified_data_type', 'Unknown')
        imputation_strategy = 'Keep'
        comments = ''
        
        if feature in high_missing_values_df['Feature'].values:
            imputation_strategy = 'Drop'
            comments = 'High missing values.'
        elif feature in moderate_missing_values_df['Feature'].values:
            if classification == 'categorical':
                imputation_strategy = 'Mode'
            elif classification == 'numerical':
                imputation_strategy = 'Median'
            elif classification == 'binary':
                imputation_strategy = 'Mode'
            comments = 'Moderate missing values.'
        elif missing_percentage is not None and missing_percentage < 10:
            if classification == 'categorical':
                imputation_strategy = 'Mode'
            elif classification == 'numerical':
                imputation_strategy = 'Median'
            elif classification == 'binary':
                imputation_strategy = 'Mode'
        
        imputation_info = {
            'Feature': feature,
            'Classification': classification,
            'Imputation Strategy': imputation_strategy,
            'Comments': comments
        }
        imputation_data.append(imputation_info)
    
    return pd.DataFrame(imputation_data)

def save_dataframes(high_missing_values_df, moderate_missing_values_df, low_missing_values_df,
                    high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df,
                    high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df, paths):
    """
    Save various DataFrames to CSV files.

    Parameters:
    high_missing_values_df, moderate_missing_values_df, low_missing_values_df (pd.DataFrame): DataFrames of missing values features.
    high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df (pd.DataFrame): DataFrames of correlation with target.
    high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df (pd.DataFrame): DataFrames of missing values correlation with target.
    paths (dict): Dictionary containing file paths.
    """
    output_dir = paths['reports']['analysis_results']
    high_output_path = os.path.join(output_dir, 'high_missing_values_handling_strategy.csv')
    moderate_output_path = os.path.join(output_dir, 'moderate_missing_values_handling_strategy.csv')
    low_output_path = os.path.join(output_dir, 'low_missing_values_handling_strategy.csv')
    high_corr_with_target_output_path = os.path.join(output_dir, 'high_corr_with_target.csv')
    moderate_corr_with_target_output_path = os.path.join(output_dir, 'moderate_corr_with_target.csv')
    low_corr_with_target_output_path = os.path.join(output_dir, 'low_corr_with_target.csv')
    high_missing_corr_with_target_output_path = os.path.join(output_dir, 'high_missing_corr_with_target.csv')
    moderate_missing_corr_with_target_output_path = os.path.join(output_dir, 'moderate_missing_corr_with_target.csv')
    low_missing_corr_with_target_output_path = os.path.join(output_dir, 'low_missing_corr_with_target.csv')

    save_dataframe(high_missing_values_df, high_output_path)
    save_dataframe(moderate_missing_values_df, moderate_output_path)
    save_dataframe(low_missing_values_df, low_output_path)
    save_dataframe(high_corr_with_target_df, high_corr_with_target_output_path)
    save_dataframe(moderate_corr_with_target_df, moderate_corr_with_target_output_path)
    save_dataframe(low_corr_with_target_df, low_corr_with_target_output_path)
    save_dataframe(high_missing_corr_with_target_df, high_missing_corr_with_target_output_path)
    save_dataframe(moderate_missing_corr_with_target_df, moderate_missing_corr_with_target_output_path)
    save_dataframe(low_missing_corr_with_target_df, low_missing_corr_with_target_output_path)

    logging.info(f"High missing values handling strategy table saved to {high_output_path}")
    logging.info(f"Moderate missing values handling strategy table saved to {moderate_output_path}")
    logging.info(f"Low missing values handling strategy table saved to {low_output_path}")
    logging.info(f"High Correlation with Target table saved to {high_corr_with_target_output_path}")
    logging.info(f"Moderate Correlation with Target table saved to {moderate_corr_with_target_output_path}")
    logging.info(f"Low Correlation with Target table saved to {low_corr_with_target_output_path}")
    logging.info(f"High Missing Values Correlation with Target table saved to {high_missing_corr_with_target_output_path}")
    logging.info(f"Moderate Missing Values Correlation with Target table saved to {moderate_missing_corr_with_target_output_path}")
    logging.info(f"Low Missing Values Correlation with Target table saved to {low_missing_corr_with_target_output_path}")

def extract_feature_data(metadata):
    """
    Extract relevant feature data for analysis.

    Parameters:
    metadata (dict): Metadata dictionary.

    Returns:
    pd.DataFrame: DataFrame containing extracted feature data.
    """
    data = []
    for feature, details in metadata['features'].items():
        missing_percentage = details.get('missing_values', {}).get('percentage', None)
        if missing_percentage is not None and missing_percentage > 0:
            feature_info = {
                'Feature': feature,
                'Missing Percentage (%)': missing_percentage,
                'Correlation with Target': details.get('correlation_with_target', None),
                'Missing Values Correlation with Target': details.get('missing_values', {}).get('missing_values_correlation_with_target', None)
            }
            data.append(feature_info)
    
    df = pd.DataFrame(data)
    df['Correlation with Target'] = pd.to_numeric(df['Correlation with Target'], errors='coerce')
    df['Missing Values Correlation with Target'] = pd.to_numeric(df['Missing Values Correlation with Target'], errors='coerce')
    return df.sort_values(by='Missing Percentage (%)', ascending=False)

def display_dataframes(high_missing_values_df, moderate_missing_values_df, low_missing_values_df,
                       high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df,
                       high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df):
    """
    Display DataFrames in a visually appealing format.

    Parameters:
    high_missing_values_df, moderate_missing_values_df, low_missing_values_df (pd.DataFrame): DataFrames of missing values features.
    high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df (pd.DataFrame): DataFrames of correlation with target.
    high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df (pd.DataFrame): DataFrames of missing values correlation with target.
    """
    print("Features with High % of Missing Values (>=50%)\n")
    display(HTML(high_missing_values_df.to_html(index=False)))
    print(f"Size of High Missing Values table: {high_missing_values_df.shape}\n")

    print("\nFeatures with Moderate % of Missing Values (>=10% and < 50%)\n")
    display(HTML(moderate_missing_values_df.to_html(index=False)))
    print(f"Size of Moderate Missing Values table: {moderate_missing_values_df.shape}\n")

    print("\nFeatures with Low % of Missing Values (<10%)\n")
    display(HTML(low_missing_values_df.to_html(index=False)))
    print(f"Size of Low Missing Values table: {low_missing_values_df.shape}\n")

    print("\nHigh Correlation with Target (|correlation| > 0.7)\n")
    display(HTML(high_corr_with_target_df.to_html(index=False)))
    print(f"Size of High Correlation with Target table: {high_corr_with_target_df.shape}\n")

    print("\nModerate Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
    display(HTML(moderate_corr_with_target_df.to_html(index=False)))
    print(f"Size of Moderate Correlation with Target table: {moderate_corr_with_target_df.shape}\n")

    print("\nLow Correlation with Target (|correlation| ≤ 0.3)\n")
    display(HTML(low_corr_with_target_df.to_html(index=False)))
    print(f"Size of Low Correlation with Target table: {low_corr_with_target_df.shape}\n")

    print("\nHigh Missing Values Correlation with Target (|correlation| > 0.7)\n")
    display(HTML(high_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of High Missing Values Correlation with Target table: {high_missing_corr_with_target_df.shape}\n")

    print("\nModerate Missing Values Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
    display(HTML(moderate_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of Moderate Missing Values Correlation with Target table: {moderate_missing_corr_with_target_df.shape}\n")

    print("\nLow Missing Values Correlation with Target (|correlation| ≤ 0.3)\n")
    display(HTML(low_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of Low Missing Values Correlation with Target table: {low_missing_corr_with_target_df.shape}\n")










# # src/feature_engineering/imputation.py

# import os
# import pandas as pd
# import logging
# from IPython.display import display, HTML
# from src.utils.file_operations import save_dataframe

# def create_imputation_strategy_table(metadata, high_missing_values_df, medium_missing_values_df):
#     """
#     Create the imputation strategy table based on feature data.

#     Parameters:
#     metadata (dict): Metadata dictionary.
#     high_missing_values_df (pd.DataFrame): DataFrame of high missing values features.
#     medium_missing_values_df (pd.DataFrame): DataFrame of medium missing values features.

#     Returns:
#     pd.DataFrame: DataFrame containing imputation strategy data.
#     """
#     imputation_data = []
#     for feature, details in metadata['features'].items():
#         missing_percentage = details.get('missing_values', {}).get('percentage', None)
#         classification = details.get('classified_data_type', 'Unknown')
#         imputation_strategy = 'Keep'
#         comments = ''
        
#         if feature in high_missing_values_df['Feature'].values:
#             imputation_strategy = 'Drop'
#             comments = 'High missing values.'
#         elif feature in medium_missing_values_df['Feature'].values:
#             comments = 'Moderate missing values.'
#         elif missing_percentage is not None and missing_percentage < 50:
#             if classification == 'categorical':
#                 imputation_strategy = 'Mode'
#             elif classification == 'numerical':
#                 imputation_strategy = 'Median'
#             elif classification == 'binary':
#                 imputation_strategy = 'Mode'
        
#         imputation_info = {
#             'Feature': feature,
#             'Classification': classification,
#             'Imputation Strategy': imputation_strategy,
#             'Comments': comments
#         }
#         imputation_data.append(imputation_info)
    
#     return pd.DataFrame(imputation_data)

# def save_dataframes(high_missing_values_df, medium_missing_values_df, low_missing_values_df,
#                     high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df,
#                     high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df, paths):
#     """
#     Save various DataFrames to CSV files.

#     Parameters:
#     high_missing_values_df, medium_missing_values_df, low_missing_values_df (pd.DataFrame): DataFrames of missing values features.
#     high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df (pd.DataFrame): DataFrames of correlation with target.
#     high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df (pd.DataFrame): DataFrames of missing values correlation with target.
#     paths (dict): Dictionary containing file paths.
#     """
#     output_dir = paths['reports']['analysis_results']
#     high_output_path = os.path.join(output_dir, 'high_missing_values_handling_strategy.csv')
#     medium_output_path = os.path.join(output_dir, 'medium_missing_values_handling_strategy.csv')
#     low_output_path = os.path.join(output_dir, 'low_missing_values_handling_strategy.csv')
#     high_corr_with_target_output_path = os.path.join(output_dir, 'high_corr_with_target.csv')
#     moderate_corr_with_target_output_path = os.path.join(output_dir, 'moderate_corr_with_target.csv')
#     low_corr_with_target_output_path = os.path.join(output_dir, 'low_corr_with_target.csv')
#     high_missing_corr_with_target_output_path = os.path.join(output_dir, 'high_missing_corr_with_target.csv')
#     moderate_missing_corr_with_target_output_path = os.path.join(output_dir, 'moderate_missing_corr_with_target.csv')
#     low_missing_corr_with_target_output_path = os.path.join(output_dir, 'low_missing_corr_with_target.csv')

#     save_dataframe(high_missing_values_df, high_output_path)
#     save_dataframe(medium_missing_values_df, medium_output_path)
#     save_dataframe(low_missing_values_df, low_output_path)
#     save_dataframe(high_corr_with_target_df, high_corr_with_target_output_path)
#     save_dataframe(moderate_corr_with_target_df, moderate_corr_with_target_output_path)
#     save_dataframe(low_corr_with_target_df, low_corr_with_target_output_path)
#     save_dataframe(high_missing_corr_with_target_df, high_missing_corr_with_target_output_path)
#     save_dataframe(moderate_missing_corr_with_target_df, moderate_missing_corr_with_target_output_path)
#     save_dataframe(low_missing_corr_with_target_df, low_missing_corr_with_target_output_path)

#     logging.info(f"High missing values handling strategy table saved to {high_output_path}")
#     logging.info(f"Medium missing values handling strategy table saved to {medium_output_path}")
#     logging.info(f"Low missing values handling strategy table saved to {low_output_path}")
#     logging.info(f"High Correlation with Target table saved to {high_corr_with_target_output_path}")
#     logging.info(f"Moderate Correlation with Target table saved to {moderate_corr_with_target_output_path}")
#     logging.info(f"Low Correlation with Target table saved to {low_corr_with_target_output_path}")
#     logging.info(f"High Missing Values Correlation with Target table saved to {high_missing_corr_with_target_output_path}")
#     logging.info(f"Moderate Missing Values Correlation with Target table saved to {moderate_missing_corr_with_target_output_path}")
#     logging.info(f"Low Missing Values Correlation with Target table saved to {low_missing_corr_with_target_output_path}")

# def extract_feature_data(metadata):
#     """
#     Extract relevant feature data for analysis.

#     Parameters:
#     metadata (dict): Metadata dictionary.

#     Returns:
#     pd.DataFrame: DataFrame containing extracted feature data.
#     """
#     data = []
#     for feature, details in metadata['features'].items():
#         missing_percentage = details.get('missing_values', {}).get('percentage', None)
#         if missing_percentage is not None and missing_percentage > 0:
#             feature_info = {
#                 'Feature': feature,
#                 'Missing Percentage (%)': missing_percentage,
#                 'Correlation with Target': details.get('correlation_with_target', None),
#                 'Missing Values Correlation with Target': details.get('missing_values', {}).get('missing_values_correlation_with_target', None)
#             }
#             data.append(feature_info)
    
#     df = pd.DataFrame(data)
#     df['Correlation with Target'] = pd.to_numeric(df['Correlation with Target'], errors='coerce')
#     df['Missing Values Correlation with Target'] = pd.to_numeric(df['Missing Values Correlation with Target'], errors='coerce')
#     return df.sort_values(by='Missing Percentage (%)', ascending=False)

# def display_dataframes(high_missing_values_df, medium_missing_values_df, low_missing_values_df,
#                        high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df,
#                        high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df):
#     """
#     Display DataFrames in a visually appealing format.

#     Parameters:
#     high_missing_values_df, medium_missing_values_df, low_missing_values_df (pd.DataFrame): DataFrames of missing values features.
#     high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df (pd.DataFrame): DataFrames of correlation with target.
#     high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df (pd.DataFrame): DataFrames of missing values correlation with target.
#     """
#     print("Features with High % of Missing Values (>=50%)\n")
#     display(HTML(high_missing_values_df.to_html(index=False)))
#     print(f"Size of High Missing Values table: {high_missing_values_df.shape}\n")

#     print("\nFeatures with Medium % of Missing Values (>=10% and < 50%)\n")
#     display(HTML(medium_missing_values_df.to_html(index=False)))
#     print(f"Size of Medium Missing Values table: {medium_missing_values_df.shape}\n")

#     print("\nFeatures with Low % of Missing Values (<10%)\n")
#     display(HTML(low_missing_values_df.to_html(index=False)))
#     print(f"Size of Low Missing Values table: {low_missing_values_df.shape}\n")

#     print("\nHigh Correlation with Target (|correlation| > 0.7)\n")
#     display(HTML(high_corr_with_target_df.to_html(index=False)))
#     print(f"Size of High Correlation with Target table: {high_corr_with_target_df.shape}\n")

#     print("\nModerate Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
#     display(HTML(moderate_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Moderate Correlation with Target table: {moderate_corr_with_target_df.shape}\n")

#     print("\nLow Correlation with Target (|correlation| ≤ 0.3)\n")
#     display(HTML(low_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Low Correlation with Target table: {low_corr_with_target_df.shape}\n")

#     print("\nHigh Missing Values Correlation with Target (|correlation| > 0.7)\n")
#     display(HTML(high_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of High Missing Values Correlation with Target table: {high_missing_corr_with_target_df.shape}\n")

#     print("\nModerate Missing Values Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
#     display(HTML(moderate_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Moderate Missing Values Correlation with Target table: {moderate_missing_corr_with_target_df.shape}\n")

#     print("\nLow Missing Values Correlation with Target (|correlation| ≤ 0.3)\n")
#     display(HTML(low_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Low Missing Values Correlation with Target table: {low_missing_corr_with_target_df.shape}\n")





















# # src/feature_engineering/imputation.py

# import yaml
# from src.config_loader import load_paths
# from src.feature_engineering.utils import load_feature_metadata, save_feature_metadata, classify_data_type

# def parse_missing_percentage(missing_value_str):
#     # Remove any non-numeric characters and convert to float
#     return float(''.join(filter(lambda x: x.isdigit() or x == '.', missing_value_str)))

# def define_imputation_strategies(feature_metadata):
#     imputation_strategies = {
#         'numerical_features': {},
#         'categorical_features': {},
#         'binary_features': {}
#     }

#     for feature, metadata in feature_metadata['features'].items():
#         data_type = classify_data_type(metadata)
#         missing_percentage = parse_missing_percentage(metadata['missing_values'])

#         if data_type == 'numerical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['numerical_features'][feature] = 'mean'
#             elif 5.0 <= missing_percentage < 20.0:
#                 imputation_strategies['numerical_features'][feature] = 'median'
#             else:
#                 imputation_strategies['numerical_features'][feature] = 'mode'

#         elif data_type == 'categorical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['categorical_features'][feature] = 'mode'
#             else:
#                 imputation_strategies['categorical_features'][feature] = 'Unknown'

#         elif data_type == 'binary':
#             imputation_strategies['binary_features'][feature] = 'mode'

#     return imputation_strategies

# def save_imputation_strategies(imputation_strategies):
#     paths = load_paths()
#     with open(paths['config']['imputation_strategies'], 'w') as file:
#         file.write("# config/imputation_strategies.yaml\n\n")
#         yaml.dump(imputation_strategies, file)
