# src/feature_engineering/imputation.py

import os
import yaml
import logging
import pandas as pd
from tqdm.notebook import tqdm
from typing import List, Tuple, Dict
from IPython.display import display, HTML
from src.config_loader import load_paths
from src.utils.json_pipeline import save_json_with_pipeline
from src.utils.metadata_operations import extract_general_attributes, extract_missing_values, extract_correlations
from src.utils.file_operations import load_json_file, save_dataframe, save_json_file
from src.feature_engineering.utils import classify_data_type
from src.utils.metadata_operations import extract_classified_data_type, extract_missing_count, extract_missing_percentage, extract_imputation_strategy

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def drop_features(data: pd.DataFrame, metadata: dict) -> Tuple[pd.DataFrame, List[str]]:
    """
    Identify and drop features flagged for dropping.

    Parameters:
    - data (pd.DataFrame): The DataFrame from which to drop features.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - Tuple[pd.DataFrame, List[str]]: A tuple containing the DataFrame with features dropped and a list of dropped features.
    """
    features_to_drop = [
        feature for feature in metadata['features'].keys() 
        if extract_imputation_strategy(metadata, feature) == 'Drop'
    ]
    data.drop(columns=features_to_drop, inplace=True)
    return data, features_to_drop


def extract_imputation_data(metadata: dict, features_to_drop: List[str]) -> pd.DataFrame:
    """
    Extract imputation strategy information into a DataFrame.

    Parameters:
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (List[str]): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with imputation data.
    """
    imputation_data = []
    for feature in metadata['features'].keys():
        if feature not in features_to_drop:
            imputation_strategy = extract_imputation_strategy(metadata, feature)
            missing_percentage = extract_missing_percentage(metadata, feature)
            classified_data_type = extract_classified_data_type(metadata, feature)
            if missing_percentage is not None:
                feature_info = {
                    'Feature': feature,
                    'Classification': classified_data_type,
                    'Imputation Strategy': imputation_strategy,
                    'Missing Percentage (%)': missing_percentage
                }
                imputation_data.append(feature_info)
    return pd.DataFrame(imputation_data)


def should_label_missing(missing_percentage: float, threshold: float = 5.0) -> bool:
    """
    Determine whether missing values for a feature should be labeled based on the threshold.
    
    Parameters:
    missing_percentage (float): The missing percentage for the feature.
    threshold (float): The threshold percentage to decide if labeling is needed. Default is 5.0.

    Returns:
    bool: True if missing values should be labeled, False otherwise.
    """
    return missing_percentage is not None and missing_percentage > threshold


def label_missing_values(data: pd.DataFrame, metadata: dict, features_to_drop: List[str]) -> Tuple[pd.DataFrame, List[str]]:
    """
    Label missing values for reference in future analysis.

    Parameters:
    - data (pd.DataFrame): The DataFrame to label missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (List[str]): List of features to drop.

    Returns:
    - Tuple[pd.DataFrame, List[str]]: DataFrame with missing values labeled and list of essential missing value indicators.
    """
    essential_missing_indicators = []
    for feature in tqdm(metadata['features'].keys(), desc="Labeling missing values"):
        if feature not in features_to_drop:
            missing_percentage = extract_missing_percentage(metadata, feature)
            if should_label_missing(missing_percentage):
                data[f'{feature}_is_missing'] = data[feature].isnull().astype(int)
                essential_missing_indicators.append(f'{feature}_is_missing')
    return data, essential_missing_indicators


def impute_missing_values(data: pd.DataFrame, metadata: dict, features_to_drop: List[str]) -> pd.DataFrame:
    """
    Impute missing values according to the imputation strategy.

    Parameters:
    - data (pd.DataFrame): The DataFrame to impute missing values.
    - metadata (dict): Metadata containing feature information.
    - features_to_drop (List[str]): List of features to drop.

    Returns:
    - pd.DataFrame: DataFrame with missing values imputed.
    """
    for feature in tqdm(metadata['features'].keys(), desc="Imputing missing values"):
        if feature not in features_to_drop:
            imputation_strategy = extract_imputation_strategy(metadata, feature)
            
            if imputation_strategy == 'Mode':
                mode_value = data[feature].mode()[0]
                data[feature] = data[feature].fillna(mode_value)
                
            elif imputation_strategy == 'Median':
                median_value = data[feature].median()
                data[feature] = data[feature].fillna(median_value)
                
            elif imputation_strategy == 'Mean':
                mean_value = data[feature].mean()
                data[feature] = data[feature].fillna(mean_value)
                
            # Add other imputation strategies as needed
            
    return data


def save_essential_missing_value_features(essential_missing_value_features: List[dict], essential_missing_value_features_path: str) -> None:
    """
    Save essential missing value features to a JSON file.

    Parameters:
    - essential_missing_value_features (List[dict]): List of dictionaries representing essential missing value features.
    - essential_missing_value_features_path (str): Path to save the JSON file.
    """
    save_json_file(essential_missing_value_features, essential_missing_value_features_path)


def create_imputation_strategy_table(metadata: dict, high_missing_values_df: pd.DataFrame, moderate_missing_values_df: pd.DataFrame) -> pd.DataFrame:
    """
    Create the imputation strategy table based on feature data.

    Parameters:
    - metadata (dict): Metadata dictionary.
    - high_missing_values_df (pd.DataFrame): DataFrame of high missing values features.
    - moderate_missing_values_df (pd.DataFrame): DataFrame of moderate missing values features.

    Returns:
    - pd.DataFrame: DataFrame containing imputation strategy data.
    """
    if isinstance(metadata, str):
        logging.error("Expected metadata to be a dictionary, but got a string.")
        raise TypeError("Metadata should be a dictionary, not a string.")

    imputation_data = []
    for feature, details in metadata['features'].items():
        missing_percentage = details.get('missing_values', {}).get('percentage', None)
        classification = details.get('general_attributes', {}).get('classified_data_type', 'Unknown')
        imputation_strategy = 'Keep'
        comments = ''
        
        if feature in high_missing_values_df['Feature'].values:
            imputation_strategy = 'Drop'
            comments = 'High missing values.'
        elif feature in moderate_missing_values_df['Feature'].values:
            if classification == 'categorical':
                imputation_strategy = 'Mode'
            elif classification == 'numerical':
                imputation_strategy = 'Median'
            elif classification == 'binary':
                imputation_strategy = 'Mode'
            comments = 'Moderate missing values.'
        elif missing_percentage is not None and missing_percentage < 10:
            if classification == 'categorical':
                imputation_strategy = 'Mode'
            elif classification == 'numerical':
                imputation_strategy = 'Median'
            elif classification == 'binary':
                imputation_strategy = 'Mode'
        
        imputation_info = {
            'Feature': feature,
            'Classification': classification,
            'Imputation Strategy': imputation_strategy,
            'Comments': comments
        }
        imputation_data.append(imputation_info)
    
    return pd.DataFrame(imputation_data)


def save_dataframes(
    high_missing_values_df: pd.DataFrame,
    moderate_missing_values_df: pd.DataFrame,
    low_missing_values_df: pd.DataFrame,
    high_corr_with_target_df: pd.DataFrame,
    moderate_corr_with_target_df: pd.DataFrame,
    low_corr_with_target_df: pd.DataFrame,
    high_missing_corr_with_target_df: pd.DataFrame,
    moderate_missing_corr_with_target_df: pd.DataFrame,
    low_missing_corr_with_target_df: pd.DataFrame,
    paths: Dict[str, Dict[str, str]]
) -> None:
    """
    Save various DataFrames to CSV files.

    Parameters:
    - high_missing_values_df (pd.DataFrame): DataFrame of high missing values features.
    - moderate_missing_values_df (pd.DataFrame): DataFrame of moderate missing values features.
    - low_missing_values_df (pd.DataFrame): DataFrame of low missing values features.
    - high_corr_with_target_df (pd.DataFrame): DataFrame of high correlation with target features.
    - moderate_corr_with_target_df (pd.DataFrame): DataFrame of moderate correlation with target features.
    - low_corr_with_target_df (pd.DataFrame): DataFrame of low correlation with target features.
    - high_missing_corr_with_target_df (pd.DataFrame): DataFrame of high missing values correlation with target.
    - moderate_missing_corr_with_target_df (pd.DataFrame): DataFrame of moderate missing values correlation with target.
    - low_missing_corr_with_target_df (pd.DataFrame): DataFrame of low missing values correlation with target.
    - paths (Dict[str, Dict[str, str]]): Dictionary containing file paths.
    """
    output_dir = paths['reports']['analysis_results']
    high_output_path = os.path.join(output_dir, 'high_missing_values_handling_strategy.csv')
    moderate_output_path = os.path.join(output_dir, 'moderate_missing_values_handling_strategy.csv')
    low_output_path = os.path.join(output_dir, 'low_missing_values_handling_strategy.csv')
    high_corr_with_target_output_path = os.path.join(output_dir, 'high_corr_with_target.csv')
    moderate_corr_with_target_output_path = os.path.join(output_dir, 'moderate_corr_with_target.csv')
    low_corr_with_target_output_path = os.path.join(output_dir, 'low_corr_with_target.csv')
    high_missing_corr_with_target_output_path = os.path.join(output_dir, 'high_missing_corr_with_target.csv')
    moderate_missing_corr_with_target_output_path = os.path.join(output_dir, 'moderate_missing_corr_with_target.csv')
    low_missing_corr_with_target_output_path = os.path.join(output_dir, 'low_missing_corr_with_target.csv')

    save_dataframe(high_missing_values_df, high_output_path)
    save_dataframe(moderate_missing_values_df, moderate_output_path)
    save_dataframe(low_missing_values_df, low_output_path)
    save_dataframe(high_corr_with_target_df, high_corr_with_target_output_path)
    save_dataframe(moderate_corr_with_target_df, moderate_corr_with_target_output_path)
    save_dataframe(low_corr_with_target_df, low_corr_with_target_output_path)
    save_dataframe(high_missing_corr_with_target_df, high_missing_corr_with_target_output_path)
    save_dataframe(moderate_missing_corr_with_target_df, moderate_missing_corr_with_target_output_path)
    save_dataframe(low_missing_corr_with_target_df, low_missing_corr_with_target_output_path)

    logging.info(f"High missing values handling strategy table saved to {high_output_path}")
    logging.info(f"Moderate missing values handling strategy table saved to {moderate_output_path}")
    logging.info(f"Low missing values handling strategy table saved to {low_output_path}")
    logging.info(f"High Correlation with Target table saved to {high_corr_with_target_output_path}")
    logging.info(f"Moderate Correlation with Target table saved to {moderate_corr_with_target_output_path}")
    logging.info(f"Low Correlation with Target table saved to {low_corr_with_target_output_path}")
    logging.info(f"High Missing Values Correlation with Target table saved to {high_missing_corr_with_target_output_path}")
    logging.info(f"Moderate Missing Values Correlation with Target table saved to {moderate_missing_corr_with_target_output_path}")
    logging.info(f"Low Missing Values Correlation with Target table saved to {low_missing_corr_with_target_output_path}")


def extract_feature_data_via_pipeline(metadata_path: str, features: list) -> pd.DataFrame:
    """
    Extract relevant feature data for analysis using the metadata extraction pipeline.

    Parameters:
    metadata_path (str): Path to the feature metadata JSON file.
    features (list): List of feature names to extract.

    Returns:
    pd.DataFrame: DataFrame containing extracted feature data.
    """
    try:
        # Load the metadata
        metadata = load_json_file(metadata_path)

        # Store DataFrames for each feature
        data = []

        for feature in features:
            # Extract relevant metadata using modular functions
            general_attributes = extract_general_attributes(metadata, feature)
            missing_values = extract_missing_values(metadata, feature)
            correlations = extract_correlations(metadata, feature)

            # Combine all extracted data into a single DataFrame
            combined_data = {'Feature': feature, **general_attributes, **missing_values, **correlations}
            feature_df = pd.DataFrame([combined_data])

            data.append(feature_df)

        # Concatenate all DataFrames into a single DataFrame
        if data:
            df_combined = pd.concat(data, ignore_index=True)
        else:
            df_combined = pd.DataFrame()  # Return an empty DataFrame if no data

        df_combined['Correlation with Target'] = pd.to_numeric(df_combined['Correlation with Target'], errors='coerce')
        df_combined['Missing Values Correlation with Target'] = pd.to_numeric(df_combined['Missing Values Correlation with Target'], errors='coerce')

        return df_combined.sort_values(by='Missing Percentage (%)', ascending=False)
    except Exception as e:
        logging.error(f"Error extracting feature data via pipeline: {e}", exc_info=True)
        raise


def display_dataframes(
    high_missing_values_df: pd.DataFrame,
    moderate_missing_values_df: pd.DataFrame,
    low_missing_values_df: pd.DataFrame,
    high_corr_with_target_df: pd.DataFrame,
    moderate_corr_with_target_df: pd.DataFrame,
    low_corr_with_target_df: pd.DataFrame,
    high_missing_corr_with_target_df: pd.DataFrame,
    moderate_missing_corr_with_target_df: pd.DataFrame,
    low_missing_corr_with_target_df: pd.DataFrame
) -> None:
    """
    Display DataFrames in a visually appealing format.

    Parameters:
    - high_missing_values_df (pd.DataFrame): DataFrame of high missing values features.
    - moderate_missing_values_df (pd.DataFrame): DataFrame of moderate missing values features.
    - low_missing_values_df (pd.DataFrame): DataFrame of low missing values features.
    - high_corr_with_target_df (pd.DataFrame): DataFrame of high correlation with target features.
    - moderate_corr_with_target_df (pd.DataFrame): DataFrame of moderate correlation with target features.
    - low_corr_with_target_df (pd.DataFrame): DataFrame of low correlation with target features.
    - high_missing_corr_with_target_df (pd.DataFrame): DataFrame of high missing values correlation with target.
    - moderate_missing_corr_with_target_df (pd.DataFrame): DataFrame of moderate missing values correlation with target.
    - low_missing_corr_with_target_df (pd.DataFrame): DataFrame of low missing values correlation with target.
    """
    print("Features with High % of Missing Values (>=50%)\n")
    display(HTML(high_missing_values_df.to_html(index=False)))
    print(f"Size of High Missing Values table: {high_missing_values_df.shape}\n")

    print("\nFeatures with Moderate % of Missing Values (>=10% and < 50%)\n")
    display(HTML(moderate_missing_values_df.to_html(index=False)))
    print(f"Size of Moderate Missing Values table: {moderate_missing_values_df.shape}\n")

    print("\nFeatures with Low % of Missing Values (<10%)\n")
    display(HTML(low_missing_values_df.to_html(index=False)))
    print(f"Size of Low Missing Values table: {low_missing_values_df.shape}\n")

    print("\nHigh Correlation with Target (|correlation| > 0.7)\n")
    display(HTML(high_corr_with_target_df.to_html(index=False)))
    print(f"Size of High Correlation with Target table: {high_corr_with_target_df.shape}\n")

    print("\nModerate Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
    display(HTML(moderate_corr_with_target_df.to_html(index=False)))
    print(f"Size of Moderate Correlation with Target table: {moderate_corr_with_target_df.shape}\n")

    print("\nLow Correlation with Target (|correlation| ≤ 0.3)\n")
    display(HTML(low_corr_with_target_df.to_html(index=False)))
    print(f"Size of Low Correlation with Target table: {low_corr_with_target_df.shape}\n")

    print("\nHigh Missing Values Correlation with Target (|correlation| > 0.7)\n")
    display(HTML(high_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of High Missing Values Correlation with Target table: {high_missing_corr_with_target_df.shape}\n")

    print("\nModerate Missing Values Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
    display(HTML(moderate_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of Moderate Missing Values Correlation with Target table: {moderate_missing_corr_with_target_df.shape}\n")

    print("\nLow Missing Values Correlation with Target (|correlation| ≤ 0.3)\n")
    display(HTML(low_missing_corr_with_target_df.to_html(index=False)))
    print(f"Size of Low Missing Values Correlation with Target table: {low_missing_corr_with_target_df.shape}\n")


def transform_imputation_strategy_to_schema(imputation_df: pd.DataFrame) -> Dict[str, Dict]:
    """
    Transform the imputation strategy DataFrame into a nested dictionary structure consistent with the schema.
    
    Parameters:
    - imputation_df (pd.DataFrame): DataFrame containing imputation strategies.
    
    Returns:
    - dict: Nested dictionary structured according to the schema.
    """
    imputation_strategy_dict: Dict[str, Dict] = {}

    for _, row in imputation_df.iterrows():
        feature_name = row['Feature']
        imputation_type = row['Imputation Strategy']
        comments = row['Comments']

        imputation_strategy_dict.setdefault('features', {}).setdefault(feature_name, {}).setdefault(
            'feature_engineering', {}).setdefault('imputation', {})['type'] = imputation_type
        imputation_strategy_dict['features'][feature_name]['feature_engineering']['imputation']['comments'] = comments

    return imputation_strategy_dict


def save_imputation_strategy(imputation_df: pd.DataFrame, save_path: str) -> None:
    """
    Save the transformed imputation strategy to a JSON file.
    
    Parameters:
    - imputation_df (pd.DataFrame): DataFrame containing imputation strategies.
    - save_path (str): The path where the JSON file should be saved.
    """
    imputation_strategy_dict = transform_imputation_strategy_to_schema(imputation_df)
    save_json_with_pipeline(imputation_strategy_dict, save_path)
    logging.info(f"Imputation strategy saved to {save_path}")











































# def display_dataframes(high_missing_values_df, moderate_missing_values_df, low_missing_values_df,
#                        high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df,
#                        high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df):
#     """
#     Display DataFrames in a visually appealing format.

#     Parameters:
#     high_missing_values_df, moderate_missing_values_df, low_missing_values_df (pd.DataFrame): DataFrames of missing values features.
#     high_corr_with_target_df, moderate_corr_with_target_df, low_corr_with_target_df (pd.DataFrame): DataFrames of correlation with target.
#     high_missing_corr_with_target_df, moderate_missing_corr_with_target_df, low_missing_corr_with_target_df (pd.DataFrame): DataFrames of missing values correlation with target.
#     """
#     print("Features with High % of Missing Values (>=50%)\n")
#     display(HTML(high_missing_values_df.to_html(index=False)))
#     print(f"Size of High Missing Values table: {high_missing_values_df.shape}\n")

#     print("\nFeatures with Moderate % of Missing Values (>=10% and < 50%)\n")
#     display(HTML(moderate_missing_values_df.to_html(index=False)))
#     print(f"Size of Moderate Missing Values table: {moderate_missing_values_df.shape}\n")

#     print("\nFeatures with Low % of Missing Values (<10%)\n")
#     display(HTML(low_missing_values_df.to_html(index=False)))
#     print(f"Size of Low Missing Values table: {low_missing_values_df.shape}\n")

#     print("\nHigh Correlation with Target (|correlation| > 0.7)\n")
#     display(HTML(high_corr_with_target_df.to_html(index=False)))
#     print(f"Size of High Correlation with Target table: {high_corr_with_target_df.shape}\n")

#     print("\nModerate Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
#     display(HTML(moderate_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Moderate Correlation with Target table: {moderate_corr_with_target_df.shape}\n")

#     print("\nLow Correlation with Target (|correlation| ≤ 0.3)\n")
#     display(HTML(low_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Low Correlation with Target table: {low_corr_with_target_df.shape}\n")

#     print("\nHigh Missing Values Correlation with Target (|correlation| > 0.7)\n")
#     display(HTML(high_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of High Missing Values Correlation with Target table: {high_missing_corr_with_target_df.shape}\n")

#     print("\nModerate Missing Values Correlation with Target (0.3 < |correlation| ≤ 0.7)\n")
#     display(HTML(moderate_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Moderate Missing Values Correlation with Target table: {moderate_missing_corr_with_target_df.shape}\n")

#     print("\nLow Missing Values Correlation with Target (|correlation| ≤ 0.3)\n")
#     display(HTML(low_missing_corr_with_target_df.to_html(index=False)))
#     print(f"Size of Low Missing Values Correlation with Target table: {low_missing_corr_with_target_df.shape}\n")


# def transform_imputation_strategy_to_schema(imputation_df: pd.DataFrame) -> dict:
#     """
#     Transform the imputation strategy DataFrame into a nested dictionary structure consistent with the schema.
    
#     Parameters:
#     imputation_df (pd.DataFrame): DataFrame containing imputation strategies.
    
#     Returns:
#     dict: Nested dictionary structured according to the schema.
#     """
#     imputation_strategy_dict = {}
    
#     for _, row in imputation_df.iterrows():
#         feature_name = row['Feature']
#         imputation_type = row['Imputation Strategy']
#         comments = row['Comments']

#         imputation_strategy_dict.setdefault('features', {}).setdefault(feature_name, {}).setdefault(
#             'feature_engineering', {}).setdefault('imputation', {})['type'] = imputation_type
#         imputation_strategy_dict['features'][feature_name]['feature_engineering']['imputation']['comments'] = comments

#     return imputation_strategy_dict


# def save_imputation_strategy(imputation_df: pd.DataFrame, save_path: str):
#     """
#     Save the transformed imputation strategy to a JSON file.
    
#     Parameters:
#     imputation_df (pd.DataFrame): DataFrame containing imputation strategies.
#     save_path (str): The path where the JSON file should be saved.
#     """
#     imputation_strategy_dict = transform_imputation_strategy_to_schema(imputation_df)
#     save_json_with_pipeline(imputation_strategy_dict, save_path)
#     logging.info(f"Imputation strategy saved to {save_path}")



























































# def save_imputation_strategies(imputation_strategies):
#     paths = load_paths()
#     with open(paths['config']['imputation_strategies'], 'w') as file:
#         file.write("# config/imputation_strategies.yaml\n\n")
#         yaml.dump(imputation_strategies, file)


# def parse_missing_percentage(missing_value_str):
#     return float(''.join(filter(lambda x: x.isdigit() or x == '.', missing_value_str)))


# def define_imputation_strategies(feature_metadata):
#     imputation_strategies = {
#         'numerical_features': {},
#         'categorical_features': {},
#         'binary_features': {}
#     }

#     for feature, metadata in feature_metadata['features'].items():
#         data_type = classify_data_type(metadata)
#         missing_percentage = parse_missing_percentage(metadata['missing_values'])

#         if data_type == 'numerical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['numerical_features'][feature] = 'mean'
#             elif 5.0 <= missing_percentage < 20.0:
#                 imputation_strategies['numerical_features'][feature] = 'median'
#             else:
#                 imputation_strategies['numerical_features'][feature] = 'mode'
#         elif data_type == 'categorical':
#             if missing_percentage < 5.0:
#                 imputation_strategies['categorical_features'][feature] = 'mode'
#             else:
#                 imputation_strategies['categorical_features'][feature] = 'Unknown'
#         elif data_type == 'binary':
#             imputation_strategies['binary_features'][feature] = 'mode'

#     return imputation_strategies



# def map_classified_to_technical(classified_type):
#     """
#     Map classified data types to technical data types.
    
#     Parameters:
#     classified_type (str): The classified data type (binary, numerical, categorical).
    
#     Returns:
#     str: The corresponding technical data type (int, float, object).
#     """
#     if classified_type == 'binary':
#         return 'int64'  # Could also use 'bool' if preferred
#     elif classified_type == 'numerical':
#         return 'float64'  # Assume float for more flexibility
#     elif classified_type == 'categorical':
#         return 'object'
#     else:
#         return None

