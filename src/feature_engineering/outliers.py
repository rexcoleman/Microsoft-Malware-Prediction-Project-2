# src/feature_engineering/outliers.py

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
from scipy.stats import zscore, skew, kurtosis
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.cluster import DBSCAN
from src.utils.common import save_json_file, save_dataframe

def extract_outlier_metrics(metadata):
    outlier_metrics_columns = [
        'Feature', 'Z-Score Outliers', 'IQR Outliers', 'MAD Scores', 'Isolation Forest Outliers', 
        'LOF Outliers', 'DBSCAN Outliers', 'Skewness', 'Kurtosis'
    ]
    
    outlier_metrics_data = []

    for feature, details in metadata['features'].items():
        if 'outlier_metrics' in details:
            outlier_metrics = details['outlier_metrics']
            row = {
                'Feature': feature,
                'Z-Score Outliers': outlier_metrics.get('Z-Score Outliers', None),
                'IQR Outliers': outlier_metrics.get('IQR Outliers', None),
                'MAD Scores': outlier_metrics.get('MAD Scores', None),
                'Isolation Forest Outliers': outlier_metrics.get('Isolation Forest Outliers', None),
                'LOF Outliers': outlier_metrics.get('LOF Outliers', None),
                'DBSCAN Outliers': outlier_metrics.get('DBSCAN Outliers', None),
                'Skewness': outlier_metrics.get('Skewness', None),
                'Kurtosis': outlier_metrics.get('Kurtosis', None)
            }
            outlier_metrics_data.append(row)

    return pd.DataFrame(outlier_metrics_data, columns=outlier_metrics_columns)

def save_outlier_metrics_to_files(outlier_metrics_df, csv_path, json_path):
    save_dataframe(outlier_metrics_df, csv_path)
    save_json_file(outlier_metrics_df.to_dict(orient='records'), json_path)

def define_strategy_and_check_thresholds(feature_metrics):
    strategies = {}
    thresholds_exceeded = {}
    thresholds = {}

    for feature, metrics in feature_metrics.items():
        # Initialize a list to hold possible actions
        possible_actions = []
        feature_thresholds = {}
        
        feature_thresholds['Log Transformation'] = metrics['Skewness'] > 1 or metrics['Skewness'] < -1
        feature_thresholds['Square Root Transformation'] = metrics['Kurtosis'] > 3
        feature_thresholds['Clipping'] = metrics['Z-Score Outliers'] > 50 or metrics['IQR Outliers'] > 50
        feature_thresholds['Removing Outliers'] = metrics['Isolation Forest Outliers'] > 50 or metrics['LOF Outliers'] > 50 or metrics['DBSCAN Outliers'] > 50
        
        # Check conditions and append respective actions
        for action, condition in feature_thresholds.items():
            if condition:
                possible_actions.append((action, 1))
        
        # Sort actions based on priority
        possible_actions.sort(key=lambda x: x[1])
        
        # Extract the highest priority action
        if possible_actions:
            highest_priority_action = possible_actions[0][0]
        else:
            highest_priority_action = 'No Action'
        
        # Add the strategy for the current feature
        strategies[feature] = highest_priority_action

        # Record which thresholds were exceeded
        exceeded = {action: condition for action, condition in feature_thresholds.items()}
        thresholds_exceeded[feature] = exceeded
        thresholds[feature] = feature_thresholds
    
    return strategies, thresholds_exceeded, thresholds

def save_remediation_strategies(strategies, thresholds_exceeded, thresholds, analysis_results_path):
    strategies_json_path = os.path.join(analysis_results_path, 'remediation_strategies.json')
    thresholds_exceeded_json_path = os.path.join(analysis_results_path, 'thresholds_exceeded.json')
    thresholds_json_path = os.path.join(analysis_results_path, 'thresholds.json')

    save_json_file(strategies, strategies_json_path)
    save_json_file(thresholds_exceeded, thresholds_exceeded_json_path)
    save_json_file(thresholds, thresholds_json_path)

def save_all_tables(strategies_df, thresholds_exceeded_df, outlier_metrics_df, analysis_results_path):
    all_tables_csv_path = os.path.join(analysis_results_path, 'outlier_remediation_all_tables.csv')
    all_tables_df = pd.concat([strategies_df, thresholds_exceeded_df, outlier_metrics_df], axis=1)
    save_dataframe(all_tables_df, all_tables_csv_path)

def display_dataframe_as_html(df):
    from IPython.display import display, HTML
    display(HTML(df.to_html(index=False)))


def detect_outliers(df, columns):
    outliers = {}
    for column in columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers

def handle_outliers(df, columns):
    for column in columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
        df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])
    return df

def plot_outliers(train_cleaned_original, train_cleaned_no_outliers, numerical_columns, outliers):
    for column in numerical_columns:
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))

        sns.boxplot(x=train_cleaned_original[column], ax=axes[0])
        axes[0].set_title(f'Box Plot of {column} Before Handling Outliers')

        sns.boxplot(x=train_cleaned_no_outliers[column], ax=axes[1])
        axes[1].set_title(f'Box Plot of {column} After Handling Outliers')

        plt.show()

        # Calculate summary statistics before and after handling outliers
        summary_before = train_cleaned_original[column].describe()
        summary_after = train_cleaned_no_outliers[column].describe()

        summary_table = pd.DataFrame({'Before Handling Outliers': summary_before, 'After Handling Outliers': summary_after})
        print(f"Summary Statistics for {column}")
        print(summary_table)
        print()

        # Calculate proportion of outliers
        num_outliers = len(outliers[column])
        proportion_outliers = num_outliers / len(train_cleaned_original) * 100

        # Calculate skewness and kurtosis
        skewness_before = train_cleaned_original[column].skew()
        skewness_after = train_cleaned_no_outliers[column].skew()
        kurtosis_before = train_cleaned_original[column].kurt()
        kurtosis_after = train_cleaned_no_outliers[column].kurt()

        # Print insights and recommended actions
        if num_outliers > 0:
            insight = f"The feature '{column}' had {num_outliers} outliers ({proportion_outliers:.2f}% of the data) which have been capped to the lower and upper bounds."
            recommended_action = f"Review the impact of outlier handling on the distribution of '{column}'. Consider further analysis or feature transformation if necessary."
        else:
            insight = f"No significant outliers were detected for the feature '{column}'."
            recommended_action = f"No action needed for outliers in '{column}'."

        print(f"Insights for {column}: {insight}")
        print(f"Proportion of Outliers: {proportion_outliers:.2f}%")
        print(f"Skewness Before Handling Outliers: {skewness_before}, After: {skewness_after}")
        print(f"Kurtosis Before Handling Outliers: {kurtosis_before}, After: {kurtosis_after}")
        print(f"Recommended Actions for {column}: {recommended_action}")
        print("\n" + "-"*80 + "\n")

def calculate_outlier_metrics(data):
    outlier_metrics = []

    for feature in tqdm(data.columns, desc="Processing features"):
        if data[feature].dtype in ['float64', 'int64']:
            feature_data = data[feature].dropna()
            if feature_data.empty:
                continue

            # Z-Score Outliers
            z_scores = zscore(feature_data)
            z_outliers = (z_scores > 3) | (z_scores < -3)

            # IQR Outliers
            iqr = feature_data.quantile(0.75) - feature_data.quantile(0.25)
            lower_bound = feature_data.quantile(0.25) - 1.5 * iqr
            upper_bound = feature_data.quantile(0.75) + 1.5 * iqr
            iqr_outliers = (feature_data < lower_bound) | (feature_data > upper_bound)

            # MAD Scores
            median = feature_data.median()
            mad = np.median(np.abs(feature_data - median))
            mad_scores = np.abs(feature_data - median) / mad

            # Isolation Forest Outliers
            isolation_forest = IsolationForest(contamination=0.05)
            isolation_forest.fit(feature_data.values.reshape(-1, 1))
            iso_outliers = isolation_forest.predict(feature_data.values.reshape(-1, 1)) == -1

            # LOF Outliers
            lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)
            lof_outliers = lof.fit_predict(feature_data.values.reshape(-1, 1)) == -1

            # DBSCAN Outliers
            dbscan = DBSCAN(eps=0.5, min_samples=5)
            dbscan_outliers = dbscan.fit_predict(feature_data.values.reshape(-1, 1)) == -1

            # Skewness and Kurtosis
            skewness = skew(feature_data)
            kurtosis_value = kurtosis(feature_data)

            metrics = {
                'Feature': feature,
                'Z-Score Outliers': z_outliers.sum(),
                'IQR Outliers': iqr_outliers.sum(),
                'Z-Score Outliers (%)': z_outliers.mean() * 100,
                'IQR Outliers (%)': iqr_outliers.mean() * 100,
                'MAD Scores': (mad_scores > 3).sum(),
                'Isolation Forest Outliers': iso_outliers.sum(),
                'LOF Outliers': lof_outliers.sum(),
                'DBSCAN Outliers': dbscan_outliers.sum(),
                'Skewness': skewness,
                'Kurtosis': kurtosis_value
            }
            outlier_metrics.append(metrics)

    return pd.DataFrame(outlier_metrics)

def save_outlier_metrics(outlier_metrics_df, path):
    if not outlier_metrics_df.empty:
        save_json_file(outlier_metrics_df.to_dict(orient='records'), path)

# src/feature_engineering/outliers.py

import numpy as np
import pandas as pd
from scipy.stats import zscore

def log_transform(df, feature):
    df[feature] = np.log1p(df[feature])
    return df

def sqrt_transform(df, feature):
    df[feature] = np.sqrt(df[feature])
    return df

def clip_outliers(df, feature, lower_percentile=0.01, upper_percentile=0.99):
    lower = df[feature].quantile(lower_percentile)
    upper = df[feature].quantile(upper_percentile)
    df[feature] = np.clip(df[feature], lower, upper)
    return df

def remove_outliers(df, feature, z_threshold=3):
    df = df[(np.abs(zscore(df[feature])) < z_threshold)]
    return df

def apply_outlier_strategy(df, feature, strategy):
    if strategy == 'Log Transformation':
        return log_transform(df, feature)
    elif strategy == 'Square Root Transformation':
        return sqrt_transform(df, feature)
    elif strategy == 'Clipping':
        return clip_outliers(df, feature)
    elif strategy == 'Removing Outliers':
        return remove_outliers(df, feature)
    return df



# # src/feature_engineering/outliers.py

# import numpy as np
# import pandas as pd
# from scipy.stats import zscore

# def log_transform(df, feature):
#     df[feature] = np.log1p(df[feature])
#     return df

# def sqrt_transform(df, feature):
#     df[feature] = np.sqrt(df[feature])
#     return df

# def clip_outliers(df, feature, lower_percentile=0.01, upper_percentile=0.99):
#     lower = df[feature].quantile(lower_percentile)
#     upper = df[feature].quantile(upper_percentile)
#     df[feature] = np.clip(df[feature], lower, upper)
#     return df

# def remove_outliers(df, feature, z_threshold=3):
#     df = df[(np.abs(zscore(df[feature])) < z_threshold)]
#     return df

