# src/feature_engineering/outliers.py

import os
import sys
import pandas as pd
import numpy as np
import logging
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from scipy.stats import zscore, skew, kurtosis
from sklearn.cluster import DBSCAN
from scipy.stats import zscore
from tqdm.notebook import tqdm
from typing import Tuple, List, Dict, Any
import matplotlib.pyplot as plt
import seaborn as sns
from src.utils.json_pipeline import save_json_with_pipeline
from src.utils.metadata_operations import should_drop_feature, extract_classified_data_type
from src.visualization.plot_utils import set_plot_style, save_figure, plot_boxplot, plot_histogram
from src.utils.display_utils import display_dataframe_as_html


def outlier_analysis(data: pd.DataFrame, metadata: dict, reports_dir: str) -> Dict[str, Dict]:
    """
    Perform outlier analysis on the dataset and save results to JSON.
    Returns a dictionary with outlier metrics for each feature.
    """
    outlier_metrics = {"features": {}}

    for feature in tqdm(sorted(metadata['features'].keys()), desc="Outlier analysis"):
        # Check if the feature is marked for dropping
        if should_drop_feature(metadata, feature):
            logging.info(f"Skipping feature '{feature}' as it is marked for dropping.")
            continue

        # Skip binary features from outlier analysis
        classified_data_type = extract_classified_data_type(metadata, feature)
        if classified_data_type == "binary":
            logging.info(f"Skipping feature '{feature}' as it is classified as binary.")
            continue

        if metadata['features'][feature]['general_attributes']['technical_data_type'] in ['float64', 'int64']:
            outlier_metrics["features"][feature] = {
                'outliers': {
                    'metrics': {
                        'z_score_outliers': int(compute_z_scores(data, feature)),
                        'iqr_outliers': tuple(map(float, compute_iqr(data, feature))),  # Convert to float
                        'mad_outliers': tuple(map(float, compute_mad(data, feature))),  # Convert to float
                        'isolation_forest_outliers': int(compute_isolation_forest(data, feature)),
                        'lof_outliers': int(compute_lof(data, feature)),
                        'dbscan_outliers': int(compute_dbscan(data, feature)),
                        'skewness': float(compute_skewness(data, feature)),
                        'kurtosis': float(compute_kurtosis(data, feature))
                    }
                }
            }

    # Save outlier metrics to JSON file
    outlier_metrics_path = os.path.join(reports_dir, 'outlier_metrics.json')
    save_json_with_pipeline(outlier_metrics, outlier_metrics_path)
    logging.info(f"Outlier metrics saved to {outlier_metrics_path}")
    
    return outlier_metrics


def compute_z_scores(data: pd.DataFrame, feature: str) -> int:
    """Compute the number of Z-score outliers for a given feature."""
    z_scores = np.abs(zscore(data[feature].dropna()))
    return np.sum(z_scores > 3)  # Count of values with Z-score > 3

def compute_iqr(data: pd.DataFrame, feature: str) -> Tuple[float, float, int]:
    """Compute IQR and count of outliers for a given feature."""
    q1 = data[feature].quantile(0.25)
    q3 = data[feature].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = np.sum((data[feature] < lower_bound) | (data[feature] > upper_bound))
    return lower_bound, upper_bound, outliers

def compute_mad(data: pd.DataFrame, feature: str) -> Tuple[float, int]:
    """Compute MAD and count of outliers for a given feature."""
    median_value = np.median(data[feature])
    mad_value = np.median(np.abs(data[feature] - median_value))
    mad_scores = np.abs(data[feature] - median_value) / mad_value
    outliers = np.sum(mad_scores > 3)  # MAD score > 3 as outlier threshold
    return mad_value, outliers

def compute_isolation_forest(data: pd.DataFrame, feature: str) -> int:
    """Compute the number of Isolation Forest outliers for a given feature."""
    iso_forest = IsolationForest(contamination=0.05)
    predictions = iso_forest.fit_predict(data[[feature]].dropna())
    return np.sum(predictions == -1)  # Count of outliers

def compute_lof(data: pd.DataFrame, feature: str) -> int:
    """Compute the number of Local Outlier Factor (LOF) outliers for a given feature."""
    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)
    predictions = lof.fit_predict(data[[feature]].dropna())
    return np.sum(predictions == -1)  # Count of outliers

def compute_dbscan(data: pd.DataFrame, feature: str) -> int:
    """Compute the number of DBSCAN outliers for a given feature."""
    scaler = StandardScaler()
    scaled_feature = scaler.fit_transform(data[[feature]].dropna())
    dbscan = DBSCAN(eps=0.5, min_samples=5)
    predictions = dbscan.fit_predict(scaled_feature)
    return np.sum(predictions == -1)  # Count of outliers

def compute_skewness(data: pd.DataFrame, feature: str) -> float:
    """Compute skewness for a given feature."""
    return data[feature].dropna().skew()

def compute_kurtosis(data: pd.DataFrame, feature: str) -> float:
    """Compute kurtosis for a given feature."""
    return data[feature].dropna().kurt()


from src.visualization.plot_utils import set_plot_style, save_figure, plot_boxplot, plot_histogram

from src.visualization.plot_utils import set_plot_style, save_figure, plot_boxplot, plot_histogram



from src.visualization.plot_utils import set_plot_style, save_figure, plot_boxplot, plot_histogram

def visualize_outliers(data: pd.DataFrame, outlier_metrics: Dict[str, Dict]) -> None:
    """
    Visualize the outliers for each feature using histograms, box plots, and a table of metrics.
    """
    # Set the plot style globally
    set_plot_style("darkgrid")

    for feature, metrics in sorted(outlier_metrics['features'].items()):
        # Create subplots
        plt.figure(figsize=(14, 8))

        # Plot histogram
        plt.subplot(2, 2, 1)
        plot_histogram(data, feature)
        plt.title(f'Histogram of {feature}')

        # Plot boxplot
        plt.subplot(2, 2, 2)
        plot_boxplot(data, feature)
        plt.title(f'Boxplot of {feature}')

        # Create a DataFrame for the metrics
        metric_data = {
            'Metric': [
                'Z-Score Outliers', 'IQR Outliers', 'MAD Outliers', 
                'Isolation Forest Outliers', 'LOF Outliers', 'DBSCAN Outliers',
                'Skewness', 'Kurtosis'
            ],
            'Value': [
                metrics['outliers']['metrics']['z_score_outliers'],
                metrics['outliers']['metrics']['iqr_outliers'][2],  # IQR outlier count
                metrics['outliers']['metrics']['mad_outliers'][1],  # MAD outlier count
                metrics['outliers']['metrics']['isolation_forest_outliers'],
                metrics['outliers']['metrics']['lof_outliers'],
                metrics['outliers']['metrics']['dbscan_outliers'],
                metrics['outliers']['metrics']['skewness'],          # Skewness
                metrics['outliers']['metrics']['kurtosis']           # Kurtosis
            ]
        }
        metric_df = pd.DataFrame(metric_data)

        # Display the table below the plots
        plt.subplot(2, 1, 2)
        plt.axis('off')  # Turn off the axis for the table plot
        table = plt.table(cellText=metric_df.values, colLabels=metric_df.columns, loc='center', cellLoc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(12)  # Set the font size for the table

        plt.title(f'Outlier Metrics for {feature}', pad=20)  # Add padding between the title and the table

        plt.suptitle(f'Outlier Analysis for {feature}', fontsize=16)
        plt.tight_layout()
        plt.show()


# src/feature_engineering/outliers.py

import os
import sys
import pandas as pd
import numpy as np
import logging
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from scipy.stats import zscore, skew, kurtosis
from sklearn.cluster import DBSCAN
from typing import Tuple, List, Dict, Any
from src.utils.json_pipeline import save_json_with_pipeline
from src.utils.metadata_operations import should_drop_feature, extract_classified_data_type
from src.utils.display_utils import display_dataframe_as_html

def define_outlier_remediation_strategy(outlier_metrics: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
    """
    Define the outlier remediation strategy based on extracted outlier metrics and update the thresholds_exceeded metadata.

    Parameters:
    outlier_metrics (Dict[str, Dict[str, Any]]): Outlier metrics for each feature.

    Returns:
    Dict[str, Dict[str, Any]]: Dictionary with remediation strategies and updated thresholds_exceeded.
    """
    strategies = {}
    for feature, metrics in outlier_metrics.items():
        possible_actions = []
        thresholds_exceeded = {
            "log_transformation": False,
            "square_root_transformation": False,
            "clipping": False,
            "removing_outliers": False
        }

        if 'skewness' in metrics and (metrics['skewness'] > 1 or metrics['skewness'] < -1):
            possible_actions.append('Log Transformation')
            thresholds_exceeded["log_transformation"] = True
        
        if 'kurtosis' in metrics and metrics['kurtosis'] > 3:
            possible_actions.append('Square Root Transformation')
            thresholds_exceeded["square_root_transformation"] = True
        
        if 'z_score_outliers' in metrics and 'iqr_outliers' in metrics:
            if metrics['z_score_outliers'] > 50 or metrics['iqr_outliers'][2] > 50:
                possible_actions.append('Clipping')
                thresholds_exceeded["clipping"] = True
        
        if ('isolation_forest_outliers' in metrics and metrics['isolation_forest_outliers'] > 50) or \
           ('lof_outliers' in metrics and metrics['lof_outliers'] > 50) or \
           ('dbscan_outliers' in metrics and metrics['dbscan_outliers'] > 50):
            possible_actions.append('Removing Outliers')
            thresholds_exceeded["removing_outliers"] = True

        strategy = possible_actions[0] if possible_actions else 'No Action'
        strategies[feature] = {
            'feature_engineering': {
                'outlier_handling': {
                    'remediation_type': strategy,
                    'comments': f'Defined based on outlier metrics for {feature}'
                }
            },
            'outliers': {
                'thresholds_exceeded': thresholds_exceeded
            }
        }
    logging.info("Outlier remediation strategy defined successfully.")
    return strategies

def save_outlier_remediation_strategies(strategies: Dict[str, Dict[str, Any]], reports_dir: str) -> None:
    """
    Save the outlier remediation strategies and thresholds_exceeded to a JSON file.

    Parameters:
    strategies (Dict[str, Dict[str, Any]]): The remediation strategies and thresholds_exceeded to save.
    reports_dir (str): Directory to save the JSON file.
    """
    try:
        remediation_file_path = os.path.join(reports_dir, 'outlier_remediation_strategies.json')
        save_json_with_pipeline({'features': strategies}, remediation_file_path)
        logging.info(f"Outlier remediation strategies saved to {remediation_file_path}")
    except Exception as e:
        logging.error(f"Error saving outlier remediation strategies: {e}")
        raise

def display_thresholds_exceeded(strategies: Dict[str, Dict[str, Any]]) -> None:
    """
    Display the thresholds exceeded for each feature in a table format using display_dataframe_as_html.
    The table is sorted alphabetically by feature names.

    Parameters:
    strategies (Dict[str, Dict[str, Any]]): The remediation strategies to display.
    """
    data = {
        'Feature': [],
        'Log Transformation': [],
        'Square Root Transformation': [],
        'Clipping': [],
        'Removing Outliers': []
    }
    
    for feature, strategy in strategies.items():
        data['Feature'].append(feature)
        thresholds = strategy['outliers']['thresholds_exceeded']
        data['Log Transformation'].append(thresholds['log_transformation'])
        data['Square Root Transformation'].append(thresholds['square_root_transformation'])
        data['Clipping'].append(thresholds['clipping'])
        data['Removing Outliers'].append(thresholds['removing_outliers'])
    
    df = pd.DataFrame(data)
    df = df.sort_values(by='Feature').reset_index(drop=True)
    
    display_dataframe_as_html(df, title="Thresholds Exceeded", description="List of features and the thresholds they exceeded.")

    logging.info("Thresholds exceeded table displayed successfully.")


def display_outlier_remediation_strategy(strategies: Dict[str, Dict[str, Any]]) -> None:
    """
    Display the outlier remediation strategy in a table format using display_dataframe_as_html.
    The table is sorted alphabetically by feature names.

    Parameters:
    strategies (Dict[str, Dict[str, Any]]): The remediation strategies to display.
    """
    # Prepare data for the DataFrame
    data = {
        'Feature': [],
        'Remediation Strategy': []
    }
    
    for feature, strategy in strategies.items():
        data['Feature'].append(feature)
        data['Remediation Strategy'].append(strategy['feature_engineering']['outlier_handling']['remediation_type'])
    
    # Create the DataFrame
    df = pd.DataFrame(data)
    
    # Sort the DataFrame by the 'Feature' column
    df = df.sort_values(by='Feature').reset_index(drop=True)
    
    # Display the DataFrame as HTML
    display_dataframe_as_html(df, title="Outlier Remediation Strategy", description="List of features and their corresponding remediation strategies.")

    logging.info("Outlier remediation strategy displayed successfully.")




























# def define_strategy_and_check_thresholds(feature_metrics):
#     strategies = {}
#     thresholds_exceeded = {}
#     thresholds = {}

#     for feature, metrics in feature_metrics.items():
#         # Initialize a list to hold possible actions
#         possible_actions = []
#         feature_thresholds = {}
        
#         feature_thresholds['Log Transformation'] = metrics['Skewness'] > 1 or metrics['Skewness'] < -1
#         feature_thresholds['Square Root Transformation'] = metrics['Kurtosis'] > 3
#         feature_thresholds['Clipping'] = metrics['Z-Score Outliers'] > 50 or metrics['IQR Outliers'] > 50
#         feature_thresholds['Removing Outliers'] = metrics['Isolation Forest Outliers'] > 50 or metrics['LOF Outliers'] > 50 or metrics['DBSCAN Outliers'] > 50
        
#         # Check conditions and append respective actions
#         for action, condition in feature_thresholds.items():
#             if condition:
#                 possible_actions.append((action, 1))
        
#         # Sort actions based on priority
#         possible_actions.sort(key=lambda x: x[1])
        
#         # Extract the highest priority action
#         if possible_actions:
#             highest_priority_action = possible_actions[0][0]
#         else:
#             highest_priority_action = 'No Action'
        
#         # Add the strategy for the current feature
#         strategies[feature] = highest_priority_action

#         # Record which thresholds were exceeded
#         exceeded = {action: condition for action, condition in feature_thresholds.items()}
#         thresholds_exceeded[feature] = exceeded
#         thresholds[feature] = feature_thresholds
    
#     return strategies, thresholds_exceeded, thresholds

# def save_remediation_strategies(strategies, thresholds_exceeded, thresholds, analysis_results_path):
#     strategies_json_path = os.path.join(analysis_results_path, 'remediation_strategies.json')
#     thresholds_exceeded_json_path = os.path.join(analysis_results_path, 'thresholds_exceeded.json')
#     thresholds_json_path = os.path.join(analysis_results_path, 'thresholds.json')

#     save_json_file(strategies, strategies_json_path)
#     save_json_file(thresholds_exceeded, thresholds_exceeded_json_path)
#     save_json_file(thresholds, thresholds_json_path)

# def save_all_tables(strategies_df, thresholds_exceeded_df, outlier_metrics_df, analysis_results_path):
#     all_tables_csv_path = os.path.join(analysis_results_path, 'outlier_remediation_all_tables.csv')
#     all_tables_df = pd.concat([strategies_df, thresholds_exceeded_df, outlier_metrics_df], axis=1)
#     save_dataframe(all_tables_df, all_tables_csv_path)

# # def display_dataframe_as_html(df):
# #     from IPython.display import display, HTML
# #     display(HTML(df.to_html(index=False)))


# def detect_outliers(df, columns):
#     outliers = {}
#     for column in columns:
#         Q1 = df[column].quantile(0.25)
#         Q3 = df[column].quantile(0.75)
#         IQR = Q3 - Q1
#         lower_bound = Q1 - 1.5 * IQR
#         upper_bound = Q3 + 1.5 * IQR
#         outliers[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
#     return outliers

# def handle_outliers(df, columns):
#     for column in columns:
#         Q1 = df[column].quantile(0.25)
#         Q3 = df[column].quantile(0.75)
#         IQR = Q3 - Q1
#         lower_bound = Q1 - 1.5 * IQR
#         upper_bound = Q3 + 1.5 * IQR
#         df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
#         df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])
#     return df

# def plot_outliers(train_cleaned_original, train_cleaned_no_outliers, numerical_columns, outliers):
#     for column in numerical_columns:
#         fig, axes = plt.subplots(1, 2, figsize=(15, 5))

#         sns.boxplot(x=train_cleaned_original[column], ax=axes[0])
#         axes[0].set_title(f'Box Plot of {column} Before Handling Outliers')

#         sns.boxplot(x=train_cleaned_no_outliers[column], ax=axes[1])
#         axes[1].set_title(f'Box Plot of {column} After Handling Outliers')

#         plt.show()

#         # Calculate summary statistics before and after handling outliers
#         summary_before = train_cleaned_original[column].describe()
#         summary_after = train_cleaned_no_outliers[column].describe()

#         summary_table = pd.DataFrame({'Before Handling Outliers': summary_before, 'After Handling Outliers': summary_after})
#         print(f"Summary Statistics for {column}")
#         print(summary_table)
#         print()

#         # Calculate proportion of outliers
#         num_outliers = len(outliers[column])
#         proportion_outliers = num_outliers / len(train_cleaned_original) * 100

#         # Calculate skewness and kurtosis
#         skewness_before = train_cleaned_original[column].skew()
#         skewness_after = train_cleaned_no_outliers[column].skew()
#         kurtosis_before = train_cleaned_original[column].kurt()
#         kurtosis_after = train_cleaned_no_outliers[column].kurt()

#         # Print insights and recommended actions
#         if num_outliers > 0:
#             insight = f"The feature '{column}' had {num_outliers} outliers ({proportion_outliers:.2f}% of the data) which have been capped to the lower and upper bounds."
#             recommended_action = f"Review the impact of outlier handling on the distribution of '{column}'. Consider further analysis or feature transformation if necessary."
#         else:
#             insight = f"No significant outliers were detected for the feature '{column}'."
#             recommended_action = f"No action needed for outliers in '{column}'."

#         print(f"Insights for {column}: {insight}")
#         print(f"Proportion of Outliers: {proportion_outliers:.2f}%")
#         print(f"Skewness Before Handling Outliers: {skewness_before}, After: {skewness_after}")
#         print(f"Kurtosis Before Handling Outliers: {kurtosis_before}, After: {kurtosis_after}")
#         print(f"Recommended Actions for {column}: {recommended_action}")
#         print("\n" + "-"*80 + "\n")


# import numpy as np
# import pandas as pd
# from scipy.stats import zscore

# def log_transform(df, feature):
#     df[feature] = np.log1p(df[feature])
#     return df

# def sqrt_transform(df, feature):
#     df[feature] = np.sqrt(df[feature])
#     return df

# def clip_outliers(df, feature, lower_percentile=0.05, upper_percentile=0.95):
#     lower = df[feature].quantile(lower_percentile)
#     upper = df[feature].quantile(upper_percentile)
#     df[feature] = np.clip(df[feature], lower, upper)
#     return df

# def remove_outliers(df, feature, z_threshold=3):
#     df = df[(np.abs(zscore(df[feature])) < z_threshold)]
#     return df

# def apply_outlier_strategy(df, feature, strategy):
#     if strategy == 'Log Transformation':
#         return log_transform(df, feature)
#     elif strategy == 'Square Root Transformation':
#         return sqrt_transform(df, feature)
#     elif strategy == 'Clipping':
#         return clip_outliers(df, feature)
#     elif strategy == 'Removing Outliers':
#         return remove_outliers(df, feature)
#     return df



# # # src/feature_engineering/outliers.py

# # import numpy as np
# # import pandas as pd
# # from scipy.stats import zscore

# # def log_transform(df, feature):
# #     df[feature] = np.log1p(df[feature])
# #     return df

# # def sqrt_transform(df, feature):
# #     df[feature] = np.sqrt(df[feature])
# #     return df

# # def clip_outliers(df, feature, lower_percentile=0.01, upper_percentile=0.99):
# #     lower = df[feature].quantile(lower_percentile)
# #     upper = df[feature].quantile(upper_percentile)
# #     df[feature] = np.clip(df[feature], lower, upper)
# #     return df

# # def remove_outliers(df, feature, z_threshold=3):
# #     df = df[(np.abs(zscore(df[feature])) < z_threshold)]
# #     return df

