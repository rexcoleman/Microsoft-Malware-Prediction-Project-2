# src/feature_engineering/data_types.py

import os
import sys
import pandas as pd
import logging
from IPython.display import display, HTML
from tqdm.notebook import tqdm
from src.utils.file_operations import save_dataframe_with_progress, save_json_file
from src.utils.json_pipeline import save_json_with_pipeline
from src.utils.metadata_operations import extract_classified_data_type, extract_technical_data_type
from src.feature_engineering.utils import convert_data_types

def validate_data_types(data, metadata):
    logging.info("Starting data type validation")
    validation_errors = []
    
    for feature in metadata['features'].keys():
        if feature in data.columns:
            expected_dtype = extract_technical_data_type(metadata, feature)
            actual_dtype = str(data[feature].dtype)
            
            if expected_dtype and expected_dtype != actual_dtype:
                error_message = f"Feature '{feature}': Expected dtype technical_data_type '{expected_dtype}', but got dtype '{actual_dtype}'"
                validation_errors.append(error_message)
                logging.error(error_message)
            else:
                logging.info(f"Feature '{feature}': Data type '{actual_dtype}' matches the expected technical_data_type '{expected_dtype}'.")
    
    if not validation_errors:
        logging.info("Data type validation passed with no errors.")
    else:
        logging.warning("Data type validation found discrepancies.")
        for error in validation_errors:
            logging.warning(error)

    logging.info("Data type validation completed.")

# 


def save_processed_data(data, metadata, paths, data_type='train'):
    if data_type == 'train':
        processed_data_path = os.path.join(paths['data']['intermediate'], '01_clean_imputation_and_data_types_train.csv')
    else:
        processed_data_path = os.path.join(paths['data']['intermediate'], '01_clean_imputation_and_data_types_test.csv')
    
    save_dataframe_with_progress(data, processed_data_path)
    logging.info(f"Processed {data_type} data saved to {processed_data_path}")

    if os.path.isfile(processed_data_path):
        logging.info(f"Processed {data_type} data file {processed_data_path} exists.")
        saved_data = pd.read_csv(processed_data_path)
        logging.info(f"Processed {data_type} data file {processed_data_path} loaded for validation.")
        
        saved_data = convert_data_types(saved_data, metadata)
        validate_data_types(saved_data, metadata)
    else:
        logging.error(f"Processed {data_type} data file {processed_data_path} does not exist.")


def save_feature_data_types(train_data, paths):
    feature_data_types_path = os.path.join(paths['reports']['analysis_results'], 'feature_data_types.json')
    feature_data_types = {
        "features": {
            feature: {
                "general_attributes": {
                    "technical_data_type": str(train_data[feature].dtype)
                }
            }
            for feature in train_data.columns if not feature.endswith('_is_missing')
        }
    }
    save_json_with_pipeline(feature_data_types, feature_data_types_path)
    logging.info(f"Feature data types saved to {feature_data_types_path}")



def process_train_data(train_data, metadata, paths):
    # Replace 'nan' string with actual NaN value
    train_data.replace('nan', pd.NA, inplace=True)

    # Import drop_features and label_missing_values locally to avoid circular import
    from src.feature_engineering.feature_utils import drop_features, label_missing_values
    
    # Drop features flagged for dropping
    train_data, features_to_drop = drop_features(train_data, metadata)
    imputation_df = extract_imputation_data(metadata, features_to_drop)
    display(HTML(imputation_df.to_html(index=False)))

    # Convert data types before imputation
    train_data = convert_data_types(train_data, metadata)

    # Label missing values and store missing indicators
    logging.info(f"Columns in train_data before labeling missing values: {train_data.columns.tolist()}")
    train_data, essential_missing_indicators = label_missing_values(train_data, metadata, features_to_drop)
    logging.info(f"Essential missing indicators identified: {essential_missing_indicators}")
    
    # Save missing value indicator features for later use
    essential_missing_value_features = {
        "features": {
            feature: {
                "general_attributes": {
                    "technical_data_type": "int64",
                    "classified_data_type": "binary"
                }
            } for feature in essential_missing_indicators
        }
    }
    essential_missing_value_features_path = os.path.join(paths['reports']['analysis_results'], 'essential_missing_value_features.json')
    save_essential_missing_value_features(essential_missing_value_features, essential_missing_value_features_path)
    logging.info(f"Essential missing value features saved to {essential_missing_value_features_path}")

    # Store imputation values from train data
    imputation_values = {}
    train_data = impute_missing_values(train_data, metadata, features_to_drop, imputation_values=imputation_values, paths=paths, is_train=True)
    train_data = validate_and_impute(train_data, imputation_values)

    # Return the train data, imputation values, and essential missing indicators
    return train_data, imputation_values, essential_missing_indicators


def process_test_data(test_data, metadata, paths, imputation_values, essential_missing_indicators):
    # Replace 'nan' string with actual NaN value
    test_data.replace('nan', pd.NA, inplace=True)

    # Drop features flagged for dropping
    test_data, features_to_drop = drop_features(test_data, metadata)

    # Ensure missing value indicators are added to the test data
    for feature in essential_missing_indicators:
        if feature not in test_data.columns:
            test_data[feature] = 0  # Add the missing indicator column with all zeros if not present

    # Apply the stored imputation strategies from train data, excluding the target variable
    for feature in metadata['features'].keys():
        if feature != 'HasDetections' and feature in test_data.columns:
            test_data[feature] = test_data[feature].fillna(imputation_values.get(feature))
            # Handle the corresponding '_is_missing' feature
            missing_indicator = f"{feature}_is_missing"
            if missing_indicator in test_data.columns:
                test_data[missing_indicator] = test_data[missing_indicator].fillna(imputation_values.get(missing_indicator, 0))

    # Convert data types
    test_data = convert_data_types(test_data, metadata)

    return test_data




# def process_test_data(test_data, metadata, paths, imputation_values, essential_missing_indicators):
#     # Replace 'nan' string with actual NaN value
#     test_data.replace('nan', pd.NA, inplace=True)

#     # Drop features flagged for dropping
#     test_data, features_to_drop = drop_features(test_data, metadata)

#     # Ensure missing value indicators are added to the test data
#     for feature in essential_missing_indicators:
#         if feature not in test_data.columns:
#             test_data[feature] = 0  # Add the missing indicator column with all zeros if not present

#     # Apply the stored imputation strategies from train data, excluding the target variable
#     for feature in metadata['features'].keys():
#         if feature != 'HasDetections' and feature in test_data.columns:
#             test_data[feature] = test_data[feature].fillna(imputation_values.get(feature))
#             # Handle the corresponding '_is_missing' feature
#             missing_indicator = f"{feature}_is_missing"
#             if missing_indicator in test_data.columns:
#                 test_data[missing_indicator] = test_data[missing_indicator].fillna(imputation_values.get(missing_indicator, 0))

#     # Convert data types
#     test_data = convert_data_types(test_data, metadata)

#     return test_data




