# src/feature_engineering/missing_value_indicators.py

import os
import sys
import pandas as pd
import logging
from tqdm.notebook import tqdm
from typing import Tuple, List, Dict
from src.utils.metadata_operations import extract_missing_percentage, extract_imputation_strategy
from src.utils.json_pipeline import save_json_with_pipeline


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def create_missing_value_indicators(df: pd.DataFrame, metadata: dict) -> Tuple[pd.DataFrame, Dict[str, Dict[str, Dict[str, str]]]]:
    """
    Create missing value indicator features for columns with missing values where the missing percentage is >= 5% and 
    drop features with the imputation strategy set to "Drop". Also, prepare a dictionary for essential missing value features.

    Parameters:
    df (pd.DataFrame): The input DataFrame.
    metadata (dict): The metadata containing missing percentage and imputation strategy information.

    Returns:
    Tuple[pd.DataFrame, Dict[str, Dict[str, Dict[str, str]]]]: 
        - DataFrame with missing value indicators added and selected features dropped.
        - Dictionary for essential missing value features.
    """
    try:
        columns_to_drop = []
        essential_missing_value_features = {"features": {}}

        for column in tqdm(df.columns, desc="Processing columns"):
            imputation_strategy = extract_imputation_strategy(metadata, column)
            if imputation_strategy == "Drop":
                columns_to_drop.append(column)
                logging.info(f"Column '{column}' marked for dropping due to imputation strategy: {imputation_strategy}.")
                continue

            missing_percentage = extract_missing_percentage(metadata, column)
            if missing_percentage is not None and missing_percentage >= 5.0:
                if df[column].isnull().any():
                    indicator_column = f'{column}_is_missing'
                    df[indicator_column] = df[column].isnull().astype(int)
                    essential_missing_value_features["features"][indicator_column] = {
                        "general_attributes": {
                            "classified_data_type": "binary",
                            "technical_data_type": "int64"
                        },
                        "feature_engineering": {
                            "imputation": {
                                "comments": "",
                                "type": "most_frequent"  # Set the imputation type to 'most_frequent'
                            }
                        }
                    }
                    logging.info(f"Missing value indicator '{indicator_column}' created for '{column}' with {missing_percentage:.2f}% missing values.")

        # Log before dropping columns
        logging.info(f"Columns to be dropped: {columns_to_drop}")

        # Drop the columns with "Drop" strategy
        if columns_to_drop:
            df.drop(columns=columns_to_drop, inplace=True)
            logging.info(f"Dropped columns: {columns_to_drop}")
            # Log the remaining columns after the drop operation
            logging.info(f"Remaining columns after dropping: {df.columns.tolist()}")
            
            # Check if the columns were successfully dropped
            remaining_columns = set(df.columns)
            failed_to_drop = set(columns_to_drop).intersection(remaining_columns)
            if failed_to_drop:
                logging.error(f"Failed to drop the following columns: {failed_to_drop}")
                raise ValueError(f"Failed to drop the following columns: {failed_to_drop}")

        return df, essential_missing_value_features
    except Exception as e:
        logging.error(f"Error creating missing value indicators: {e}")
        raise


def save_essential_missing_value_features(essential_features: Dict[str, Dict[str, Dict[str, str]]], save_dir: str) -> None:
    """
    Save the essential missing value features to a JSON file.

    Parameters:
    essential_features (Dict[str, Dict[str, Dict[str, str]]]): The essential missing value features to save.
    save_dir (str): Directory to save the JSON file.
    """
    try:
        save_json_with_pipeline(essential_features, os.path.join(save_dir, 'essential_missing_value_features.json'))
        logging.info(f"Essential missing value features saved to '{save_dir}/essential_missing_value_features.json'")
    except Exception as e:
        logging.error(f"Error saving essential missing value features: {e}")
        raise
        

def validate_missing_value_indicators(df: pd.DataFrame) -> List[str]:
    """
    Validate the missing value indicator features in the DataFrame.

    Parameters:
    df (pd.DataFrame): The DataFrame with missing value indicators.

    Returns:
    List[str]: A list of indicator columns that failed validation.
    """
    failed_validations = []
    try:
        for column in df.columns:
            if column.endswith('_is_missing'):
                original_column = column.replace('_is_missing', '')
                # Check if the indicator matches the missing values in the original column
                if not df[column].equals(df[original_column].isnull().astype(int)):
                    logging.error(f"Validation failed for missing value indicator: {column}")
                    failed_validations.append(column)
        if not failed_validations:
            logging.info("All missing value indicators validated successfully.")
        return failed_validations
    except Exception as e:
        logging.error(f"Error during validation of missing value indicators: {e}")
        raise


# def create_data_overview_report(train_data: pd.DataFrame, test_data: pd.DataFrame, save_dir: str, step_name: str, report_file_name: str) -> None:
#     """
#     Create a JSON report for the data overview after each transformation step.

#     Parameters:
#     train_data (pd.DataFrame): The processed training data.
#     test_data (pd.DataFrame): The processed testing data.
#     save_dir (str): The directory where the JSON report should be saved.
#     step_name (str): The name of the transformation step (e.g., 'missing_values_indicators_added').
#     report_file_name (str): The name of the report file to save (e.g., 'data_overview.json').
#     """
#     try:
#         data_overview = {
#             "data_overview": {
#                 f"train_{step_name}_shape": list(train_data.shape),
#                 f"test_{step_name}_shape": list(test_data.shape),
#                 f"train_columns_{step_name}": train_data.columns.tolist(),
#                 f"test_columns_{step_name}": test_data.columns.tolist()
#             }
#         }

#         save_path = os.path.join(save_dir, report_file_name)
#         save_json_with_pipeline(data_overview, save_path)
#         logging.info(f"Data overview report saved to {save_path}")
#     except Exception as e:
#         logging.error(f"Error creating data overview report: {e}")
#         raise

# def create_data_overview_report(train_data: pd.DataFrame, test_data: pd.DataFrame, save_dir: str) -> None:
#     """
#     Create a JSON report for the data overview after adding missing value indicators.

#     Parameters:
#     train_data (pd.DataFrame): The processed training data.
#     test_data (pd.DataFrame): The processed testing data.
#     save_dir (str): The directory where the JSON report should be saved.
#     """
#     try:
#         data_overview = {
#             "data_overview": {
#                 "intermediate_01_train_missing_values_indicators_added_shape": list(train_data.shape),
#                 "intermediate_01_test_missing_values_indicators_added_shape": list(test_data.shape),
#                 "train_columns_intermediate_01_missing_values_indicators_added": train_data.columns.tolist(),
#                 "test_columns_intermediate_01_missing_values_indicators_added": test_data.columns.tolist()
#             }
#         }

#         save_path = os.path.join(save_dir, 'data_overview_missing_value_indicators.json')
#         save_json_with_pipeline(data_overview, save_path)
#         logging.info(f"Data overview report saved to {save_path}")
#     except Exception as e:
#         logging.error(f"Error creating data overview report: {e}")
#         raise

