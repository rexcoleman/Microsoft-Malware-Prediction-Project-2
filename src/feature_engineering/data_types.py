# src/feature_engineering/data_types.py

import pandas as pd
import logging
from tqdm.notebook import tqdm

def map_classified_to_technical(classified_type):
    """
    Map classified data types to technical data types.
    
    Parameters:
    classified_type (str): The classified data type (binary, numerical, categorical).
    
    Returns:
    str: The corresponding technical data type (int, float, object).
    """
    if classified_type == 'binary':
        return 'int64'  # Could also use 'bool' if preferred
    elif classified_type == 'numerical':
        return 'float64'  # Assume float for more flexibility
    elif classified_type == 'categorical':
        return 'object'
    else:
        return None


def convert_data_types(data, metadata):
    """
    Convert columns to their correct types based on classified data type in metadata.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with imputed values.
    - metadata (dict): Metadata containing feature information.

    Returns:
    - pd.DataFrame: DataFrame with converted data types.
    """
    for feature, details in tqdm(metadata['features'].items(), desc="Converting data types"):
        if feature in data.columns:
            classified_data_type = details.get('classified_data_type', None)
            technical_data_type = map_classified_to_technical(classified_data_type)
            
            if technical_data_type:
                try:
                    if technical_data_type == 'int64':
                        data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('int64')
                    elif technical_data_type == 'float64':
                        data[feature] = pd.to_numeric(data[feature], errors='coerce').astype('float64')
                    elif technical_data_type == 'object':
                        data[feature] = data[feature].astype(str)
                    elif technical_data_type == 'datetime':
                        data[feature] = pd.to_datetime(data[feature], errors='coerce')
                    logging.info(f"Converted feature '{feature}' to '{technical_data_type}'.")
                except Exception as e:
                    logging.error(f"Error converting feature '{feature}' to '{technical_data_type}': {e}")
            else:
                logging.warning(f"Technical data type not mapped for classified data type '{classified_data_type}' for feature '{feature}'")
        else:
            logging.warning(f"Feature '{feature}' not found in data.")
    return data


def save_feature_data_types(data, output_path):
    """
    Save the feature names and updated data types to a JSON file.
    
    Parameters:
    - data (pd.DataFrame): The DataFrame with processed data.
    - output_path (str): Path to save the feature data types JSON file.
    """
    feature_data_types = [
        {'Feature': feature, 'Technical Data Type': str(data[feature].dtype)}
        for feature in data.columns
    ]
    save_json_file(feature_data_types, output_path)


def validate_data_types(data, metadata):
    """
    Validate that data types of the DataFrame columns match the metadata specifications.

    Parameters:
    data (pd.DataFrame): The DataFrame to validate.
    metadata (dict): Metadata containing feature information.

    Returns:
    None
    """
    logging.info("Starting data type validation")
    validation_errors = []
    
    for feature, details in metadata['features'].items():
        if feature in data.columns:
            expected_dtype = details.get('technical_data_type', None)
            actual_dtype = str(data[feature].dtype)
            
            if expected_dtype and expected_dtype != actual_dtype:
                error_message = f"Feature '{feature}': Expected dtype technical_data_type '{expected_dtype}', but got dtype '{actual_dtype}'"
                validation_errors.append(error_message)
                logging.error(error_message)
            else:
                logging.info(f"Feature '{feature}': Data type dtype '{actual_dtype}' matches the expected technical_data_type type.")
    
    if not validation_errors:
        logging.info("Data type validation passed with no errors.")
    else:
        logging.warning("Data type validation found discrepancies.")
        for error in validation_errors:
            logging.warning(error)

    logging.info("Data type validation completed.")

