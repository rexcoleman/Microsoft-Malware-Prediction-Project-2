# src/data/data_preparation.py


import os
import yaml
import numpy as np
import pandas as pd
from src.config_loader import load_paths
from src.utils.data_loading_utils import read_csv_with_progress
from src.validation.validate_univariate_analysis import ensure_all_features_in_comparison_table

# from src.data.load_data import load_sample_data



def generate_sample_data(file_path, nrows=10000, stratify_by=None):
    """
    Generate a sample of the dataset with the specified number of rows.

    Args:
        file_path (str): Path to the dataset file.
        nrows (int): Number of rows for the sample.
        stratify_by (str, optional): Column to stratify the sample by.

    Returns:
        pd.DataFrame: Sampled data.
    """
    
    # Read the CSV file with progress feedback
    data = read_csv_with_progress(file_path, chunksize=10000)

    if stratify_by:
        unique_groups = data[stratify_by].unique()
        sampled_data = pd.DataFrame()

        for group in unique_groups:
            group_data = data[data[stratify_by] == group]
            sample_size = min(nrows // len(unique_groups), len(group_data))
            sampled_group_data = group_data.sample(sample_size, random_state=42)
            sampled_data = pd.concat([sampled_data, sampled_group_data])

        return sampled_data.sample(n=nrows, random_state=42)  # Shuffle the sampled data
    else:
        return data.sample(n=nrows, random_state=42)


def convert_to_native_types(data):
    """
    Convert numpy data types to native Python types.

    Parameters:
    data: Data to convert.

    Returns:
    Data converted to native Python types.
    """
    if isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif isinstance(data, dict):
        return {k: convert_to_native_types(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [convert_to_native_types(v) for v in data]
    else:
        return data


def prepare_feature_classification_comparison_table(train_sample, metadata):
    """
    Prepare the comparison table for manual review and update.

    Parameters:
    train_sample (pd.DataFrame): The training sample DataFrame.
    metadata (dict): Feature metadata.

    Returns:
    pd.DataFrame: Prepared comparison table.
    """
    try:
        output_dir = os.path.join('reports', 'manual_review_and_update')
        comparison_table_path = os.path.join(output_dir, 'feature_classification_manual_review_and_update.csv')
        comparison_table = create_or_load_comparison_table(train_sample, metadata, comparison_table_path)
        comparison_table = ensure_all_features_in_comparison_table(train_sample, comparison_table, metadata, comparison_table_path)

        # Check if 'Manual Review and Update' and 'Notes' columns exist before dropping
        columns_to_drop = [col for col in ['Manual Review and Update', 'Notes'] if col in comparison_table.columns]
        return comparison_table.drop(columns=columns_to_drop)
    except Exception as e:
        print(f"Error preparing comparison table: {e}")
        raise


def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
    """
    Create or load a comparison table for feature classification.

    Args:
        train_sample (pd.DataFrame): The training sample data.
        metadata (dict): Metadata for the features.
        comparison_table_path (str): Path to save/load the comparison table.

    Returns:
        pd.DataFrame: Comparison table for feature classification.
    """
    from src.analysis.univariate_analysis import create_comparison_table
    
    if not os.path.exists(comparison_table_path):
        comparison_table = create_comparison_table(train_sample, metadata)
        comparison_table.to_csv(comparison_table_path, index=False)
        print("\nManual review file created.")
    else:
        print("\nManual review file already exists. Skipping creation.")
        comparison_table = pd.read_csv(comparison_table_path)
    
    return comparison_table











# Existing functions...


# def load_and_prepare_data(nrows=10000):
#     """
#     Load and prepare the training data.

#     Args:
#         nrows (int): Number of rows to load from the sample data.

#     Returns:
#         pd.DataFrame: Loaded training sample data.
#     """
#     paths = load_paths()
#     processed_train_path = paths['data']['processed_train']

#     if not os.path.exists(processed_train_path):
#         print(f"{processed_train_path} not found. Generating from raw data...")
#         train_sample, _ = load_sample_data(nrows=nrows)
#         train_sample.to_csv(processed_train_path, index=False)
#     else:
#         train_sample = pd.read_csv(processed_train_path)
    
#     return train_sample

# def load_metadata(metadata_path):
#     """
#     Load metadata from a YAML file.

#     Args:
#         metadata_path (str): Path to the metadata file.

#     Returns:
#         dict: Loaded metadata.
#     """
#     with open(metadata_path, 'r') as file:
#         metadata = yaml.safe_load(file)
#     return metadata
































# # src/data/data_preparation.py

# import pandas as pd
# import os
# import yaml
# from src.data.load_data import load_sample_data, read_csv_with_progress
# from src.config_loader import load_paths

# def load_and_prepare_data(nrows=10000):
#     """
#     Load and prepare the training data.

#     Args:
#         nrows (int): Number of rows to load from the sample data.

#     Returns:
#         pd.DataFrame: Loaded training sample data.
#     """
#     paths = load_paths()
#     processed_train_path = paths['data']['processed_train']

#     if not os.path.exists(processed_train_path):
#         print(f"{processed_train_path} not found. Generating from raw data...")
#         train_sample, _ = load_sample_data(nrows=nrows)
#         train_sample.to_csv(processed_train_path, index=False)
#     else:
#         train_sample = pd.read_csv(processed_train_path)
    
#     return train_sample

# def load_metadata(metadata_path):
#     """
#     Load metadata from a YAML file.

#     Args:
#         metadata_path (str): Path to the metadata file.

#     Returns:
#         dict: Loaded metadata.
#     """
#     with open(metadata_path, 'r') as file:
#         metadata = yaml.safe_load(file)
#     return metadata

# def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
#     """
#     Create or load a comparison table for feature classification.

#     Args:
#         train_sample (pd.DataFrame): The training sample data.
#         metadata (dict): Metadata for the features.
#         comparison_table_path (str): Path to save/load the comparison table.

#     Returns:
#         pd.DataFrame: Comparison table for feature classification.
#     """
#     from src.analysis.univariate_analysis import create_comparison_table
    
#     if not os.path.exists(comparison_table_path):
#         comparison_table = create_comparison_table(train_sample, metadata)
#         comparison_table.to_csv(comparison_table_path, index=False)
#         print("\nManual review file created.")
#     else:
#         print("\nManual review file already exists. Skipping creation.")
#         comparison_table = pd.read_csv(comparison_table_path)
    
#     return comparison_table

# def prepare_feature_classification_comparison_table(train_sample, metadata):
#     """
#     Prepare the comparison table for manual review and update.

#     Parameters:
#     train_sample (pd.DataFrame): The training sample DataFrame.
#     metadata (dict): Feature metadata.

#     Returns:
#     pd.DataFrame: Prepared comparison table.
#     """
#     try:
#         output_dir = os.path.join('reports', 'manual_review_and_update')
#         comparison_table_path = os.path.join(output_dir, 'feature_classification_manual_review_and_update.csv')
#         comparison_table = create_or_load_comparison_table(train_sample, metadata, comparison_table_path)
#         comparison_table = ensure_all_features_in_comparison_table(train_sample, comparison_table, metadata, comparison_table_path)

#         # Check if 'Manual Review and Update' and 'Notes' columns exist before dropping
#         columns_to_drop = [col for col in ['Manual Review and Update', 'Notes'] if col in comparison_table.columns]
#         return comparison_table.drop(columns=columns_to_drop)
#     except Exception as e:
#         print(f"Error preparing comparison table: {e}")
#         raise





# # # src/data/data_preparation.py

# # import pandas as pd
# # import os
# # import yaml
# # from src.data.load_data import load_sample_data, read_csv_with_progress
# # from src.config_loader import load_paths

# # def load_and_prepare_data(nrows=10000):
# #     """
# #     Load and prepare the training data.

# #     Args:
# #         nrows (int): Number of rows to load from the sample data.

# #     Returns:
# #         pd.DataFrame: Loaded training sample data.
# #     """
# #     paths = load_paths()
# #     processed_train_path = paths['data']['processed_train']

# #     if not os.path.exists(processed_train_path):
# #         print(f"{processed_train_path} not found. Generating from raw data...")
# #         train_sample, _ = load_sample_data(nrows=nrows)
# #         train_sample.to_csv(processed_train_path, index=False)
# #     else:
# #         train_sample = pd.read_csv(processed_train_path)
    
# #     return train_sample

# # def load_metadata(metadata_path):
# #     """
# #     Load metadata from a YAML file.

# #     Args:
# #         metadata_path (str): Path to the metadata file.

# #     Returns:
# #         dict: Loaded metadata.
# #     """
# #     with open(metadata_path, 'r') as file:
# #         metadata = yaml.safe_load(file)
# #     return metadata

# # def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
# #     """
# #     Create or load a comparison table for feature classification.

# #     Args:
# #         train_sample (pd.DataFrame): The training sample data.
# #         metadata (dict): Metadata for the features.
# #         comparison_table_path (str): Path to save/load the comparison table.

# #     Returns:
# #         pd.DataFrame: Comparison table for feature classification.
# #     """
# #     from src.analysis.univariate_analysis import create_comparison_table
    
# #     if not os.path.exists(comparison_table_path):
# #         comparison_table = create_comparison_table(train_sample, metadata)
# #         comparison_table.to_csv(comparison_table_path, index=False)
# #         print("\nManual review file created.")
# #     else:
# #         print("\nManual review file already exists. Skipping creation.")
# #         comparison_table = pd.read_csv(comparison_table_path)
    
# #     return comparison_table

# # def generate_sample_data(file_path, nrows=10000, stratify_by=None):
# #     """
# #     Generate a sample of the dataset with the specified number of rows.

# #     Args:
# #         file_path (str): Path to the dataset file.
# #         nrows (int): Number of rows for the sample.
# #         stratify_by (str, optional): Column to stratify the sample by.

# #     Returns:
# #         pd.DataFrame: Sampled data.
# #     """
# #     data = read_csv_with_progress(file_path, chunksize=10000)
# #     if stratify_by:
# #         sample_data = data.groupby(stratify_by, group_keys=False).apply(
# #             lambda x: x.sample(min(len(x), nrows // len(data[stratify_by].unique())), random_state=42)
# #         ).sample(n=nrows, random_state=42)
# #     else:
# #         sample_data = data.sample(n=nrows, random_state=42)
# #     return sample_data

# # def main():
# #     """
# #     Main function to execute data preparation steps.
# #     """
# #     try:
# #         paths = load_paths()
# #         metadata_path = paths['config']['metadata']
# #         comparison_table_path = paths['results']['comparison_table']
        
# #         train_sample = load_and_prepare_data()
# #         metadata = load_metadata(metadata_path)
# #         comparison_table = create_or_load_comparison_table(train_sample, metadata, comparison_table_path)

# #         # Additional processing or analysis can be added here

# #     except Exception as e:
# #         print(f"Error in main function: {e}")

# # if __name__ == "__main__":
# #     main()




# # # # src/data/data_preparation.py

# # # import pandas as pd
# # # import os
# # # import yaml
# # # from src.data.load_data import load_sample_data, read_csv_with_progress
# # # from src.config_loader import load_paths

# # # def load_and_prepare_data(nrows=10000):
# # #     paths = load_paths()
# # #     processed_train_path = paths['data']['processed_train']

# # #     if not os.path.exists(processed_train_path):
# # #         print(f"{processed_train_path} not found. Generating from raw data...")
# # #         train_sample, _ = load_sample_data(nrows=nrows)
# # #         train_sample.to_csv(processed_train_path, index=False)
# # #     else:
# # #         train_sample = pd.read_csv(processed_train_path)
    
# # #     return train_sample

# # # def load_metadata(metadata_path):
# # #     with open(metadata_path, 'r') as file:
# # #         metadata = yaml.safe_load(file)
# # #     return metadata

# # # def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
# # #     from src.analysis.univariate_analysis import create_comparison_table
    
# # #     if not os.path.exists(comparison_table_path):
# # #         comparison_table = create_comparison_table(train_sample, metadata)
# # #         comparison_table.to_csv(comparison_table_path, index=False)
# # #         print("\nManual review file created.")
# # #     else:
# # #         print("\nManual review file already exists. Skipping creation.")
# # #         comparison_table = pd.read_csv(comparison_table_path)
    
# # #     return comparison_table

# # # def generate_sample_data(file_path, nrows=10000, stratify_by=None):
# # #     """Generate a sample of the dataset with the specified number of rows."""
# # #     data = read_csv_with_progress(file_path, chunksize=10000)
# # #     if stratify_by:
# # #         sample_data = data.groupby(stratify_by, group_keys=False).apply(lambda x: x.sample(min(len(x), nrows // len(data[stratify_by].unique())), random_state=42)).sample(n=nrows, random_state=42)
# # #     else:
# # #         sample_data = data.sample(n=nrows, random_state=42)
# # #     return sample_data




# # # # # src/data/data_preparation.py

# # # # import pandas as pd
# # # # import os
# # # # import yaml
# # # # from sklearn.model_selection import train_test_split
# # # # from src.data.load_data import load_sample_data, read_csv_with_progress
# # # # from src.config_loader import load_paths

# # # # def load_and_prepare_data(nrows=10000):
# # # #     paths = load_paths()
# # # #     processed_train_path = paths['data']['processed_train']

# # # #     if not os.path.exists(processed_train_path):
# # # #         print(f"{processed_train_path} not found. Generating from raw data...")
# # # #         train_sample, _ = load_sample_data(nrows=nrows)
# # # #         train_sample.to_csv(processed_train_path, index=False)
# # # #     else:
# # # #         train_sample = pd.read_csv(processed_train_path)
    
# # # #     return train_sample

# # # # def load_metadata(metadata_path='config/feature_metadata.yaml'):
# # # #     with open(metadata_path, 'r') as file:
# # # #         metadata = yaml.safe_load(file)
# # # #     return metadata

# # # # def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
# # # #     from src.analysis.univariate_analysis import create_comparison_table
    
# # # #     if not os.path.exists(comparison_table_path):
# # # #         comparison_table = create_comparison_table(train_sample, metadata)
# # # #         comparison_table.to_csv(comparison_table_path, index=False)
# # # #         print("\nManual review file created.")
# # # #     else:
# # # #         print("\nManual review file already exists. Skipping creation.")
# # # #         comparison_table = pd.read_csv(comparison_table_path)
    
# # # #     return comparison_table

# # # # def generate_sample_data(file_path, nrows=10000, stratify_by=None):
# # # #     """Generate a sample of the dataset with the specified number of rows."""
# # # #     data = read_csv_with_progress(file_path, chunksize=10000)
# # # #     if stratify_by:
# # # #         sample_data, _ = train_test_split(data, train_size=nrows, stratify=data[stratify_by], random_state=42)
# # # #     else:
# # # #         sample_data = data.sample(n=nrows, random_state=42)
# # # #     return sample_data










# # # # # src/data/data_preparation.py

# # # # import pandas as pd
# # # # import os
# # # # import yaml
# # # # from sklearn.model_selection import train_test_split
# # # # from src.data.load_data import load_sample_data, read_csv_with_progress
# # # # from src.config_loader import load_paths

# # # # def load_and_prepare_data(nrows=10000):
# # # #     """Load and prepare the training data."""
# # # #     paths = load_paths()
# # # #     processed_train_path = paths['data']['processed_train']

# # # #     if not os.path.exists(processed_train_path):
# # # #         print(f"{processed_train_path} not found. Generating from raw data...")
# # # #         train_sample, _ = load_sample_data(nrows=nrows)
# # # #         train_sample.to_csv(processed_train_path, index=False)
# # # #     else:
# # # #         train_sample = pd.read_csv(processed_train_path)
    
# # # #     return train_sample

# # # # def load_metadata(metadata_path='config/feature_metadata.yaml'):
# # # #     with open(metadata_path, 'r') as file:
# # # #         metadata = yaml.safe_load(file)
# # # #     return metadata

# # # # def create_or_load_comparison_table(train_sample, metadata, comparison_table_path):
# # # #     from src.analysis.univariate_analysis import create_comparison_table
    
# # # #     if not os.path.exists(comparison_table_path):
# # # #         comparison_table = create_comparison_table(train_sample, metadata)
# # # #         comparison_table.to_csv(comparison_table_path, index=False)
# # # #         print("\nManual review file created.")
# # # #     else:
# # # #         print("\nManual review file already exists. Skipping creation.")
# # # #         comparison_table = pd.read_csv(comparison_table_path)
    
# # # #     return comparison_table

# # # # def generate_sample_data(file_path, nrows=10000, stratify_by=None):
# # # #     """Generate a sample of the dataset with the specified number of rows, optionally stratified by a target variable."""
# # # #     data = read_csv_with_progress(file_path, chunksize=10000)
# # # #     if stratify_by and stratify_by in data.columns:
# # # #         _, sample_data = train_test_split(data, train_size=nrows, stratify=data[stratify_by], random_state=42)
# # # #     else:
# # # #         sample_data = data.sample(n=nrows, random_state=42)
# # # #     return sample_data
