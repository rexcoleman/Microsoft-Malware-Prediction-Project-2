# src/data/data_analysis.py

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def generate_summary_statistics(df):
    """
    Generate summary statistics for the dataframe.

    Parameters:
    - df (DataFrame): The dataframe to analyze.

    Returns:
    - DataFrame: Summary statistics.
    """
    summary_stats = df.describe(include='all').transpose()
    summary_stats['missing_values'] = df.isnull().sum()
    summary_stats['missing_percentage'] = (summary_stats['missing_values'] / len(df)) * 100
    summary_stats['dtype'] = df.dtypes
    return summary_stats

def plot_correlation_heatmap(df, target_col='HasDetections'):
    """
    Plot a correlation heatmap for the dataframe.

    Parameters:
    - df (DataFrame): The dataframe to analyze.
    - target_col (str): The target column for correlation analysis.

    Returns:
    - DataFrame: Correlation matrix.
    """
    plt.figure(figsize=(12, 8))
    corr_matrix = df.corr()
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
    plt.title('Correlation Matrix')
    plt.show()
    return corr_matrix

def suggest_imputation_strategy(summary_stats, corr_matrix, target_col='HasDetections'):
    """
    Suggest imputation strategies based on summary statistics and correlation matrix.

    Parameters:
    - summary_stats (DataFrame): Summary statistics.
    - corr_matrix (DataFrame): Correlation matrix.
    - target_col (str): The target column for correlation analysis.

    Returns:
    - dict: Suggested imputation strategies.
    """
    strategies = {}
    for column in summary_stats.index:
        if summary_stats.loc[column, 'missing_values'] > 0:
            if summary_stats.loc[column, 'dtype'] in ['float64', 'int64']:
                if abs(corr_matrix[target_col].get(column, 0)) > 0.1:
                    strategies[column] = 'median'  # For numerical columns with significant correlation, use median
                else:
                    strategies[column] = 'mean'    # For numerical columns with low correlation, use mean
            else:
                strategies[column] = 'mode'        # For categorical columns, use mode
    return strategies

def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
    """
    Save the analysis results to files.

    Parameters:
    - train_summary_stats (DataFrame): Summary statistics for the training data.
    - test_summary_stats (DataFrame): Summary statistics for the test data.
    - imputation_strategies (dict): Suggested imputation strategies.
    - report_dir (str): Directory to save the report files.
    """
    train_summary_stats.to_csv(f'{report_dir}/train_summary_statistics.csv')
    test_summary_stats.to_csv(f'{report_dir}/test_summary_statistics.csv')

    with open(f'{report_dir}/imputation_strategies.yaml', 'w') as file:
        yaml.dump(imputation_strategies, file)

def plot_univariate_analysis(df):
    """
    Perform univariate analysis by plotting the distribution of each feature.

    Parameters:
    - df (DataFrame): The dataframe to analyze.
    """
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns
    categorical_features = df.select_dtypes(include=['object']).columns

    # Plot numeric features
    for feature in numeric_features:
        if not df[feature].empty:
            plt.figure(figsize=(10, 6))
            sns.histplot(df[feature].dropna(), kde=True)
            plt.title(f'Distribution of {feature}')
            plt.show()

    # Plot categorical features
    for feature in categorical_features:
        if not df[feature].empty and not df[feature].value_counts().empty:
            plt.figure(figsize=(10, 6))
            df[feature].value_counts().plot(kind='bar')
            plt.title(f'Distribution of {feature}')
            plt.show()

def plot_bivariate_analysis(df, target_col):
    """
    Perform bivariate and multivariate analysis by plotting relationships between features and the target variable.

    Parameters:
    - df (DataFrame): The dataframe to analyze.
    - target_col (str): The target column.
    """
    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns

    for feature in numeric_features:
        if feature != target_col and not df[feature].empty:
            plt.figure(figsize=(10, 6))
            sns.boxplot(x=target_col, y=feature, data=df)
            plt.title(f'{feature} vs {target_col}')
            plt.show()

def plot_time_series_analysis(df):
    """
    Perform time series analysis by plotting time-related features.

    Parameters:
    - df (DataFrame): The dataframe to analyze.
    """
    time_features = [col for col in df.columns if 'Date' in col or 'Time' in col]

    for feature in time_features:
        df[feature] = pd.to_datetime(df[feature], errors='coerce')
        if not df[feature].dropna().empty:
            plt.figure(figsize=(10, 6))
            df.groupby(df[feature].dt.to_period("M")).size().plot()
            plt.title(f'Time Series Analysis of {feature}')
            plt.show()




# # src/data/data_analysis.py

# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as plt
# import yaml

# def generate_summary_statistics(df):
#     summary_stats = df.describe(include='all').transpose()
#     summary_stats['missing_values'] = df.isnull().sum()
#     summary_stats['missing_percentage'] = (summary_stats['missing_values'] / len(df)) * 100
#     summary_stats['dtype'] = df.dtypes
#     return summary_stats

# def plot_correlation_heatmap(df, target_col='HasDetections'):
#     plt.figure(figsize=(12, 8))
#     numeric_df = df.select_dtypes(include=['float64', 'int64'])
#     corr_matrix = numeric_df.corr()
#     sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
#     plt.title('Correlation Matrix')
#     plt.show()
#     return corr_matrix

# def suggest_imputation_strategy(summary_stats, corr_matrix, target_col='HasDetections', correlation_threshold=0.1):
#     strategies = {}
#     for column in summary_stats.index:
#         if summary_stats.loc[column, 'missing_values'] > 0:
#             if summary_stats.loc[column, 'dtype'] in ['float64', 'int64']:
#                 correlation = abs(corr_matrix[target_col].get(column, 0))
#                 if correlation > correlation_threshold:
#                     print(f"Using median for {column} due to high correlation: {correlation}")
#                     strategies[column] = 'median'  # For numerical columns with significant correlation, use median
#                 else:
#                     print(f"Using mean for {column} due to low correlation: {correlation}")
#                     strategies[column] = 'mean'  # For numerical columns without significant correlation, use mean
#             else:
#                 print(f"Using mode for {column} as it is categorical")
#                 strategies[column] = 'mode'  # For categorical columns, use mode
#     return strategies

# def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
#     train_summary_stats.to_csv(f"{report_dir}/train_summary_stats.csv", index=True)
#     test_summary_stats.to_csv(f"{report_dir}/test_summary_stats.csv", index=True)
    
#     with open(f"{report_dir}/imputation_strategies.yaml", 'w') as file:
#         yaml.dump({"imputation_strategies": imputation_strategies}, file)



