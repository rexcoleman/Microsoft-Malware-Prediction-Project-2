# # src/data/load_data.py

# import pandas as pd
# from src.config_loader import load_paths
# from src.utils.data_loading_utils import read_csv_with_progress

# def load_sample_data(nrows=None):
#     """
#     Load a sample of the training and test data.

#     Args:
#         nrows (int, optional): Number of rows to load from the sample data. Defaults to None.

#     Returns:
#         tuple: A tuple containing the training sample and test sample dataframes.
#     """
#     paths = load_paths()
#     train_sample = pd.read_csv(paths['data']['raw_train'], nrows=nrows, low_memory=False)
#     test_sample = pd.read_csv(paths['data']['raw_test'], nrows=nrows, low_memory=False)
#     return train_sample, test_sample





















# def load_data(file_path, dtype_spec=None):
#     """
#     Load data from a CSV file with optional data type specification.

#     Args:
#         file_path (str): Path to the CSV file to load.
#         dtype_spec (dict, optional): Dictionary specifying the data types for the columns. Defaults to None.

#     Returns:
#         pd.DataFrame: Loaded data as a DataFrame.
#     """
#     try:
#         return pd.read_csv(file_path, dtype=dtype_spec, low_memory=False)
#     except pd.errors.ParserError as e:
#         print(f"Parser error while loading data from {file_path}: {e}")
#         raise
#     except Exception as e:
#         print(f"Error while loading data from {file_path}: {e}")
#         raise

# def main():
#     """
#     Main function to execute data loading steps.
#     """
#     try:
#         # Example usage of the load_sample_data function
#         train_sample, test_sample = load_sample_data(nrows=10000)
#         print(f"Loaded train sample with shape: {train_sample.shape}")
#         print(f"Loaded test sample with shape: {test_sample.shape}")

#         # Example usage of the load_data function
#         dtype_spec = {'column_name': 'data_type'}  # Adjust as needed
#         data = load_data('path/to/your/file.csv', dtype_spec=dtype_spec)
#         print(f"Loaded data with shape: {data.shape}")

#     except Exception as e:
#         print(f"Error in main function: {e}")

# if __name__ == "__main__":
#     main()
















# # # src/data/load_data.py

# # import pandas as pd
# # from tqdm.notebook import tqdm
# # from src.config_loader import load_paths
# # from sklearn.model_selection import train_test_split

# # def read_csv_with_progress(file_path, chunksize=10000):
# #     total_lines = sum(1 for _ in open(file_path)) - 1  # Calculate total lines in the file
# #     chunk_list = []
# #     for chunk in tqdm(pd.read_csv(file_path, chunksize=chunksize, low_memory=False), total=total_lines//chunksize + 1, desc="Loading data"):
# #         chunk_list.append(chunk)
# #     return pd.concat(chunk_list, axis=0)

# # def load_sample_data(nrows=None):
# #     paths = load_paths()
# #     train_sample = pd.read_csv(paths['data']['raw_train'], nrows=nrows, low_memory=False)
# #     test_sample = pd.read_csv(paths['data']['raw_test'], nrows=nrows, low_memory=False)
# #     return train_sample, test_sample

# # def detect_mixed_types(df):
# #     mixed_type_columns = []
# #     for column in df.columns:
# #         unique_types = df[column].apply(type).unique()
# #         if len(unique_types) > 1:
# #             mixed_type_columns.append((column, unique_types))
# #     return mixed_type_columns

# # def clean_mixed_types(df, mixed_type_columns):
# #     for column, types in mixed_type_columns:
# #         df[column] = df[column].astype(str).replace('nan', 'Unknown')
# #     return df

# # def load_data(file_path, dtype_spec=None):
# #     return pd.read_csv(file_path, dtype=dtype_spec, low_memory=False)




