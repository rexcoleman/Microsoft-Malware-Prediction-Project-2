# src/data/load_data.py

import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from config_loader import load_config, get_feature_metadata

def load_data(file_path, nrows=None, chunksize=10000, dtype=None):
    """
    Load data from a CSV file with a progress bar. Optionally load a random sample.

    Parameters:
    - file_path (str): The path to the CSV file.
    - nrows (int): Number of rows to read. Reads all rows if None.
    - chunksize (int): Size of the chunks to read at a time.
    - dtype (dict): Dictionary of column data types.

    Returns:
    - DataFrame: Loaded data.
    """
    if dtype is None:
        # Load dtype from feature metadata if not provided
        config = load_config('../config/feature_metadata.yaml')
        feature_metadata = get_feature_metadata(config)
        dtype = {feature: feature_metadata[feature]['data_type'] for feature in feature_metadata}

    if nrows is not None:
        # Calculate the number of chunks to read
        chunks = []
        with pd.read_csv(file_path, chunksize=chunksize, dtype=dtype) as reader:
            for i, chunk in enumerate(tqdm(reader, desc=f"Loading {file_path}")):
                chunks.append(chunk)
                if len(chunks) * chunksize >= nrows:
                    break
        data = pd.concat(chunks, ignore_index=True)
        return data.sample(n=nrows)

    # Use chunksize to load data in chunks with a progress bar
    chunks = []
    with pd.read_csv(file_path, chunksize=chunksize, dtype=dtype) as reader:
        for chunk in tqdm(reader, desc=f"Loading {file_path}"):
            chunks.append(chunk)
    return pd.concat(chunks, ignore_index=True)

def sample_data(df, n_samples=10000, random_state=42, stratify_col=None):
    """
    Sample the dataframe with a progress bar.

    Parameters:
    - df (DataFrame): The dataframe to sample from.
    - n_samples (int): The number of samples to draw.
    - random_state (int): Random seed for reproducibility.
    - stratify_col (str): Column name to stratify the sample by.

    Returns:
    - DataFrame: Sampled data.
    """
    if stratify_col:
        _, sample = train_test_split(df, test_size=n_samples, random_state=random_state, stratify=df[stratify_col])
        return sample
    return df.sample(n=n_samples, random_state=random_state)
