# src/data/load_data.py

import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split

def load_data(file_path, nrows=None, chunksize=10000):
    """
    Load data from a CSV file with a progress bar. Optionally load a random sample.

    Parameters:
    - file_path (str): The path to the CSV file.
    - nrows (int): Number of rows to read. Reads all rows if None.
    - chunksize (int): Size of the chunks to read at a time.

    Returns:
    - DataFrame: Loaded data.
    """
    tqdm.pandas(desc="Loading data")
    
    if nrows is not None:
        # Calculate the number of chunks to read
        chunks = []
        total_chunks = (nrows // chunksize) + 1
        with pd.read_csv(file_path, chunksize=chunksize) as reader:
            for chunk in tqdm(reader, desc=f"Loading {file_path}", total=total_chunks):
                chunks.append(chunk)
                if len(chunks) * chunksize >= nrows:
                    break
        data = pd.concat(chunks, ignore_index=True)
        return data.sample(n=nrows)

    # Use chunksize to load data in chunks with a progress bar
    chunks = []
    with pd.read_csv(file_path, chunksize=chunksize) as reader:
        for chunk in tqdm(reader, desc=f"Loading {file_path}"):
            chunks.append(chunk)
    return pd.concat(chunks, ignore_index=True)

def sample_data(df, n_samples=10000, random_state=42, stratify_col=None):
    """
    Sample the dataframe with a progress bar.

    Parameters:
    - df (DataFrame): The dataframe to sample from.
    - n_samples (int): The number of samples to draw.
    - random_state (int): Random seed for reproducibility.
    - stratify_col (str): Column name to stratify the sample by.

    Returns:
    - DataFrame: Sampled data.
    """
    if stratify_col:
        _, sample = train_test_split(df, test_size=n_samples, random_state=random_state, stratify=df[stratify_col])
        return sample
    return df.sample(n=n_samples, random_state=random_state)





# # src/data/load_data.py

# import pandas as pd
# from tqdm import tqdm
# from sklearn.model_selection import train_test_split

# def load_data(file_path, nrows=None, chunksize=10000):
#     """
#     Load data from a CSV file with a progress bar. Optionally load a random sample.

#     Parameters:
#     - file_path (str): The path to the CSV file.
#     - nrows (int): Number of rows to read. Reads all rows if None.
#     - chunksize (int): Size of the chunks to read at a time.

#     Returns:
#     - DataFrame: Loaded data.
#     """
#     if nrows is not None:
#         # Calculate the number of chunks to read
#         chunks = []
#         with pd.read_csv(file_path, chunksize=chunksize) as reader:
#             for i, chunk in enumerate(tqdm(reader, desc=f"Loading {file_path}")):
#                 chunks.append(chunk)
#                 if len(chunks) * chunksize >= nrows:
#                     break
#         data = pd.concat(chunks, ignore_index=True)
#         return data.sample(n=nrows)

#     # Use chunksize to load data in chunks with a progress bar
#     chunks = []
#     with pd.read_csv(file_path, chunksize=chunksize) as reader:
#         for chunk in tqdm(reader, desc=f"Loading {file_path}"):
#             chunks.append(chunk)
#     return pd.concat(chunks, ignore_index=True)

# def sample_data(df, n_samples=10000, random_state=42, stratify_col=None):
#     """
#     Sample the dataframe with a progress bar.

#     Parameters:
#     - df (DataFrame): The dataframe to sample from.
#     - n_samples (int): The number of samples to draw.
#     - random_state (int): Random seed for reproducibility.
#     - stratify_col (str): Column name to stratify the sample by.

#     Returns:
#     - DataFrame: Sampled data.
#     """
#     if stratify_col:
#         _, sample = train_test_split(df, test_size=n_samples, random_state=random_state, stratify=df[stratify_col])
#         return sample
#     return df.sample(n=n_samples, random_state=random_state)
