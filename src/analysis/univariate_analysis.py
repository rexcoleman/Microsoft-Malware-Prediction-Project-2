# src/analysis/univariate_analysis.py

import os
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
from typing import Dict, List
from src.visualization.eda import plot_histogram, plot_boxplot, plot_kde, plot_countplot, plot_piechart, plot_binary_feature
from src.utils.metadata_operations import determine_feature_type

def create_comparison_table(dataframe: pd.DataFrame, metadata: Dict) -> pd.DataFrame:
    """
    Create a comparison table of features' classified types and determined types.

    Parameters:
    dataframe (pd.DataFrame): The DataFrame containing the data.
    metadata (dict): The metadata containing feature information.

    Returns:
    pd.DataFrame: The comparison table with feature types and discrepancies.
    """
    comparison_data = []
    for feature in dataframe.columns:
        classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
        determined_type = determine_feature_type(feature, metadata)
        discrepancy = classified_type != determined_type
        comparison_data.append({
            'Feature': feature,
            'Previously Analyzed Type': classified_type,
            'Current Analyzed Type': determined_type,
            'Discrepancy': discrepancy,
            'Manual Review and Update': determined_type  # Initialize with current analyzed type
        })
    comparison_table = pd.DataFrame(comparison_data)
    comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
    return comparison_table


def save_summary_statistics(dataframe: pd.DataFrame, feature: str, summary_output_dir: str) -> None:
    """
    Save summary statistics and value counts for the given feature to CSV files.

    Parameters:
    dataframe (pd.DataFrame): The DataFrame containing the data.
    feature (str): The feature to analyze.
    summary_output_dir (str): Directory to save the summary statistics and value counts.
    """
    summary_stats = dataframe[feature].describe().to_frame(name='Summary_Statistics')
    summary_stats_path = os.path.join(summary_output_dir, f'{feature}_summary.csv')
    summary_stats.to_csv(summary_stats_path)

    non_missing_data = dataframe[feature].dropna()
    value_counts = non_missing_data.value_counts().to_frame(name='Count')
    value_counts['Percentage'] = (value_counts['Count'] / dataframe[feature].size) * 100
    value_counts_path = os.path.join(summary_output_dir, f'{feature}_value_counts.csv')
    value_counts.to_csv(value_counts_path)


def plot_feature_analysis(dataframe: pd.DataFrame, feature: str, feature_type: str, labels: List[str], sizes: List[float], unique_value_threshold: int, figure_dir: str) -> None:
    """
    Plot various analyses for a given feature.

    Parameters:
    dataframe (pd.DataFrame): The DataFrame containing the data.
    feature (str): The feature to analyze.
    feature_type (str): The type of the feature (categorical or numerical).
    labels (list): Labels for the pie chart.
    sizes (list): Sizes for the pie chart.
    unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
    figure_dir (str): Directory to save the figures.
    """
    fig, axs = plt.subplots(3, 2, figsize=(18, 24))
    axs = axs.flatten()

    if feature_type == 'categorical' or dataframe[feature].nunique() < unique_value_threshold:
        # Treat as categorical
        plot_countplot(dataframe, feature, axs[0])
        plot_piechart(labels, sizes, axs[1], feature)
    else:
        # Treat as numerical
        plot_histogram(dataframe, feature, axs[0])
        plot_boxplot(dataframe, feature, axs[1])
        plot_kde(dataframe, feature, axs[2])

    # Always include binary feature plot
    if dataframe[feature].nunique() == 2:
        plot_binary_feature(dataframe, feature, axs[3])

    # Include both categorical and numerical plots for features with numerical values but many unique categories
    if feature_type == 'numerical' and dataframe[feature].nunique() > unique_value_threshold:
        plot_countplot(dataframe, feature, axs[4])
        plot_piechart(labels, sizes, axs[5], feature)

    plt.tight_layout()
    plt.savefig(f'{figure_dir}/{feature}_analysis.png')
    plt.show()


def contextual_insights_and_recommendations(dataframe: pd.DataFrame, feature: str, feature_type: str, summary_stats: pd.DataFrame, value_counts: pd.DataFrame, unique_value_threshold: int) -> None:
    """
    Print contextual insights and recommendations based on feature analysis.

    Parameters:
    dataframe (pd.DataFrame): The DataFrame containing the data.
    feature (str): The feature to analyze.
    feature_type (str): The type of the feature (categorical or numerical).
    summary_stats (pd.DataFrame): The summary statistics of the feature.
    value_counts (pd.DataFrame): The value counts of the feature.
    unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
    """
    print(f"\nSummary Statistics for {feature}:\n{summary_stats}")
    print(f"\nValue Counts for {feature}:\n{value_counts}")

    print("\n--- Contextual Insights and Recommendations ---\n")
    try:
        if feature_type != 'categorical' and dataframe[feature].nunique() >= unique_value_threshold:
            mean = summary_stats.loc['mean'].values[0]
            std = summary_stats.loc['std'].values[0]
            count = summary_stats.loc['count'].values[0]
            min_val = summary_stats.loc['min'].values[0]
            max_val = summary_stats.loc['max'].values[0]
            print(f"High-Level Overview: {feature} has a mean of {mean} and a standard deviation of {std}.")
            print(f"Detailed Technical Insights: The distribution of {feature} shows {count} instances with a range from {min_val} to {max_val}.")
            print("Actionable Recommendations: Use this information to identify potential outliers and decide on normalization or transformation techniques.")
        else:
            unique_categories = value_counts.shape[0]
            most_frequent = value_counts.index[0]
            print(f"High-Level Overview: {feature} has {unique_categories} unique categories with the most frequent category being {most_frequent}.")
            print("Detailed Technical Insights: The distribution shows a clear dominance of certain categories which may influence model training.")
            print("Actionable Recommendations: Consider encoding techniques and assess the impact of dominant categories on the target variable.")
    except KeyError as e:
        print(f"An error occurred while processing feature {feature}: {e}")


def univariate_analysis(dataframe: pd.DataFrame, paths: Dict, metadata: Dict, comparison_table: pd.DataFrame, unique_value_threshold: int = 20) -> None:
    """
    Perform univariate analysis on the features of the DataFrame.

    Parameters:
    dataframe (pd.DataFrame): The DataFrame containing the data.
    paths (dict): The paths and directories for the project.
    metadata (dict): The metadata containing feature information.
    comparison_table (pd.DataFrame): The comparison table with feature types and discrepancies.
    unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
    """
    output_dir = paths['reports']['univariate_analysis']
    figure_dir = os.path.join(output_dir, 'figures', 'univariate_analysis', '01_univariate_analysis')
    table_dir = os.path.join(output_dir, 'tables', 'univariate_analysis', '01_univariate_analysis')
    os.makedirs(figure_dir, exist_ok=True)
    os.makedirs(table_dir, exist_ok=True)

    all_features = dataframe.columns
    for feature in all_features:
        feature_type = determine_feature_type(feature, metadata)
        missing_count = metadata['features'][feature]['missing_values']['count']
        total_count = dataframe[feature].size
        non_missing_data = dataframe[feature].dropna()
        value_counts = non_missing_data.value_counts()
        top_value_counts = value_counts.head(10)
        remaining_count = value_counts.iloc[10:].sum()

        labels = list(top_value_counts.index)
        sizes = list((top_value_counts / total_count) * 100)

        if remaining_count > 0:
            labels.append('Remaining Examples')
            sizes.append((remaining_count / total_count) * 100)

        if missing_count > 0:
            labels.append('Missing Values')
            sizes.append((missing_count / total_count) * 100)

        plot_feature_analysis(dataframe, feature, feature_type, labels, sizes, unique_value_threshold, figure_dir)
        save_summary_statistics(dataframe, feature, table_dir)

        summary_stats = pd.read_csv(os.path.join(table_dir, f'{feature}_summary.csv'))
        value_counts = pd.read_csv(os.path.join(table_dir, f'{feature}_value_counts.csv'))
        contextual_insights_and_recommendations(dataframe, feature, feature_type, summary_stats, value_counts, unique_value_threshold)




# # src/analysis/univariate_analysis.py

# import os
# import pandas as pd
# import matplotlib.pyplot as plt
# from tqdm import tqdm
# from src.visualization.eda import plot_histogram, plot_boxplot, plot_kde, plot_countplot, plot_piechart, plot_binary_feature
# from src.utils.metadata_operations import determine_feature_type
# from typing import Dict


# def create_comparison_table(dataframe: pd.DataFrame, metadata: Dict) -> pd.DataFrame:
#     """
#     Create a comparison table of features' classified types and determined types.

#     Parameters:
#     dataframe (pd.DataFrame): The DataFrame containing the data.
#     metadata (dict): The metadata containing feature information.

#     Returns:
#     pd.DataFrame: The comparison table with feature types and discrepancies.
#     """
#     comparison_data = []
#     for feature in dataframe.columns:
#         classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
#         determined_type = determine_feature_type(feature, metadata)
#         discrepancy = classified_type != determined_type
#         comparison_data.append({
#             'Feature': feature,
#             'Previously Analyzed Type': classified_type,
#             'Current Analyzed Type': determined_type,
#             'Discrepancy': discrepancy,
#             'Manual Review and Update': determined_type  # Initialize with current analyzed type
#         })
#     comparison_table = pd.DataFrame(comparison_data)
#     comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
#     return comparison_table


# def save_summary_statistics(dataframe: pd.DataFrame, feature: str, summary_output_dir: str) -> None:
#     """
#     Save summary statistics and value counts for the given feature to CSV files.

#     Parameters:
#     dataframe (pd.DataFrame): The DataFrame containing the data.
#     feature (str): The feature to analyze.
#     summary_output_dir (str): Directory to save the summary statistics and value counts.
#     """
#     summary_stats = dataframe[feature].describe().to_frame(name='Summary_Statistics')
#     summary_stats_path = os.path.join(summary_output_dir, f'{feature}_summary.csv')
#     summary_stats.to_csv(summary_stats_path)

#     non_missing_data = dataframe[feature].dropna()
#     value_counts = non_missing_data.value_counts().to_frame(name='Count')
#     value_counts['Percentage'] = (value_counts['Count'] / dataframe[feature].size) * 100
#     value_counts_path = os.path.join(summary_output_dir, f'{feature}_value_counts.csv')
#     value_counts.to_csv(value_counts_path)


# def plot_feature_analysis(dataframe: pd.DataFrame, feature: str, feature_type: str, labels: list, sizes: list, unique_value_threshold: int, figure_dir: str) -> None:
#     """
#     Plot various analyses for a given feature.

#     Parameters:
#     dataframe (pd.DataFrame): The DataFrame containing the data.
#     feature (str): The feature to analyze.
#     feature_type (str): The type of the feature (categorical or numerical).
#     labels (list): Labels for the pie chart.
#     sizes (list): Sizes for the pie chart.
#     unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
#     figure_dir (str): Directory to save the figures.
#     """
#     fig, axs = plt.subplots(3, 2, figsize=(18, 24))
#     axs = axs.flatten()

#     if feature_type == 'categorical' or dataframe[feature].nunique() < unique_value_threshold:
#         # Treat as categorical
#         plot_countplot(dataframe, feature, axs[0])
#         plot_piechart(labels, sizes, axs[1], feature)
#     else:
#         # Treat as numerical
#         plot_histogram(dataframe, feature, axs[0])
#         plot_boxplot(dataframe, feature, axs[1])
#         plot_kde(dataframe, feature, axs[2])

#     # Always include binary feature plot
#     if dataframe[feature].nunique() == 2:
#         plot_binary_feature(dataframe, feature, axs[3])

#     # Include both categorical and numerical plots for features with numerical values but many unique categories
#     if feature_type == 'numerical' and dataframe[feature].nunique() > unique_value_threshold:
#         plot_countplot(dataframe, feature, axs[4])
#         plot_piechart(labels, sizes, axs[5], feature)

#     plt.tight_layout()
#     plt.savefig(f'{figure_dir}/{feature}_analysis.png')
#     plt.show()


# def contextual_insights_and_recommendations(dataframe: pd.DataFrame, feature: str, feature_type: str, summary_stats: pd.DataFrame, value_counts: pd.DataFrame, unique_value_threshold: int) -> None:
#     """
#     Print contextual insights and recommendations based on feature analysis.

#     Parameters:
#     dataframe (pd.DataFrame): The DataFrame containing the data.
#     feature (str): The feature to analyze.
#     feature_type (str): The type of the feature (categorical or numerical).
#     summary_stats (pd.DataFrame): The summary statistics of the feature.
#     value_counts (pd.DataFrame): The value counts of the feature.
#     unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
#     """
#     print(f"\nSummary Statistics for {feature}:\n{summary_stats}")
#     print(f"\nValue Counts for {feature}:\n{value_counts}")

#     print("\n--- Contextual Insights and Recommendations ---\n")
#     try:
#         if feature_type != 'categorical' and dataframe[feature].nunique() >= unique_value_threshold:
#             mean = summary_stats.loc['mean'].values[0]
#             std = summary_stats.loc['std'].values[0]
#             count = summary_stats.loc['count'].values[0]
#             min_val = summary_stats.loc['min'].values[0]
#             max_val = summary_stats.loc['max'].values[0]
#             print(f"High-Level Overview: {feature} has a mean of {mean} and a standard deviation of {std}.")
#             print(f"Detailed Technical Insights: The distribution of {feature} shows {count} instances with a range from {min_val} to {max_val}.")
#             print("Actionable Recommendations: Use this information to identify potential outliers and decide on normalization or transformation techniques.")
#         else:
#             unique_categories = value_counts.shape[0]
#             most_frequent = value_counts.index[0]
#             print(f"High-Level Overview: {feature} has {unique_categories} unique categories with the most frequent category being {most_frequent}.")
#             print("Detailed Technical Insights: The distribution shows a clear dominance of certain categories which may influence model training.")
#             print("Actionable Recommendations: Consider encoding techniques and assess the impact of dominant categories on the target variable.")
#     except KeyError as e:
#         print(f"An error occurred while processing feature {feature}: {e}")


# def univariate_analysis(dataframe: pd.DataFrame, paths: Dict, metadata: Dict, comparison_table: pd.DataFrame, unique_value_threshold: int = 20) -> None:
#     """
#     Perform univariate analysis on the features of the DataFrame.

#     Parameters:
#     dataframe (pd.DataFrame): The DataFrame containing the data.
#     paths (dict): The paths and directories for the project.
#     metadata (dict): The metadata containing feature information.
#     comparison_table (pd.DataFrame): The comparison table with feature types and discrepancies.
#     unique_value_threshold (int): The threshold for treating a feature as numerical or categorical.
#     """
#     output_dir = paths['reports']['univariate_analysis']
#     figure_dir = os.path.join(output_dir, 'figures', 'univariate_analysis', '01_univariate_analysis')
#     table_dir = os.path.join(output_dir, 'tables', 'univariate_analysis', '01_univariate_analysis')
#     os.makedirs(figure_dir, exist_ok=True)
#     os.makedirs(table_dir, exist_ok=True)

#     all_features = dataframe.columns
#     for feature in all_features:
#         feature_type = determine_feature_type(feature, metadata)
#         missing_count = metadata['features'][feature]['missing_values']['count']
#         total_count = dataframe[feature].size
#         non_missing_data = dataframe[feature].dropna()
#         value_counts = non_missing_data.value_counts()
#         top_value_counts = value_counts.head(10)
#         remaining_count = value_counts.iloc[10:].sum()

#         labels = list(top_value_counts.index)
#         sizes = list((top_value_counts / total_count) * 100)

#         if remaining_count > 0:
#             labels.append('Remaining Examples')
#             sizes.append((remaining_count / total_count) * 100)

#         if missing_count > 0:
#             labels.append('Missing Values')
#             sizes.append((missing_count / total_count) * 100)

#         plot_feature_analysis(dataframe, feature, feature_type, labels, sizes, unique_value_threshold, figure_dir)

#         save_summary_statistics(dataframe, feature, table_dir)

#         summary_stats = pd.read_csv(os.path.join(table_dir, f'{feature}_summary.csv'))
#         value_counts = pd.read_csv(os.path.join(table_dir, f'{feature}_value_counts.csv'))
#         contextual_insights_and_recommendations(dataframe, feature, feature_type, summary_stats, value_counts, unique_value_threshold)





# # # src/analysis/univariate_analysis.py

# # import pandas as pd
# # import matplotlib.pyplot as plt
# # import os
# # from tqdm import tqdm
# # # from src.visualization.plot_utils import plot_histogram, plot_boxplot, plot_kde, plot_countplot, plot_piechart, plot_binary_feature
# # from src.visualization.eda import plot_histogram, plot_boxplot, plot_kde, plot_countplot, plot_piechart, plot_binary_feature
# # from src.utils.metadata_operations import determine_feature_type

# # def create_comparison_table(dataframe, metadata):
# #     comparison_data = []
# #     for feature in dataframe.columns:
# #         classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
# #         determined_type = determine_feature_type(feature, metadata)
# #         discrepancy = classified_type != determined_type
# #         comparison_data.append({
# #             'Feature': feature,
# #             'Previously Analyzed Type': classified_type,
# #             'Current Analyzed Type': determined_type,
# #             'Discrepancy': discrepancy,
# #             'Manual Review and Update': determined_type  # Initialize with current analyzed type
# #         })
# #     comparison_table = pd.DataFrame(comparison_data)
# #     comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
# #     return comparison_table

# # def univariate_analysis(dataframe, paths, metadata, comparison_table, unique_value_threshold=20):
# #     output_dir = paths['reports']['univariate_analysis']
# #     figure_dir = os.path.join(output_dir, 'figures', 'univariate_analysis', '01_univariate_analysis')
# #     table_dir = os.path.join(output_dir, 'tables', 'univariate_analysis', '01_univariate_analysis')
# #     os.makedirs(figure_dir, exist_ok=True)
# #     os.makedirs(table_dir, exist_ok=True)

# #     all_features = dataframe.columns
# #     for feature in all_features:
# #         feature_type = determine_feature_type(feature, metadata)
# #         fig, axs = plt.subplots(3, 2, figsize=(18, 24))
# #         axs = axs.flatten()

# #         # Use missing values from metadata
# #         missing_count = metadata['features'][feature]['missing_values']['count']
# #         missing_percentage = metadata['features'][feature]['missing_values']['percentage']
# #         total_count = dataframe[feature].size
# #         non_missing_data = dataframe[feature].dropna()
# #         value_counts = non_missing_data.value_counts()
# #         top_value_counts = value_counts.head(10)
# #         remaining_count = value_counts.iloc[10:].sum()

# #         labels = list(top_value_counts.index)
# #         sizes = list((top_value_counts / total_count) * 100)

# #         if remaining_count > 0:
# #             labels.append('Remaining Examples')
# #             sizes.append((remaining_count / total_count) * 100)

# #         if missing_count > 0:
# #             labels.append('Missing Values')
# #             sizes.append((missing_count / total_count) * 100)

# #         if feature_type == 'categorical' or dataframe[feature].nunique() < unique_value_threshold:
# #             # Treat as categorical
# #             plot_countplot(dataframe, feature, axs[0])
# #             plot_piechart(labels, sizes, axs[1], feature)
# #         else:
# #             # Treat as numerical
# #             plot_histogram(dataframe, feature, axs[0])
# #             plot_boxplot(dataframe, feature, axs[1])
# #             plot_kde(dataframe, feature, axs[2])

# #         # Always include binary feature plot
# #         if dataframe[feature].nunique() == 2:
# #             plot_binary_feature(dataframe, feature, axs[3])

# #         # Include both categorical and numerical plots for features with numerical values but many unique categories
# #         if feature_type == 'numerical' and dataframe[feature].nunique() > unique_value_threshold:
# #             plot_countplot(dataframe, feature, axs[4])
# #             plot_piechart(labels, sizes, axs[5], feature)

# #         plt.tight_layout()
# #         plt.savefig(f'{figure_dir}/{feature}_analysis.png')
# #         plt.show()

# #         # Directory to save summary statistics and value counts
# #         summary_output_dir = os.path.join(table_dir)
# #         os.makedirs(summary_output_dir, exist_ok=True)

# #         # Save Summary Statistics or Value Counts to CSV
# #         summary_stats = dataframe[feature].describe().to_frame(name='Summary_Statistics')
# #         summary_stats_path = os.path.join(summary_output_dir, f'{feature}_summary.csv')
# #         summary_stats.to_csv(summary_stats_path)

# #         value_counts = non_missing_data.value_counts().to_frame(name='Count')
# #         value_counts['Percentage'] = (value_counts['Count'] / total_count) * 100
# #         value_counts_path = os.path.join(summary_output_dir, f'{feature}_value_counts.csv')
# #         value_counts.to_csv(value_counts_path)

# #         print(f"\nSummary Statistics for {feature}:\n{summary_stats}")
# #         print(f"\nValue Counts for {feature}:\n{value_counts}")

# #         print("\n--- Contextual Insights and Recommendations ---\n")
# #         try:
# #             if feature_type != 'categorical' and dataframe[feature].nunique() >= unique_value_threshold:
# #                 mean = summary_stats.loc['mean'].values[0]
# #                 std = summary_stats.loc['std'].values[0]
# #                 count = summary_stats.loc['count'].values[0]
# #                 min_val = summary_stats.loc['min'].values[0]
# #                 max_val = summary_stats.loc['max'].values[0]
# #                 print(f"High-Level Overview: {feature} has a mean of {mean} and a standard deviation of {std}.")
# #                 print(f"Detailed Technical Insights: The distribution of {feature} shows {count} instances with a range from {min_val} to {max_val}.")
# #                 print("Actionable Recommendations: Use this information to identify potential outliers and decide on normalization or transformation techniques.")
# #             else:
# #                 unique_categories = value_counts.shape[0]
# #                 most_frequent = value_counts.index[0]
# #                 print(f"High-Level Overview: {feature} has {unique_categories} unique categories with the most frequent category being {most_frequent}.")
# #                 print("Detailed Technical Insights: The distribution shows a clear dominance of certain categories which may influence model training.")
# #                 print("Actionable Recommendations: Consider encoding techniques and assess the impact of dominant categories on the target variable.")
# #         except KeyError as e:
# #             print(f"An error occurred while processing feature {feature}: {e}")
