# src/analysis/univariate_analysis.py

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

def plot_histogram(data, feature, ax):
    sns.histplot(data[feature], kde=True, bins=30, ax=ax)
    ax.set_title(f'Distribution of {feature}')
    ax.set_xlabel(feature)
    ax.set_ylabel('Frequency')

def plot_boxplot(data, feature, ax):
    sns.boxplot(y=data[feature], ax=ax)
    ax.set_title(f'Box Plot of {feature}')
    ax.set_ylabel(feature)

def plot_kde(data, feature, ax):
    if pd.api.types.is_numeric_dtype(data[feature]):
        sns.kdeplot(data[feature], fill=True, warn_singular=False, ax=ax)
        ax.set_title(f'Kernel Density Estimate of {feature}')
        ax.set_xlabel(feature)
        ax.set_ylabel('Density')
    else:
        ax.set_title(f'KDE not applicable for {feature}')
        ax.axis('off')

def plot_countplot(data, feature, ax, top_n=10):
    value_counts = data[feature].value_counts().head(top_n)
    sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
    ax.set_title(f'Top {top_n} Categories of {feature}')
    ax.set_xlabel(feature)
    ax.set_ylabel('Count')
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)

def plot_piechart(labels, sizes, ax, feature):
    ax.pie(sizes, labels=labels, autopct='%1.1f%%')
    ax.set_title(f'Top {len(labels)} Categories of {feature}')

def plot_binary_feature(data, feature, ax):
    sns.countplot(x=data[feature], ax=ax)
    ax.set_title(f'Count Plot of {feature}')
    ax.set_xlabel(f'{feature} Value')
    ax.set_ylabel('Count')
    total = len(data[feature].dropna())
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2., height + 3, '{:1.2f}%'.format(100 * height / total), ha="center")

def determine_feature_type(feature, metadata):
    classified_type = metadata['features'][feature].get('classified_data_type', '')
    if classified_type == 'binary':
        return 'binary'
    if classified_type == 'categorical':
        return 'categorical'
    example_values = metadata['features'][feature].get('example_values', [])
    if all(isinstance(val, (int, float)) for val in example_values):
        if len(example_values) > 0 and isinstance(example_values[0], int):
            return 'categorical'
    return 'numerical'

def create_comparison_table(dataframe, metadata):
    comparison_data = []
    for feature in dataframe.columns:
        classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
        determined_type = determine_feature_type(feature, metadata)
        discrepancy = classified_type != determined_type
        comparison_data.append({
            'Feature': feature,
            'Previously Analyzed Type': classified_type,
            'Current Analyzed Type': determined_type,
            'Discrepancy': discrepancy,
            'Manual Review and Update': determined_type  # Initialize with current analyzed type
        })
    comparison_table = pd.DataFrame(comparison_data)
    comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
    return comparison_table

def univariate_analysis(dataframe, paths, metadata, comparison_table, unique_value_threshold=20):
    output_dir = paths['reports']['univariate_analysis']
    figure_dir = os.path.join(output_dir, 'figures', 'univariate_analysis', '01_univariate_analysis')
    table_dir = os.path.join(output_dir, 'tables', 'univariate_analysis', '01_univariate_analysis')
    os.makedirs(figure_dir, exist_ok=True)
    os.makedirs(table_dir, exist_ok=True)

    all_features = dataframe.columns
    for feature in all_features:
        feature_type = determine_feature_type(feature, metadata)
        fig, axs = plt.subplots(3, 2, figsize=(18, 24))
        axs = axs.flatten()

        # Use missing values from metadata
        missing_count = metadata['features'][feature]['missing_values']['count']
        missing_percentage = metadata['features'][feature]['missing_values']['percentage']
        total_count = dataframe[feature].size
        non_missing_data = dataframe[feature].dropna()
        value_counts = non_missing_data.value_counts()
        top_value_counts = value_counts.head(10)
        remaining_count = value_counts.iloc[10:].sum()

        labels = list(top_value_counts.index)
        sizes = list((top_value_counts / total_count) * 100)

        if remaining_count > 0:
            labels.append('Remaining Examples')
            sizes.append((remaining_count / total_count) * 100)

        if missing_count > 0:
            labels.append('Missing Values')
            sizes.append((missing_count / total_count) * 100)

        if feature_type == 'categorical' or dataframe[feature].nunique() < unique_value_threshold:
            # Treat as categorical
            plot_countplot(dataframe, feature, axs[0])
            plot_piechart(labels, sizes, axs[1], feature)
        else:
            # Treat as numerical
            plot_histogram(dataframe, feature, axs[0])
            plot_boxplot(dataframe, feature, axs[1])
            plot_kde(dataframe, feature, axs[2])

        # Always include binary feature plot
        if dataframe[feature].nunique() == 2:
            plot_binary_feature(dataframe, feature, axs[3])

        # Include both categorical and numerical plots for features with numerical values but many unique categories
        if feature_type == 'numerical' and dataframe[feature].nunique() > unique_value_threshold:
            plot_countplot(dataframe, feature, axs[4])
            plot_piechart(labels, sizes, axs[5], feature)

        plt.tight_layout()
        plt.savefig(f'{figure_dir}/{feature}_analysis.png')
        plt.show()

        # Directory to save summary statistics and value counts
        summary_output_dir = os.path.join(table_dir)
        os.makedirs(summary_output_dir, exist_ok=True)

        # Save Summary Statistics or Value Counts to CSV
        summary_stats = dataframe[feature].describe().to_frame(name='Summary_Statistics')
        summary_stats_path = os.path.join(summary_output_dir, f'{feature}_summary.csv')
        summary_stats.to_csv(summary_stats_path)

        value_counts = non_missing_data.value_counts().to_frame(name='Count')
        value_counts['Percentage'] = (value_counts['Count'] / total_count) * 100
        value_counts_path = os.path.join(summary_output_dir, f'{feature}_value_counts.csv')
        value_counts.to_csv(value_counts_path)

        print(f"\nSummary Statistics for {feature}:\n{summary_stats}")
        print(f"\nValue Counts for {feature}:\n{value_counts}")

        print("\n--- Contextual Insights and Recommendations ---\n")
        try:
            if feature_type != 'categorical' and dataframe[feature].nunique() >= unique_value_threshold:
                mean = summary_stats.loc['mean'].values[0]
                std = summary_stats.loc['std'].values[0]
                count = summary_stats.loc['count'].values[0]
                min_val = summary_stats.loc['min'].values[0]
                max_val = summary_stats.loc['max'].values[0]
                print(f"High-Level Overview: {feature} has a mean of {mean} and a standard deviation of {std}.")
                print(f"Detailed Technical Insights: The distribution of {feature} shows {count} instances with a range from {min_val} to {max_val}.")
                print("Actionable Recommendations: Use this information to identify potential outliers and decide on normalization or transformation techniques.")
            else:
                unique_categories = value_counts.shape[0]
                most_frequent = value_counts.index[0]
                print(f"High-Level Overview: {feature} has {unique_categories} unique categories with the most frequent category being {most_frequent}.")
                print("Detailed Technical Insights: The distribution shows a clear dominance of certain categories which may influence model training.")
                print("Actionable Recommendations: Consider encoding techniques and assess the impact of dominant categories on the target variable.")
        except KeyError as e:
            print(f"An error occurred while processing feature {feature}: {e}")




# # src/analysis/univariate_analysis.py

# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# import os

# def plot_histogram(data, feature, ax):
#     sns.histplot(data[feature], kde=True, bins=30, ax=ax)
#     ax.set_title(f'Distribution of {feature}')
#     ax.set_xlabel(feature)
#     ax.set_ylabel('Frequency')

# def plot_boxplot(data, feature, ax):
#     sns.boxplot(y=data[feature], ax=ax)
#     ax.set_title(f'Box Plot of {feature}')
#     ax.set_ylabel(feature)

# def plot_kde(data, feature, ax):
#     if pd.api.types.is_numeric_dtype(data[feature]):
#         sns.kdeplot(data[feature], fill=True, warn_singular=False, ax=ax)
#         ax.set_title(f'Kernel Density Estimate of {feature}')
#         ax.set_xlabel(feature)
#         ax.set_ylabel('Density')
#     else:
#         ax.set_title(f'KDE not applicable for {feature}')
#         ax.axis('off')

# def plot_countplot(data, feature, ax, top_n=10):
#     value_counts = data[feature].value_counts().head(top_n)
#     sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax)
#     ax.set_title(f'Top {top_n} Categories of {feature}')
#     ax.set_xlabel(feature)
#     ax.set_ylabel('Count')
#     ax.set_xticklabels(ax.get_xticklabels(), rotation=45)

# def plot_piechart(labels, sizes, ax, feature):
#     ax.pie(sizes, labels=labels, autopct='%1.1f%%')
#     ax.set_title(f'Top {len(labels)} Categories of {feature}')

# def plot_binary_feature(data, feature, ax):
#     sns.countplot(x=data[feature], ax=ax)
#     ax.set_title(f'Count Plot of {feature}')
#     ax.set_xlabel(f'{feature} Value')
#     ax.set_ylabel('Count')
#     total = len(data[feature].dropna())
#     for p in ax.patches:
#         height = p.get_height()
#         ax.text(p.get_x() + p.get_width() / 2., height + 3, '{:1.2f}%'.format(100 * height / total), ha="center")

# def determine_feature_type(feature, metadata):
#     classified_type = metadata['features'][feature].get('classified_data_type', '')
#     if classified_type == 'binary':
#         return 'binary'
#     if classified_type == 'categorical':
#         return 'categorical'
#     example_values = metadata['features'][feature].get('example_values', [])
#     if all(isinstance(val, (int, float)) for val in example_values):
#         if len(example_values) > 0 and isinstance(example_values[0], int):
#             return 'categorical'
#     return 'numerical'

# def create_comparison_table(dataframe, metadata):
#     comparison_data = []
#     for feature in dataframe.columns:
#         classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
#         determined_type = determine_feature_type(feature, metadata)
#         discrepancy = classified_type != determined_type
#         comparison_data.append({
#             'Feature': feature,
#             'Previously Analyzed Type': classified_type,
#             'Current Analyzed Type': determined_type,
#             'Discrepancy': discrepancy,
#             'Manual Review and Update': determined_type  # Initialize with current analyzed type
#         })
#     comparison_table = pd.DataFrame(comparison_data)
#     comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
#     return comparison_table

# def univariate_analysis(dataframe, paths, metadata, comparison_table, unique_value_threshold=20):
#     all_features = dataframe.columns
#     for feature in all_features:
#         feature_type = determine_feature_type(feature, metadata)
#         fig, axs = plt.subplots(3, 2, figsize=(18, 24))
#         axs = axs.flatten()

#         # Use missing values from metadata
#         missing_count = metadata['features'][feature]['missing_values']['count']
#         missing_percentage = metadata['features'][feature]['missing_values']['percentage']
#         total_count = dataframe[feature].size
#         non_missing_data = dataframe[feature].dropna()
#         value_counts = non_missing_data.value_counts()
#         top_value_counts = value_counts.head(10)
#         remaining_count = value_counts.iloc[10:].sum()

#         labels = list(top_value_counts.index)
#         sizes = list((top_value_counts / total_count) * 100)

#         if remaining_count > 0:
#             labels.append('Remaining Examples')
#             sizes.append((remaining_count / total_count) * 100)

#         if missing_count > 0:
#             labels.append('Missing Values')
#             sizes.append((missing_count / total_count) * 100)

#         if feature_type == 'categorical' or dataframe[feature].nunique() < unique_value_threshold:
#             # Treat as categorical
#             plot_countplot(dataframe, feature, axs[0])
#             plot_piechart(labels, sizes, axs[1], feature)
#         else:
#             # Treat as numerical
#             plot_histogram(dataframe, feature, axs[0])
#             plot_boxplot(dataframe, feature, axs[1])
#             plot_kde(dataframe, feature, axs[2])

#         # Always include binary feature plot
#         if dataframe[feature].nunique() == 2:
#             plot_binary_feature(dataframe, feature, axs[3])

#         # Include both categorical and numerical plots for features with numerical values but many unique categories
#         if feature_type == 'numerical' and dataframe[feature].nunique() > unique_value_threshold:
#             plot_countplot(dataframe, feature, axs[4])
#             plot_piechart(labels, sizes, axs[5], feature)

#         plt.tight_layout()
#         figure_dir = os.path.join('reports', 'figures', 'univariate_analysis', '01_univariate_analysis')
#         os.makedirs(figure_dir, exist_ok=True)
#         plt.savefig(f'{figure_dir}/{feature}_analysis.png')
#         plt.show()

#         # Directory to save summary statistics and value counts
#         summary_output_dir = os.path.join('reports', 'tables', 'univariate_analysis', '01_univariate_analysis')
#         os.makedirs(summary_output_dir, exist_ok=True)

#         # Save Summary Statistics or Value Counts to CSV
#         summary_stats = dataframe[feature].describe().to_frame(name='Summary_Statistics')
#         summary_stats_path = os.path.join(summary_output_dir, f'{feature}_summary.csv')
#         summary_stats.to_csv(summary_stats_path)

#         value_counts = non_missing_data.value_counts().to_frame(name='Count')
#         value_counts['Percentage'] = (value_counts['Count'] / total_count) * 100
#         value_counts_path = os.path.join(summary_output_dir, f'{feature}_value_counts.csv')
#         value_counts.to_csv(value_counts_path)

#         print(f"\nSummary Statistics for {feature}:\n{summary_stats}")
#         print(f"\nValue Counts for {feature}:\n{value_counts}")

#         print("\n--- Contextual Insights and Recommendations ---\n")
#         try:
#             if feature_type != 'categorical' and dataframe[feature].nunique() >= unique_value_threshold:
#                 mean = summary_stats.loc['mean'].values[0]
#                 std = summary_stats.loc['std'].values[0]
#                 count = summary_stats.loc['count'].values[0]
#                 min_val = summary_stats.loc['min'].values[0]
#                 max_val = summary_stats.loc['max'].values[0]
#                 print(f"High-Level Overview: {feature} has a mean of {mean} and a standard deviation of {std}.")
#                 print(f"Detailed Technical Insights: The distribution of {feature} shows {count} instances with a range from {min_val} to {max_val}.")
#                 print("Actionable Recommendations: Use this information to identify potential outliers and decide on normalization or transformation techniques.")
#             else:
#                 unique_categories = value_counts.shape[0]
#                 most_frequent = value_counts.index[0]
#                 print(f"High-Level Overview: {feature} has {unique_categories} unique categories with the most frequent category being {most_frequent}.")
#                 print("Detailed Technical Insights: The distribution shows a clear dominance of certain categories which may influence model training.")
#                 print("Actionable Recommendations: Consider encoding techniques and assess the impact of dominant categories on the target variable.")
#         except KeyError as e:
#             print(f"An error occurred while processing feature {feature}: {e}")









