# src/analysis/data_understanding.py

import pandas as pd
import os
import logging
import seaborn as sns
import matplotlib.pyplot as plt
from config_loader import load_config, update_imputation_strategies
from utils import save_analysis_results
from feature_engineering.imputation import suggest_imputation_strategy, handle_missing_values

logger = logging.getLogger(__name__)

def generate_summary_statistics(df):
    """
    Generate summary statistics for the given dataframe.

    Parameters:
    - df (DataFrame): The dataframe to analyze.

    Returns:
    - DataFrame: Summary statistics.
    """
    summary_stats = df.describe(include='all').transpose()
    summary_stats['missing_values'] = df.isnull().sum()
    summary_stats['missing_percentage'] = (df.isnull().sum() / len(df)) * 100
    return summary_stats

def save_summary_statistics(summary_stats, save_path):
    """
    Save summary statistics as a CSV file and an image.

    Parameters:
    - summary_stats (DataFrame): The summary statistics to save.
    - save_path (str): The path to save the image.
    """
    summary_stats.to_csv(save_path.replace('.png', '.csv'))
    fig, ax = plt.subplots(figsize=(20, 10))  # Adjust size as necessary
    sns.heatmap(summary_stats.isnull(), cbar=False, ax=ax, cmap='viridis')
    plt.xticks(rotation=90)
    plt.tight_layout()  # Ensure everything fits without overlapping
    plt.savefig(save_path)
    plt.close()

def plot_correlation_heatmap(df, save_path=None):
    """
    Plot a correlation heatmap for the dataframe.

    Parameters:
    - df (DataFrame): The dataframe to analyze.
    - save_path (str): The path to save the heatmap image.

    Returns:
    - DataFrame: Correlation matrix.
    """
    plt.figure(figsize=(20, 16))
    
    # Select only numeric columns for correlation analysis
    numeric_df = df.select_dtypes(include=['float64', 'int64', 'float32', 'int32'])
    
    # Calculate the correlation matrix
    corr_matrix = numeric_df.corr()
    
    # Plot the heatmap
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
    plt.title('Correlation Matrix')
    
    if save_path:
        plt.savefig(save_path)
    
    plt.show()
    return corr_matrix

def initial_data_analysis(train_chunk, test_chunk, config):
    try:
        report_dir = config['report_dir']
        if not os.path.exists(report_dir):
            os.makedirs(report_dir)

        # Generate summary statistics for train and test samples
        logger.info("Generating summary statistics for training data.")
        train_summary_stats = generate_summary_statistics(train_chunk)
        save_summary_statistics(train_summary_stats, os.path.join(report_dir, 'train_summary_statistics.png'))

        logger.info("Generating summary statistics for test data.")
        test_summary_stats = generate_summary_statistics(test_chunk)
        save_summary_statistics(test_summary_stats, os.path.join(report_dir, 'test_summary_statistics.png'))

        # Print summary statistics
        logger.info("Train Summary Statistics:")
        print(train_summary_stats)

        logger.info("Test Summary Statistics:")
        print(test_summary_stats)

        # Correlation Analysis
        logger.info("Performing correlation analysis.")
        corr_matrix = plot_correlation_heatmap(train_chunk, save_path=os.path.join(report_dir, 'correlation_heatmap.png'))

        # Suggest imputation strategies
        logger.info("Suggesting imputation strategies.")
        imputation_strategies = suggest_imputation_strategy(train_summary_stats, corr_matrix)

        # Handle missing values based on suggested imputation strategies
        logger.info("Handling missing values.")
        train_chunk = handle_missing_values(train_chunk, imputation_strategies)
        test_chunk = handle_missing_values(test_chunk, imputation_strategies)

        # Save analysis results
        save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir)

        # Update and save imputation strategies to config file
        updated_config = update_imputation_strategies(imputation_strategies, config_path=config['config_paths']['imputation_strategies'])
        logger.info(f"Updated Imputation Strategies: {updated_config}")

        logger.info("Initial data analysis completed successfully.")
        return train_chunk, test_chunk

    except Exception as e:
        logger.error(f"An error occurred during initial data analysis: {e}")
        raise

def save_cleaned_data(train_chunk, test_chunk, config):
    train_cleaned_path = config['data_paths']['train_cleaned']
    test_cleaned_path = config['data_paths']['test_cleaned']

    train_chunk.to_csv(train_cleaned_path, index=False)
    test_chunk.to_csv(test_cleaned_path, index=False)

    logger.info(f"Cleaned training data saved to {train_cleaned_path}")
    logger.info(f"Cleaned test data saved to {test_cleaned_path}")

def ensure_directories_exist(config):
    report_dir = config['report_dir']
    figures_dir = os.path.join(report_dir, 'figures')
    if not os.path.exists(report_dir):
        os.makedirs(report_dir)
    if not os.path.exists(figures_dir):
        os.makedirs(figures_dir)












# import pandas as pd
# import os
# import logging
# import seaborn as sns
# import matplotlib.pyplot as plt
# from config_loader import load_config, update_imputation_strategies
# from utils import save_analysis_results
# from feature_engineering.imputation import suggest_imputation_strategy, handle_missing_values

# logger = logging.getLogger(__name__)

# def generate_summary_statistics(df):
#     """
#     Generate summary statistics for the given dataframe.

#     Parameters:
#     - df (DataFrame): The dataframe to analyze.

#     Returns:
#     - DataFrame: Summary statistics.
#     """
#     summary_stats = df.describe(include='all').transpose()
#     summary_stats['missing_values'] = df.isnull().sum()
#     summary_stats['missing_percentage'] = (df.isnull().sum() / len(df)) * 100
#     return summary_stats

# def save_summary_statistics(summary_stats, save_path):
#     """
#     Save summary statistics as a CSV file and an image.

#     Parameters:
#     - summary_stats (DataFrame): The summary statistics to save.
#     - save_path (str): The path to save the image.
#     """
#     summary_stats.to_csv(save_path.replace('.png', '.csv'))
#     fig, ax = plt.subplots(figsize=(20, 10))  # Adjust size as necessary
#     sns.heatmap(summary_stats.isnull(), cbar=False, ax=ax, cmap='viridis')
#     plt.savefig(save_path)
#     plt.close()

# def plot_correlation_heatmap(df, save_path=None):
#     """
#     Plot a correlation heatmap for the dataframe.

#     Parameters:
#     - df (DataFrame): The dataframe to analyze.
#     - save_path (str): The path to save the heatmap image.

#     Returns:
#     - DataFrame: Correlation matrix.
#     """
#     plt.figure(figsize=(20, 16))
    
#     # Select only numeric columns for correlation analysis
#     numeric_df = df.select_dtypes(include=['float64', 'int64', 'float32', 'int32'])
    
#     # Calculate the correlation matrix
#     corr_matrix = numeric_df.corr()
    
#     # Plot the heatmap
#     sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
#     plt.title('Correlation Matrix')
    
#     if save_path:
#         plt.savefig(save_path)
    
#     plt.show()
#     return corr_matrix

# def initial_data_analysis(train_chunk, test_chunk, config):
#     try:
#         report_dir = config['report_dir']
#         if not os.path.exists(report_dir):
#             os.makedirs(report_dir)

#         # Generate summary statistics for train and test samples
#         logger.info("Generating summary statistics for training data.")
#         train_summary_stats = generate_summary_statistics(train_chunk)
#         save_summary_statistics(train_summary_stats, os.path.join(report_dir, 'train_summary_statistics.png'))

#         logger.info("Generating summary statistics for test data.")
#         test_summary_stats = generate_summary_statistics(test_chunk)
#         save_summary_statistics(test_summary_stats, os.path.join(report_dir, 'test_summary_statistics.png'))

#         # Print summary statistics
#         logger.info("Train Summary Statistics:")
#         print(train_summary_stats)

#         logger.info("Test Summary Statistics:")
#         print(test_summary_stats)

#         # Correlation Analysis
#         logger.info("Performing correlation analysis.")
#         corr_matrix = plot_correlation_heatmap(train_chunk, save_path=os.path.join(report_dir, 'correlation_heatmap.png'))

#         # Suggest imputation strategies
#         logger.info("Suggesting imputation strategies.")
#         imputation_strategies = suggest_imputation_strategy(train_summary_stats, corr_matrix)

#         # Handle missing values based on suggested imputation strategies
#         logger.info("Handling missing values.")
#         train_chunk = handle_missing_values(train_chunk, imputation_strategies)
#         test_chunk = handle_missing_values(test_chunk, imputation_strategies)

#         # Save analysis results
#         save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir)

#         # Update and save imputation strategies to config file
#         updated_config = update_imputation_strategies(imputation_strategies, config_path=config['config_paths']['imputation_strategies'])
#         logger.info(f"Updated Imputation Strategies: {updated_config}")

#         logger.info("Initial data analysis completed successfully.")
#         return train_chunk, test_chunk

#     except Exception as e:
#         logger.error(f"An error occurred during initial data analysis: {e}")
#         raise

# def save_cleaned_data(train_chunk, test_chunk, config):
#     train_cleaned_path = config['data_paths']['train_cleaned']
#     test_cleaned_path = config['data_paths']['test_cleaned']

#     train_chunk.to_csv(train_cleaned_path, index=False)
#     test_chunk.to_csv(test_cleaned_path, index=False)

#     logger.info(f"Cleaned training data saved to {train_cleaned_path}")
#     logger.info(f"Cleaned test data saved to {test_cleaned_path}")

# def ensure_directories_exist(config):
#     report_dir = config['report_dir']
#     figures_dir = os.path.join(report_dir, 'figures')
#     if not os.path.exists(report_dir):
#         os.makedirs(report_dir)
#     if not os.path.exists(figures_dir):
#         os.makedirs(figures_dir)






