# src/analysis/data_understanding.py

import pandas as pd
import os
import logging
import seaborn as sns
import matplotlib.pyplot as plt
from config_loader import load_config, update_imputation_strategies
from utils import save_analysis_results
from feature_engineering.imputation import suggest_imputation_strategy, handle_missing_values
from visualization.visualize import plot_correlation_heatmap

logger = logging.getLogger(__name__)

def generate_summary_statistics(df):
    """
    Generate summary statistics for the given dataframe.

    Parameters:
    - df (DataFrame): The dataframe to analyze.

    Returns:
    - DataFrame: Summary statistics.
    """
    summary_stats = df.describe(include='all').transpose()
    summary_stats['missing_values'] = df.isnull().sum()
    summary_stats['missing_percentage'] = (df.isnull().sum() / len(df)) * 100
    return summary_stats

def save_summary_statistics(summary_stats, save_path):
    """
    Save summary statistics as a CSV file and an image.

    Parameters:
    - summary_stats (DataFrame): The summary statistics to save.
    - save_path (str): The path to save the image.
    """
    summary_stats.to_csv(save_path.replace('.png', '.csv'))
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(summary_stats.isnull(), cbar=False, ax=ax)
    plt.savefig(save_path)
    plt.close()

def initial_data_analysis(train_chunk, test_chunk, config):
    try:
        # Ensure directories exist
        ensure_directories_exist(config)

        report_dir = config['report_dir']

        # Generate summary statistics for train and test samples
        logger.info("Generating summary statistics for training data.")
        train_summary_stats = generate_summary_statistics(train_chunk)
        save_summary_statistics(train_summary_stats, os.path.join(report_dir, 'train_summary_statistics.png'))

        logger.info("Generating summary statistics for test data.")
        test_summary_stats = generate_summary_statistics(test_chunk)
        save_summary_statistics(test_summary_stats, os.path.join(report_dir, 'test_summary_statistics.png'))

        # Print summary statistics
        logger.info("Train Summary Statistics:")
        print(train_summary_stats)

        logger.info("Test Summary Statistics:")
        print(test_summary_stats)

        # Correlation Analysis
        logger.info("Performing correlation analysis.")
        corr_matrix = plot_correlation_heatmap(train_chunk, save_path=os.path.join(report_dir, 'correlation_heatmap.png'))

        # Suggest imputation strategies
        logger.info("Suggesting imputation strategies.")
        imputation_strategies = suggest_imputation_strategy(train_summary_stats, corr_matrix)

        # Handle missing values based on suggested imputation strategies
        logger.info("Handling missing values.")
        train_chunk = handle_missing_values(train_chunk, imputation_strategies)
        test_chunk = handle_missing_values(test_chunk, imputation_strategies)

        # Save analysis results
        save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir)

        # Update and save imputation strategies to config file
        updated_config = update_imputation_strategies(imputation_strategies, config_path=config['config_paths']['imputation_strategies'])
        logger.info(f"Updated Imputation Strategies: {updated_config}")

        logger.info("Initial data analysis completed successfully.")
        return train_chunk, test_chunk

    except Exception as e:
        logger.error(f"An error occurred during initial data analysis: {e}")
        raise

def save_cleaned_data(train_chunk, test_chunk, config):
    train_cleaned_path = config['data_paths']['train_cleaned']
    test_cleaned_path = config['data_paths']['test_cleaned']

    train_chunk.to_csv(train_cleaned_path, index=False)
    test_chunk.to_csv(test_cleaned_path, index=False)

    logger.info(f"Cleaned training data saved to {train_cleaned_path}")
    logger.info(f"Cleaned test data saved to {test_cleaned_path}")

def ensure_directories_exist(config):
    report_dir = config['report_dir']
    figures_dir = os.path.join(report_dir, 'figures')
    if not os.path.exists(report_dir):
        os.makedirs(report_dir)
    if not os.path.exists(figures_dir):
        os.makedirs(figures_dir)














# import pandas as pd
# import os
# import logging
# from config_loader import load_config, update_imputation_strategies
# from utils import save_analysis_results
# from feature_engineering.imputation import suggest_imputation_strategy, handle_missing_values
# from visualization.visualize import plot_correlation_heatmap

# logger = logging.getLogger(__name__)

# def generate_summary_statistics(df):
#     """
#     Generate summary statistics for the dataframe.
#     """
#     summary_stats = df.describe(include='all').transpose()
#     summary_stats['missing_values'] = df.isnull().sum()
#     summary_stats['missing_percentage'] = (summary_stats['missing_values'] / len(df)) * 100
#     summary_stats['dtype'] = df.dtypes
#     return summary_stats

# def save_summary_statistics(summary_stats, filename):
#     summary_stats.to_csv(filename)

# def save_missing_values_table(summary_stats, filename):
#     missing_values_table = summary_stats[['missing_values', 'missing_percentage']]
#     missing_values_table.to_csv(filename)

# def save_imputation_strategies(imputation_strategies, filename):
#     imputation_strategies_df = pd.DataFrame(list(imputation_strategies['imputation_strategies'].items()), columns=['Feature', 'Imputation Strategy'])
#     imputation_strategies_df.to_csv(filename, index=False)

# def initial_data_analysis(train_chunk, test_chunk, config):
#     try:
#         # Generate summary statistics for train and test samples
#         logger.info("Generating summary statistics for training data.")
#         train_summary_stats = generate_summary_statistics(train_chunk)
#         logger.info("Generating summary statistics for test data.")
#         test_summary_stats = generate_summary_statistics(test_chunk)

#         # Save summary statistics
#         save_summary_statistics(train_summary_stats, '../reports/figures/train_summary_statistics.csv')
#         save_summary_statistics(test_summary_stats, '../reports/figures/test_summary_statistics.csv')

#         # Print summary statistics
#         logger.info("Train Summary Statistics:")
#         print(train_summary_stats)

#         logger.info("Test Summary Statistics:")
#         print(test_summary_stats)

#         # Correlation Analysis
#         logger.info("Performing correlation analysis.")
#         corr_matrix = plot_correlation_heatmap(train_chunk, target_col='HasDetections')

#         # Suggest imputation strategies
#         logger.info("Suggesting imputation strategies.")
#         imputation_strategies = suggest_imputation_strategy(train_summary_stats, corr_matrix, target_col='HasDetections')

#         # Handle missing values based on suggested imputation strategies
#         logger.info("Handling missing values.")
#         train_chunk = handle_missing_values(train_chunk, imputation_strategies)
#         test_chunk = handle_missing_values(test_chunk, imputation_strategies)

#         # Save missing values table
#         save_missing_values_table(train_summary_stats, '../reports/figures/train_missing_values.csv')
#         save_missing_values_table(test_summary_stats, '../reports/figures/test_missing_values.csv')

#         # Save imputation strategies table
#         save_imputation_strategies(imputation_strategies, '../reports/figures/imputation_strategies.csv')

#         # Save analysis results
#         report_dir = config['report_dir']
#         if not os.path.exists(report_dir):
#             os.makedirs(report_dir)
#         save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir)

#         # Update and save imputation strategies to config file
#         updated_config = update_imputation_strategies(imputation_strategies, config_path=config['config_paths']['imputation_strategies'])
#         logger.info(f"Updated Imputation Strategies: {updated_config}")

#         logger.info("Initial data analysis completed successfully.")

#         return train_chunk, test_chunk

#     except Exception as e:
#         logger.error(f"An error occurred during initial data analysis: {e}")
#         raise

# def save_cleaned_data(train_chunk, test_chunk, config):
#     train_cleaned_path = config['data_paths']['train_cleaned']
#     test_cleaned_path = config['data_paths']['test_cleaned']
    
#     train_chunk.to_csv(train_cleaned_path, index=False)
#     test_chunk.to_csv(test_cleaned_path, index=False)
    
#     logger.info(f"Cleaned training data saved to {train_cleaned_path}")
#     logger.info(f"Cleaned test data saved to {test_cleaned_path}")












