# src/utils/file_operations.py

import yaml
import os
import json
import numpy as np
import pandas as pd
import logging
from tqdm.notebook import tqdm

def save_dataframe_with_progress(df, path, chunk_size=100):
    """
    Save a DataFrame to a CSV file with a progress bar.

    Parameters:
    df (pd.DataFrame): DataFrame to save.
    path (str): File path to save the DataFrame to.
    chunk_size (int): Number of rows per chunk. Default is 100.
    """
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        total_rows = len(df)
        progress_bar = tqdm(total=total_rows, desc=f"Saving {os.path.basename(path)}")
        with open(path, 'w') as file:
            for i, chunk in enumerate(np.array_split(df, chunk_size)):
                chunk.to_csv(file, header=(i == 0), index=False)
                progress_bar.update(len(chunk))
        progress_bar.close()
    except Exception as e:
        print(f"Error saving DataFrame with progress: {e}")
        raise

def save_dataframe(df, path):
    """
    Save a DataFrame to a CSV file.

    Parameters:
    df (pd.DataFrame): DataFrame to save.
    path (str): File path to save the DataFrame to.
    """
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        df.to_csv(path, index=False)
    except Exception as e:
        print(f"Error saving DataFrame: {e}")
        raise

def load_csv_with_progress(file_path, chunksize=10000):
    """
    Load a CSV file with a progress bar.

    Parameters:
    file_path (str): Path to the CSV file to load.
    chunksize (int): Number of rows per chunk. Default is 10,000.

    Returns:
    pd.DataFrame: Loaded DataFrame.
    """
    try:
        total_lines = sum(1 for _ in open(file_path)) - 1
        chunk_list = []
        progress_bar = tqdm(total=total_lines // chunksize + 1, desc=f"Loading {os.path.basename(file_path)}")
        for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):
            chunk_list.append(chunk)
            progress_bar.update(1)
        progress_bar.close()
        return pd.concat(chunk_list, axis=0)
    except Exception as e:
        print(f"Error loading CSV with progress: {e}")
        raise

def load_yaml(file_path):
    """
    Load a YAML file.

    Parameters:
    file_path (str): Path to the YAML file to load.

    Returns:
    dict: Loaded YAML data.
    """
    try:
        with open(file_path, 'r') as file:
            return yaml.safe_load(file)
    except Exception as e:
        print(f"Error loading YAML file: {e}")
        raise



# def load_yaml(file_path):
#     """
#     Load a YAML file.

#     Parameters:
#     file_path (str): Path to the YAML file to load.

#     Returns:
#     dict: Loaded YAML data.
#     """
#     try:
#         with open(file_path, 'r') as file:
#             return yaml.safe_load(file)
#     except Exception as e:
#         print(f"Error loading YAML file: {e}")
#         raise

def save_yaml(data, file_path):
    """
    Save data to a YAML file.

    Parameters:
    data (dict): Data to save.
    file_path (str): Path to the YAML file to save to.
    """
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w') as file:
            yaml.safe_dump(data, file)
    except Exception as e:
        print(f"Error saving YAML file: {e}")
        raise

def load_json_file(filepath):
    """
    Load a JSON file.

    Parameters:
    filepath (str): Path to the JSON file to load.

    Returns:
    dict: Loaded JSON data.
    """
    try:
        with open(filepath, 'r') as file:
            return json.load(file)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from file {filepath}: {e}")
        return None
    except FileNotFoundError:
        return {}
    except Exception as e:
        print(f"Error loading JSON file: {e}")
        raise


# if this is called switch to save_json_file below
# def save_to_json(data, filename):
#     """
#     Save data to a JSON file.

#     Parameters:
#     data (dict): Data to save.
#     filename (str): Path to the JSON file to save to.
#     """
#     try:
#         with open(filename, 'w') as f:
#             json.dump(data, f, indent=4)
#     except Exception as e:
#         print(f"Error saving JSON file: {e}")
#         raise


def save_json_file(data, filepath):
    """
    Save data to a JSON file and update the config/json_files.yaml if necessary.

    Parameters:
    data (dict): Data to save.
    filepath (str): Path to the JSON file to save to.
    """
    try:
        # Save JSON file
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w') as file:
            json.dump(data, file, indent=4)
        
        # Update config/json_files.yaml
        update_json_files_config(filepath)
    except Exception as e:
        logging.error(f"Error saving JSON file: {e}", exc_info=True)
        raise

def update_json_files_config(filepath):
    """
    Update the config/json_files.yaml to include the new JSON file if not already listed.

    Parameters:
    filepath (str): Path to the JSON file.
    """
    try:
        config_path = os.path.join('config', 'json_files.yaml')
        with open(config_path, 'r') as file:
            config = yaml.safe_load(file)

        json_files = config.get('json_files', [])
        filename = os.path.basename(filepath)

        if filename not in json_files:
            json_files.append(filename)
            config['json_files'] = json_files

            with open(config_path, 'w') as file:
                yaml.safe_dump(config, file)
            
            logging.info(f"Updated config/json_files.yaml to include: {filename}")
    except Exception as e:
        logging.error(f"Error updating config/json_files.yaml: {e}", exc_info=True)
        raise

def initialize_json_files(json_files, save_dir):
    """
    Initialize JSON files in the specified directory.

    Parameters:
    json_files (list): List of JSON file names to initialize.
    save_dir (str): Directory to save the JSON files in.
    """
    try:
        for json_file in json_files:
            json_path = os.path.join(save_dir, json_file)
            if not os.path.exists(json_path):
                save_json_file({}, json_path)
    except Exception as e:
        print(f"Error initializing JSON files: {e}")
        raise


# def initialize_json_files(json_files, save_dir):
#     """
#     Initialize JSON files in the specified directory.

#     Parameters:
#     json_files (list): List of JSON file names to initialize.
#     save_dir (str): Directory to save the JSON files in.
#     """
#     try:
#         for json_file in json_files:
#             json_path = os.path.join(save_dir, json_file)
#             if not os.path.exists(json_path):
#                 save_json_file({}, json_path)
#     except Exception as e:
#         print(f"Error initializing JSON files: {e}")
#         raise

def convert_to_native_types(data):
    """
    Convert numpy data types to native Python types.

    Parameters:
    data: Data to convert.

    Returns:
    Data converted to native Python types.
    """
    if isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif isinstance(data, dict):
        return {k: convert_to_native_types(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [convert_to_native_types(v) for v in data]
    else:
        return data

def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
    """
    Save analysis results to CSV and YAML files.

    Parameters:
    train_summary_stats (pd.DataFrame): Training summary statistics.
    test_summary_stats (pd.DataFrame): Test summary statistics.
    imputation_strategies (dict): Imputation strategies.
    report_dir (str): Directory to save the results in.
    """
    try:
        tables_dir = os.path.join(report_dir, 'tables')
        os.makedirs(tables_dir, exist_ok=True)

        train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
        test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

        with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
            yaml.safe_dump(imputation_strategies, file)
    except Exception as e:
        print(f"Error saving analysis results: {e}")
        raise

def save_missing_values_correlations_with_target(data, path):
    """
    Save missing values correlations with target variable to a JSON file.

    Parameters:
    data (dict): Data to save.
    path (str): Path to the JSON file to save to.
    """
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        save_json_file(data, path)
    except Exception as e:
        print(f"Error saving missing values correlations with target: {e}")
        raise

def save_missing_value_pair_correlations(data, path):
    """
    Save missing value pair correlations to a JSON file.

    Parameters:
    data (dict): Data to save.
    path (str): Path to the JSON file to save to.
    """
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        save_json_file(data, path)
    except Exception as e:
        print(f"Error saving missing value pair correlations: {e}")
        raise

def load_manual_updates(manual_update_path):
    """
    Load manual feature classification updates from a YAML file.

    Parameters:
    manual_update_path (str): Path to the manual update file.

    Returns:
    dict: Dictionary containing manual feature classification updates.
    """
    try:
        return load_yaml(manual_update_path)['manual_feature_classification_updates']
    except Exception as e:
        print(f"Error loading manual updates: {e}")
        raise

def load_feature_descriptions(feature_descriptions_path):
    """
    Load feature descriptions from the specified path.

    Parameters:
    feature_descriptions_path (str): The path to the feature descriptions file.

    Returns:
    dict: The loaded feature descriptions.
    """
    return load_yaml(feature_descriptions_path)

def load_metadata_schema(feature_metadata_schema_path):
    """
    Load metadata schema from the specified path.

    Parameters:
    feature_metadata_schema_path (str): The path to the metadata schema file.

    Returns:
    dict: The loaded metadata schema.
    """
    return load_yaml(feature_metadata_schema_path)





# # src/utils/file_operations.py

# import yaml
# import os
# import json
# import numpy as np
# import pandas as pd
# from tqdm.notebook import tqdm

# def save_dataframe_with_progress(df, path):
#     """
#     Save a DataFrame to a CSV file with a progress bar.

#     Parameters:
#     df (pd.DataFrame): DataFrame to save.
#     path (str): File path to save the DataFrame to.
#     """
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     total_rows = len(df)
#     progress_bar = tqdm(total=total_rows, desc=f"Saving {os.path.basename(path)}")
#     with open(path, 'w') as file:
#         for i, chunk in enumerate(np.array_split(df, 100)):
#             chunk.to_csv(file, header=(i == 0), index=False)
#             progress_bar.update(len(chunk))
#     progress_bar.close()

# def save_dataframe(df, path):
#     """
#     Save a DataFrame to a CSV file.

#     Parameters:
#     df (pd.DataFrame): DataFrame to save.
#     path (str): File path to save the DataFrame to.
#     """
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     df.to_csv(path, index=False)

# def load_csv_with_progress(file_path, chunksize=10000):
#     """
#     Load a CSV file with a progress bar.

#     Parameters:
#     file_path (str): Path to the CSV file to load.
#     chunksize (int): Number of rows per chunk. Default is 10,000.

#     Returns:
#     pd.DataFrame: Loaded DataFrame.
#     """
#     total_lines = sum(1 for _ in open(file_path)) - 1
#     chunk_list = []
#     progress_bar = tqdm(total=total_lines // chunksize + 1, desc=f"Loading {os.path.basename(file_path)}")
#     for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):
#         chunk_list.append(chunk)
#         progress_bar.update(1)
#     progress_bar.close()
#     return pd.concat(chunk_list, axis=0)

# def load_yaml(file_path):
#     """
#     Load a YAML file.

#     Parameters:
#     file_path (str): Path to the YAML file to load.

#     Returns:
#     dict: Loaded YAML data.
#     """
#     with open(file_path, 'r') as file:
#         return yaml.safe_load(file)

# def save_yaml(data, file_path):
#     """
#     Save data to a YAML file.

#     Parameters:
#     data (dict): Data to save.
#     file_path (str): Path to the YAML file to save to.
#     """
#     os.makedirs(os.path.dirname(file_path), exist_ok=True)
#     with open(file_path, 'w') as file:
#         yaml.safe_dump(data, file)

# def load_json_file(filepath):
#     """
#     Load a JSON file.

#     Parameters:
#     filepath (str): Path to the JSON file to load.

#     Returns:
#     dict: Loaded JSON data.
#     """
#     try:
#         with open(filepath, 'r') as file:
#             return json.load(file)
#     except json.JSONDecodeError as e:
#         print(f"Error decoding JSON from file {filepath}: {e}")
#         return None
#     except FileNotFoundError:
#         return {}

# def save_to_json(data, filename):
#     """
#     Save data to a JSON file.

#     Parameters:
#     data (dict): Data to save.
#     filename (str): Path to the JSON file to save to.
#     """
#     with open(filename, 'w') as f:
#         json.dump(data, f, indent=4)

# def save_json_file(data, filepath):
#     """
#     Save data to a JSON file.

#     Parameters:
#     data (dict): Data to save.
#     filepath (str): Path to the JSON file to save to.
#     """
#     os.makedirs(os.path.dirname(filepath), exist_ok=True)
#     with open(filepath, 'w') as file:
#         json.dump(data, file, indent=4, default=convert_to_native_types)

# def initialize_json_files(json_files, save_dir):
#     """
#     Initialize JSON files in the specified directory.

#     Parameters:
#     json_files (list): List of JSON file names to initialize.
#     save_dir (str): Directory to save the JSON files in.
#     """
#     for json_file in json_files:
#         json_path = os.path.join(save_dir, json_file)
#         if not os.path.exists(json_path):
#             save_json_file({}, json_path)

# def convert_to_native_types(data):
#     """
#     Convert numpy data types to native Python types.

#     Parameters:
#     data: Data to convert.

#     Returns:
#     Data converted to native Python types.
#     """
#     if isinstance(data, np.integer):
#         return int(data)
#     elif isinstance(data, np.floating):
#         return float(data)
#     elif isinstance(data, np.ndarray):
#         return data.tolist()
#     elif isinstance(data, dict):
#         return {k: convert_to_native_types(v) for k, v in data.items()}
#     elif isinstance(data, list):
#         return [convert_to_native_types(v) for v in data]
#     else:
#         return data

# def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
#     """
#     Save analysis results to CSV and YAML files.

#     Parameters:
#     train_summary_stats (pd.DataFrame): Training summary statistics.
#     test_summary_stats (pd.DataFrame): Test summary statistics.
#     imputation_strategies (dict): Imputation strategies.
#     report_dir (str): Directory to save the results in.
#     """
#     tables_dir = os.path.join(report_dir, 'tables')
#     os.makedirs(tables_dir, exist_ok=True)

#     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
#     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

#     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
#         yaml.safe_dump(imputation_strategies, file)

# def save_missing_values_correlations_with_target(data, path):
#     """
#     Save missing values correlations with target variable to a JSON file.

#     Parameters:
#     data (dict): Data to save.
#     path (str): Path to the JSON file to save to.
#     """
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     save_json_file(data, path)

# def save_missing_value_pair_correlations(data, path):
#     """
#     Save missing value pair correlations to a JSON file.

#     Parameters:
#     data (dict): Data to save.
#     path (str): Path to the JSON file to save to.
#     """
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     save_json_file(data, path)



# # # src/utils/file_operations.py

# # import yaml
# # import os
# # import json
# # import numpy as np
# # import pandas as pd
# # from tqdm.notebook import tqdm

# # def save_dataframe_with_progress(df, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     total_rows = len(df)
# #     progress_bar = tqdm(total=total_rows, desc=f"Saving {os.path.basename(path)}")
# #     with open(path, 'w') as file:
# #         for i, chunk in enumerate(np.array_split(df, 100)):
# #             chunk.to_csv(file, header=(i == 0), index=False)
# #             progress_bar.update(len(chunk))
# #     progress_bar.close()

# # def save_dataframe(df, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     df.to_csv(path, index=False)

# # def load_csv_with_progress(file_path, chunksize=10000):
# #     total_lines = sum(1 for _ in open(file_path)) - 1
# #     chunk_list = []
# #     progress_bar = tqdm(total=total_lines // chunksize + 1, desc=f"Loading {os.path.basename(file_path)}")
# #     for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):
# #         chunk_list.append(chunk)
# #         progress_bar.update(1)
# #     progress_bar.close()
# #     return pd.concat(chunk_list, axis=0)

# # def load_yaml(file_path):
# #     with open(file_path, 'r') as file:
# #         return yaml.safe_load(file)

# # def save_yaml(data, file_path):
# #     os.makedirs(os.path.dirname(file_path), exist_ok=True)
# #     with open(file_path, 'w') as file:
# #         yaml.safe_dump(data, file)

# # def load_json_file(filepath):
# #     try:
# #         with open(filepath, 'r') as file:
# #             return json.load(file)
# #     except json.JSONDecodeError as e:
# #         print(f"Error decoding JSON from file {filepath}: {e}")
# #         return None
# #     except FileNotFoundError:
# #         return {}

# # def save_to_json(data, filename):
# #     with open(filename, 'w') as f:
# #         json.dump(data, f, indent=4)

# # def save_json_file(data, filepath):
# #     os.makedirs(os.path.dirname(filepath), exist_ok=True)
# #     with open(filepath, 'w') as file:
# #         json.dump(data, file, indent=4, default=convert_to_native_types)

# # def initialize_json_files(json_files, save_dir):
# #     for json_file in json_files:
# #         json_path = os.path.join(save_dir, json_file)
# #         if not os.path.exists(json_path):
# #             save_json_file({}, json_path)

# # def convert_to_native_types(data):
# #     if isinstance(data, np.integer):
# #         return int(data)
# #     elif isinstance(data, np.floating):
# #         return float(data)
# #     elif isinstance(data, np.ndarray):
# #         return data.tolist()
# #     elif isinstance(data, dict):
# #         return {k: convert_to_native_types(v) for k, v in data.items()}
# #     elif isinstance(data, list):
# #         return [convert_to_native_types(v) for v in data]
# #     else:
# #         return data

# # def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
# #     tables_dir = os.path.join(report_dir, 'tables')
# #     os.makedirs(tables_dir, exist_ok=True)

# #     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
# #     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

# #     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
# #         yaml.safe_dump(imputation_strategies, file)

# # def save_missing_values_correlations_with_target(data, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     save_json_file(data, path)

# # def save_missing_value_pair_correlations(data, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     save_json_file(data, path)




# # # # src/utils/file_operations.py

# # # import yaml
# # # import os
# # # import json
# # # import numpy as np
# # # import pandas as pd
# # # from tqdm.notebook import tqdm

# # # def save_dataframe_with_progress(df, path):
# # #     os.makedirs(os.path.dirname(path), exist_ok=True)
# # #     total_rows = len(df)
# # #     progress_bar = tqdm(total=total_rows, desc=f"Saving {os.path.basename(path)}")
# # #     with open(path, 'w') as file:
# # #         for i, chunk in enumerate(np.array_split(df, 100)):
# # #             chunk.to_csv(file, header=(i == 0), index=False)
# # #             progress_bar.update(len(chunk))
# # #     progress_bar.close()

# # # def load_csv_with_progress(file_path, chunksize=10000):
# # #     total_lines = sum(1 for _ in open(file_path)) - 1  # Calculate total lines in the file
# # #     chunk_list = []
# # #     progress_bar = tqdm(total=total_lines // chunksize + 1, desc=f"Loading {os.path.basename(file_path)}")
# # #     for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):
# # #         chunk_list.append(chunk)
# # #         progress_bar.update(1)
# # #     progress_bar.close()
# # #     return pd.concat(chunk_list, axis=0)

# # # def load_yaml(file_path):
# # #     with open(file_path, 'r') as file:
# # #         return yaml.safe_load(file)

# # # def save_yaml(data, file_path):
# # #     os.makedirs(os.path.dirname(file_path), exist_ok=True)
# # #     with open(file_path, 'w') as file:
# # #         yaml.safe_dump(data, file)

# # # def load_json_file(filepath):
# # #     try:
# # #         with open(filepath, 'r') as file:
# # #             return json.load(file)
# # #     except json.JSONDecodeError as e:
# # #         print(f"Error decoding JSON from file {filepath}: {e}")
# # #         return None
# # #     except FileNotFoundError:
# # #         return {}

# # # def save_json_file(data, filepath):
# # #     os.makedirs(os.path.dirname(filepath), exist_ok=True)
# # #     with open(filepath, 'w') as file:
# # #         json.dump(data, file, indent=4, default=convert_to_native_types)

# # # def clean_json_file(filepath):
# # #     data = load_json_file(filepath)
# # #     if data:
# # #         cleaned_data = clean_balance_format(data)
# # #         save_json_file(cleaned_data, filepath)

# # # def convert_to_native_types(data):
# # #     if isinstance(data, np.integer):
# # #         return int(data)
# # #     elif isinstance(data, np.floating):
# # #         return float(data)
# # #     elif isinstance(data, np.ndarray):
# # #         return data.tolist()
# # #     elif isinstance(data, dict):
# # #         return {k: convert_to_native_types(v) for k, v in data.items()}
# # #     elif isinstance(data, list):
# # #         return [convert_to_native_types(v) for v in data]
# # #     else:
# # #         return data

