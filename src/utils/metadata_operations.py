# src/utils/metadata_operations.py

import yaml
from src.utils.file_operations import load_yaml, save_yaml, convert_to_native_types, load_json_file
from datetime import datetime
import shutil
import os

def load_metadata(paths):
    return load_yaml(paths['config']['feature_metadata'])

def save_metadata(metadata, paths):
    save_yaml(metadata, paths['config']['feature_metadata'])

def update_feature_metadata(feature_metadata, feature, updates):
    if feature not in feature_metadata["features"]:
        feature_metadata["features"][feature] = {}
    for key, value in updates.items():
        if isinstance(value, dict):
            if key not in feature_metadata["features"][feature]:
                feature_metadata["features"][feature][key] = {}
            for sub_key, sub_value in value.items():
                feature_metadata["features"][feature][key][sub_key] = sub_value
        else:
            feature_metadata["features"][feature][key] = value
    return feature_metadata

def initialize_feature_metadata(schema_path):
    schema = load_yaml(schema_path)
    feature_metadata = {"features": {}}
    for attribute, default_value in schema["default_attributes"].items():
        feature_metadata[attribute] = default_value
    return feature_metadata

def ensure_metadata_completeness(metadata, schema):
    for feature in metadata['features']:
        for attribute, default_value in schema['default_attributes'].items():
            if attribute not in metadata['features'][feature]:
                metadata['features'][feature][attribute] = default_value
    return metadata

def update_metadata_with_data_types(metadata, feature_data_types, attribute_name):
    for item in feature_data_types:
        feature = item['Feature']
        data_type = item[attribute_name]
        if feature in metadata['features']:
            metadata['features'][feature][attribute_name] = data_type
    return metadata

def determine_feature_type(feature, metadata):
    classified_type = metadata['features'][feature].get('classified_data_type', '')
    if classified_type == 'binary':
        return 'binary'
    if classified_type == 'categorical':
        return 'categorical'
    example_values = metadata['features'][feature].get('example_values', [])
    if all(isinstance(val, (int, float)) for val in example_values):
        if len(example_values) > 0 and isinstance(example_values[0], int):
            return 'categorical'
    return 'numerical'

def backup_metadata(paths):
    backup_dir = os.path.join('config', 'backup')
    os.makedirs(backup_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    backup_path = os.path.join(backup_dir, f'feature_metadata_{timestamp}.yaml')
    shutil.copy(paths['config']['feature_metadata'], backup_path)
    print(f"Backup created at {backup_path}")

def update_metadata_with_results(metadata, schema, results):
    if 'data_overview' in results and results['data_overview']:
        metadata['data_overview'] = results['data_overview']

    if 'data_types' in results:
        for feature, dtype in results['data_types'].items():
            metadata = update_feature_metadata(metadata, feature, {'technical_data_type': dtype})

    if 'stat_summary' in results:
        for feature, stats in results['stat_summary'].items():
            metadata = update_feature_metadata(metadata, feature, {'summary_statistics': stats})

    if 'missing_values' in results:
        for feature, missing_data in results['missing_values'].items():
            metadata = update_feature_metadata(metadata, feature, {'missing_values': missing_data})

    if 'feature_balance' in results:
        for feature, balance_data in results['feature_balance'].items():
            metadata = update_feature_metadata(metadata, feature, {'balance': {'most_common_value_weight': balance_data['most_common_value_weight']}})

    if 'correlations' in results:
        for feature, correlation_data in results['correlations'].items():
            metadata = update_feature_metadata(metadata, feature, {'correlation_with_other_features': correlation_data})

    if 'target_correlations' in results:
        for feature, correlation in results['target_correlations'].items():
            metadata = update_feature_metadata(metadata, feature, {'correlation_with_target': correlation})

    return metadata

def update_metadata_with_descriptions(metadata, descriptions_data, schema):
    for feature, details in descriptions_data['features'].items():
        metadata = update_feature_metadata(metadata, feature, {
            'description': details['description'],
            'security_context': details['security_context']
        })
    return metadata

def classify_and_update_features(train_sample, metadata, schema):
    from src.analysis.data_understanding import feature_classification

    binary_features_auto, categorical_features_auto, numerical_features_auto = feature_classification(train_sample)

    for feature in binary_features_auto:
        metadata = update_feature_metadata(metadata, feature, {'classified_data_type': 'binary'})

    for feature in categorical_features_auto:
        metadata = update_feature_metadata(metadata, feature, {'classified_data_type': 'categorical'})

    for feature in numerical_features_auto:
        metadata = update_feature_metadata(metadata, feature, {'classified_data_type': 'numerical'})

    return metadata

def update_example_values(metadata, data_types, train_sample):
    def select_example_values(feature, dtype, dataframe):
        if dtype in ['int64', 'float64']:
            example_values = [
                dataframe[feature].min(),
                dataframe[feature].max(),
                dataframe[feature].mean(),
                dataframe[feature].median(),
                dataframe[feature].std()
            ]
        elif dtype == 'object':
            example_values = dataframe[feature].value_counts().index.tolist()[:5]
        else:
            example_values = dataframe[feature].unique().tolist()
        return example_values

    for feature, dtype in data_types.items():
        example_values = select_example_values(feature, dtype, train_sample)
        metadata = update_feature_metadata(metadata, feature, {'example_values': example_values})
    
    return metadata

def save_updated_metadata(metadata, paths, schema, target_variable_analysis):
    metadata = ensure_metadata_completeness(metadata, schema)
    metadata = convert_to_native_types(metadata)
    metadata = {'target_variable_analysis': target_variable_analysis, **metadata}
    save_metadata(metadata, paths)

def load_analysis_results(analysis_results_dir, json_files):
    return {file: load_json_file(os.path.join(analysis_results_dir, file)) for file in json_files}

def display_metadata(metadata):
    print("\n--- Metadata to be stored in config/feature_metadata.yaml ---\n")
    print(yaml.dump(metadata, default_flow_style=False))








# # src/utils/metadata_operations.py

# from src.utils.file_operations import load_yaml, save_yaml

# def load_metadata(paths):
#     return load_yaml(paths['config']['feature_metadata'])

# def save_metadata(metadata, paths):
#     save_yaml(metadata, paths['config']['feature_metadata'])

# def update_feature_metadata(feature_metadata, feature, updates):
#     if feature not in feature_metadata["features"]:
#         feature_metadata["features"][feature] = {}
#     for key, value in updates.items():
#         if isinstance(value, dict):
#             if key not in feature_metadata["features"][feature]:
#                 feature_metadata["features"][feature][key] = {}
#             for sub_key, sub_value in value.items():
#                 feature_metadata["features"][feature][key][sub_key] = sub_value
#         else:
#             feature_metadata["features"][feature][key] = value
#     return feature_metadata

# def initialize_feature_metadata(schema_path):
#     schema = load_yaml(schema_path)
#     feature_metadata = {"features": {}}
#     for attribute, default_value in schema["default_attributes"].items():
#         feature_metadata[attribute] = default_value
#     return feature_metadata

# def ensure_metadata_completeness(metadata, schema):
#     for feature in metadata['features']:
#         for attribute, default_value in schema['default_attributes'].items():
#             if attribute not in metadata['features'][feature]:
#                 metadata['features'][feature][attribute] = default_value
#     return metadata

# def update_metadata_with_data_types(metadata, feature_data_types, attribute_name):
#     for item in feature_data_types:
#         feature = item['Feature']
#         data_type = item[attribute_name]
#         if feature in metadata['features']:
#             metadata['features'][feature][attribute_name] = data_type
#     return metadata

# def determine_feature_type(feature, metadata):
#     classified_type = metadata['features'][feature].get('classified_data_type', '')
#     if classified_type == 'binary':
#         return 'binary'
#     if classified_type == 'categorical':
#         return 'categorical'
#     example_values = metadata['features'][feature].get('example_values', [])
#     if all(isinstance(val, (int, float)) for val in example_values):
#         if len(example_values) > 0 and isinstance(example_values[0], int):
#             return 'categorical'
#     return 'numerical'




# # # src/utils/metadata_operations.py

# # from src.utils.file_operations import load_yaml, save_yaml

# # from src.utils.file_operations import load_yaml, save_yaml

# # def load_metadata(paths):
# #     return load_yaml(paths['config']['feature_metadata'])

# # def save_metadata(metadata, paths):
# #     save_yaml(metadata, paths['config']['feature_metadata'])

# # def update_feature_metadata(feature_metadata, feature, updates):
# #     if feature not in feature_metadata["features"]:
# #         feature_metadata["features"][feature] = {}
# #     for key, value in updates.items():
# #         if isinstance(value, dict):
# #             if key not in feature_metadata["features"][feature]:
# #                 feature_metadata["features"][feature][key] = {}
# #             for sub_key, sub_value in value.items():
# #                 feature_metadata["features"][feature][key][sub_key] = sub_value
# #         else:
# #             feature_metadata["features"][feature][key] = value
# #     return feature_metadata

# # def initialize_feature_metadata(schema_path):
# #     schema = load_yaml(schema_path)
# #     feature_metadata = {"features": {}}
# #     for attribute, default_value in schema["default_attributes"].items():
# #         feature_metadata[attribute] = default_value
# #     return feature_metadata

# # def ensure_metadata_completeness(metadata, schema):
# #     for feature in metadata['features']:
# #         for attribute, default_value in schema['default_attributes'].items():
# #             if attribute not in metadata['features'][feature]:
# #                 metadata['features'][feature][attribute] = default_value
# #     return metadata

# # def update_metadata_with_data_types(metadata, feature_data_types, attribute_name):
# #     for item in feature_data_types:
# #         feature = item['Feature']
# #         data_type = item[attribute_name]
# #         if feature in metadata['features']:
# #             metadata['features'][feature][attribute_name] = data_type
# #     return metadata

# # def determine_feature_type(feature, metadata):
# #     classified_type = metadata['features'][feature].get('classified_data_type', '')
# #     if classified_type == 'binary':
# #         return 'binary'
# #     if classified_type == 'categorical':
# #         return 'categorical'
# #     example_values = metadata['features'][feature].get('example_values', [])
# #     if all(isinstance(val, (int, float)) for val in example_values):
# #         if len(example_values) > 0 and isinstance(example_values[0], int):
# #             return 'categorical'
# #     return 'numerical'





