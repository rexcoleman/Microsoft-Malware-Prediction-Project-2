# src/utils/data_preparation_utils.py

import pandas as pd
from src.utils.data_loading_utils import read_csv_with_progress

def load_and_prepare_data(paths):
    """
    Load sample data and metadata.

    Parameters:
    paths (dict): Dictionary containing file paths.

    Returns:
    tuple: DataFrames for train sample, metadata dictionary, and paths dictionary.
    """
    try:
        train_sample = pd.read_csv(paths['data']['train_sample'])
        metadata = load_metadata(paths['config']['feature_metadata'])
        return train_sample, metadata, paths
    except Exception as e:
        print(f"Error loading data and metadata: {e}")
        raise

# src/utils/data_preparation_utils.py

import os
import pandas as pd

# src/utils/data_preparation_utils.py

import os
import pandas as pd

def create_feature_classification_comparison_table(train_sample, metadata_path):
    """
    Create or load the comparison table for feature classification.

    Parameters:
    train_sample (pd.DataFrame): The training sample DataFrame.
    metadata_path (str): Path to the feature metadata file.

    Returns:
    pd.DataFrame: The prepared comparison table.
    """
    try:
        # Load feature metadata
        metadata = pd.read_csv(metadata_path)
        
        # Create or load the comparison table
        output_dir = os.path.join('reports', 'manual_review_and_update')
        os.makedirs(output_dir, exist_ok=True)
        comparison_table_path = os.path.join(output_dir, 'feature_classification_manual_review_and_update.csv')
        
        if os.path.exists(comparison_table_path):
            comparison_table = pd.read_csv(comparison_table_path)
        else:
            # Initialize comparison table if it doesn't exist
            comparison_table = pd.DataFrame(columns=['Feature', 'Previously Analyzed Type', 'Newly Analyzed Type', 'Discrepancy', 'Manual Review and Update', 'Notes'])
            comparison_table['Feature'] = train_sample.columns
            comparison_table['Previously Analyzed Type'] = metadata['classified_data_type']
        
        return comparison_table
    except Exception as e:
        print(f"Error creating feature classification comparison table: {e}")
        raise
 
def prepare_comparison_table(train_sample, metadata):
    """
    Prepare the comparison table for manual review and update.

    Parameters:
    train_sample (pd.DataFrame): The training sample DataFrame.
    metadata (dict): Feature metadata.

    Returns:
    pd.DataFrame: Prepared comparison table.
    """
    try:
        output_dir = os.path.join('reports', 'manual_review_and_update')
        comparison_table_path = os.path.join(output_dir, 'feature_classification_manual_review_and_update.csv')
        comparison_table = create_or_load_comparison_table(train_sample, metadata, comparison_table_path)
        comparison_table = ensure_all_features_in_comparison_table(train_sample, comparison_table, metadata, comparison_table_path)

        # Check if 'Manual Review and Update' and 'Notes' columns exist before dropping
        columns_to_drop = [col for col in ['Manual Review and Update', 'Notes'] if col in comparison_table.columns]
        return comparison_table.drop(columns=columns_to_drop)
    except Exception as e:
        print(f"Error preparing comparison table: {e}")
        raise






# def generate_sample_data(file_path, stratify_by, nrows=10000):
#     """Generate a stratified random sample of the dataset with the specified number of rows."""
#     data = read_csv_with_progress(file_path)
#     n_samples_per_class = nrows // data[stratify_by].nunique()
#     sample_data = data.groupby(stratify_by, group_keys=False).apply(lambda x: x.sample(n=min(len(x), n_samples_per_class), random_state=42))
#     return sample_data.reset_index(drop=True)

# def generate_test_sample_data(train_file_path, test_file_path, stratify_by, nrows=10000):
#     """Generate a stratified random sample of the test dataset based on the distribution of the train dataset."""
#     train_data = read_csv_with_progress(train_file_path)
#     test_data = read_csv_with_progress(test_file_path)

#     # Get stratified sample proportions from the train data
#     stratified_sample = train_data.groupby(stratify_by, group_keys=False).apply(lambda x: x.sample(n=int(nrows * (len(x) / len(train_data))), random_state=42))

#     # Merge with the test data
#     test_sample = test_data.sample(n=nrows, random_state=42)
#     test_sample[stratify_by] = stratified_sample[stratify_by].values[:len(test_sample)]

#     return test_sample