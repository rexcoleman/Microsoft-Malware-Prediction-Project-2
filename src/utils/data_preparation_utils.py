# src/data/data_preparation.py

import pandas as pd
from src.utils.data_loading_utils import read_csv_with_progress

def generate_sample_data(file_path, stratify_by, nrows=10000):
    """Generate a stratified random sample of the dataset with the specified number of rows."""
    data = read_csv_with_progress(file_path)
    n_samples_per_class = nrows // data[stratify_by].nunique()
    sample_data = data.groupby(stratify_by, group_keys=False).apply(lambda x: x.sample(n=min(len(x), n_samples_per_class), random_state=42))
    return sample_data.reset_index(drop=True)

def generate_test_sample_data(train_file_path, test_file_path, stratify_by, nrows=10000):
    """Generate a stratified random sample of the test dataset based on the distribution of the train dataset."""
    train_data = read_csv_with_progress(train_file_path)
    test_data = read_csv_with_progress(test_file_path)

    # Get stratified sample proportions from the train data
    stratified_sample = train_data.groupby(stratify_by, group_keys=False).apply(lambda x: x.sample(n=int(nrows * (len(x) / len(train_data))), random_state=42))

    # Merge with the test data
    test_sample = test_data.sample(n=nrows, random_state=42)
    test_sample[stratify_by] = stratified_sample[stratify_by].values[:len(test_sample)]

    return test_sample
