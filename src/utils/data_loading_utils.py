# src/utils/data_loading_utils.py

import pandas as pd
import os
from tqdm.notebook import tqdm

def read_csv_with_progress(file_path, chunksize=10000, sample_size=None):
    total_lines = sum(1 for _ in open(file_path)) - 1  # Calculate total lines in the file
    print(f"Total lines: {total_lines}")
    
    if sample_size:
        # Load a sample of the data
        chunks = []
        for chunk in tqdm(pd.read_csv(file_path, chunksize=chunksize, low_memory=False), desc="Loading data"):
            chunks.append(chunk)
            if len(chunks) * chunksize >= sample_size:
                break
        return pd.concat(chunks, axis=0).head(sample_size)
    else:
        # Load the full dataset
        chunk_list = []
        for chunk in tqdm(pd.read_csv(file_path, chunksize=chunksize, low_memory=False), total=total_lines // chunksize + 1, desc="Loading data"):
            chunk_list.append(chunk)
        return pd.concat(chunk_list, axis=0)

def save_dataframe_with_progress(df, path):
    total_rows = df.shape[0]
    chunk_size = 1000  # Adjust as needed for performance
    chunks = [df[i:i + chunk_size] for i in range(0, total_rows, chunk_size)]
    
    for chunk in tqdm(chunks, desc=f"Saving {os.path.basename(path)}", total=len(chunks)):
        mode = 'w' if chunk is chunks[0] else 'a'
        header = True if chunk is chunks[0] else False
        chunk.to_csv(path, mode=mode, header=header, index=False)
