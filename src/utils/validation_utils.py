# src/utils/validation_utils.py

import pandas as pd
from tqdm.notebook import tqdm

def validate_stratification_with_progress(original_df, sample_df, stratify_by):
    """
    Validate that the stratification of the sample matches the original dataset.
    
    Parameters:
    original_df (pd.DataFrame): The original dataframe.
    sample_df (pd.DataFrame): The sampled dataframe.
    stratify_by (str): The column to stratify by.
    
    Returns:
    bool: True if stratification is correct, False otherwise.
    """
    if stratify_by not in original_df.columns or stratify_by not in sample_df.columns:
        raise KeyError(f"Column '{stratify_by}' not found in one of the dataframes.")
    
    original_distribution = original_df[stratify_by].value_counts(normalize=True)
    sample_distribution = sample_df[stratify_by].value_counts(normalize=True)
    
    comparison_df = pd.DataFrame({
        'Original': original_distribution,
        'Sample': sample_distribution
    })
    
    progress_bar = tqdm(total=len(comparison_df), desc="Validating stratification")
    for i in range(len(comparison_df)):
        progress_bar.update(1)
    progress_bar.close()

    print("Class Distribution Comparison:")
    print(comparison_df)
    
    return comparison_df['Original'].equals(comparison_df['Sample'])

def validate_size_and_shape(original_df, sample_df):
    """
    Validate the size and shape of the sample dataset against the original dataset.
    
    Parameters:
    original_df (pd.DataFrame): The original dataframe.
    sample_df (pd.DataFrame): The sampled dataframe.
    """
    print(f"Original dataset shape: {original_df.shape}")
    print(f"Sample dataset shape: {sample_df.shape}")
    print(f"Sample dataset size: {sample_df.memory_usage(deep=True).sum() / (1024 * 1024):.2f} MB")

def ensure_all_features_in_comparison_table(dataframe, comparison_table, metadata, comparison_table_path):
    """
    Ensure all features in the dataset are included in the comparison table.
    
    Parameters:
    dataframe (pd.DataFrame): The dataset.
    comparison_table (pd.DataFrame): The existing comparison table.
    metadata (dict): The feature metadata.
    comparison_table_path (str): The path to save the updated comparison table.
    
    Returns:
    pd.DataFrame: The updated comparison table.
    """
    # Extract existing features from the comparison table
    existing_features = comparison_table['Feature'].tolist()
    
    # Find missing features
    missing_features = [feature for feature in dataframe.columns if feature not in existing_features]
    
    # Create entries for missing features
    new_entries = []
    for feature in missing_features:
        classified_type = metadata['features'][feature].get('classified_data_type', 'Unknown')
        determined_type = determine_feature_type(feature, metadata)
        new_entries.append({
            'Feature': feature,
            'Previously Analyzed Type': classified_type,
            'Current Analyzed Type': determined_type,
            'Discrepancy': classified_type != determined_type,
            'Manual Review and Update': determined_type  # Initialize with current analyzed type
        })
    
    # Append new entries to the comparison table
    if new_entries:
        new_entries_df = pd.DataFrame(new_entries)
        comparison_table = pd.concat([comparison_table, new_entries_df], ignore_index=True)
        comparison_table.sort_values(by=['Discrepancy', 'Previously Analyzed Type'], ascending=[False, True], inplace=True)
    
    # Save the updated comparison table
    comparison_table.to_csv(comparison_table_path, index=False)
    
    # Print validation results
    print(f"Total features in the dataset: {len(dataframe.columns)}")
    print(f"Total features in the comparison table: {comparison_table.shape[0]}")
    print(f"Missing features added: {len(missing_features)}")
    
    return comparison_table