# src/utils/sample_data_generation.py

import os
import logging
import pandas as pd
from src.config_loader import load_paths
from src.data.data_preparation import generate_sample_data
from src.utils.file_operations import save_dataframe_with_progress, load_csv_with_progress
from src.utils.validation_utils import validate_stratification_with_progress, validate_size_and_shape
from src.utils.display_utils import display_dataframe_as_html

def load_configuration_paths():
    """
    Load configuration paths using the load_paths function.

    Returns:
    dict: A dictionary containing file paths.
    """
    return load_paths()

def generate_and_save_samples(train_data_path, test_data_path, intermediate_data_path, stratify_by, nrows=10000):
    """
    Generate and save sample datasets.

    Parameters:
    train_data_path (str): Path to the raw training data.
    test_data_path (str): Path to the raw testing data.
    intermediate_data_path (str): Path to save the intermediate data.
    stratify_by (str): Column to stratify by.
    nrows (int): Number of rows for the sample dataset.
    """
    try:
        train_sample = generate_sample_data(train_data_path, nrows=nrows, stratify_by=stratify_by)
        test_sample = generate_sample_data(test_data_path, nrows=nrows)
        
        save_dataframe_with_progress(train_sample, os.path.join(intermediate_data_path, "train_sample.csv"))
        save_dataframe_with_progress(test_sample, os.path.join(intermediate_data_path, "test_sample.csv"))
        
        logging.info(f"Sample train data saved to: {os.path.join(intermediate_data_path, 'train_sample.csv')}")
        logging.info(f"Sample test data saved to: {os.path.join(intermediate_data_path, 'test_sample.csv')}")
    except Exception as e:
        logging.error(f"Error generating and saving samples: {e}")
        raise

def validate_samples(train_data_path, test_data_path, train_sample_path, test_sample_path, stratify_by):
    """
    Validate the generated sample datasets against the original datasets.

    Parameters:
    train_data_path (str): Path to the raw training data.
    test_data_path (str): Path to the raw testing data.
    train_sample_path (str): Path to the saved training sample.
    test_sample_path (str): Path to the saved testing sample.
    stratify_by (str): Column to stratify by.
    """
    try:
        original_train_data = load_csv_with_progress(train_data_path)
        original_test_data = load_csv_with_progress(test_data_path)
        train_sample = pd.read_csv(train_sample_path)
        test_sample = pd.read_csv(test_sample_path)

        # Validate that the target column exists in the original train dataset
        if stratify_by not in original_train_data.columns:
            raise KeyError(f"Column '{stratify_by}' not found in original train data.")

        # Validate stratification for the training data
        is_train_valid, comparison_df = validate_stratification_with_progress(original_train_data, train_sample, stratify_by)

        display_dataframe_as_html(comparison_df, title="Class Distribution Comparison", description="Comparison of class distributions between original and sample dataframes.")

        if is_train_valid:
            logging.info("Stratification is correct for the train sample.")
        else:
            logging.warning("Stratification is incorrect for the train sample.")

        # Validate size and shape for both train and test data
        original_train_shape, train_sample_shape, train_sample_size = validate_size_and_shape(original_train_data, train_sample)
        original_test_shape, test_sample_shape, test_sample_size = validate_size_and_shape(original_test_data, test_sample)

        # Display size and shape validation results
        validation_results = pd.DataFrame({
            "Dataset": ["Original Train", "Train Sample", "Original Test", "Test Sample"],
            "Shape": [original_train_shape, train_sample_shape, original_test_shape, test_sample_shape],
            "Size (MB)": ["N/A", train_sample_size, "N/A", test_sample_size]
        })

        display_dataframe_as_html(validation_results, title="Size and Shape Validation Results", description="Validation results of size and shape for original and sample datasets.")
    except Exception as e:
        logging.error(f"Error validating samples: {e}")
        raise
        
def main():
    """
    Main function to generate and validate sample data.
    """
    try:
        # Load configuration paths
        paths = load_configuration_paths()
        
        # Define parameters
        train_data_path = paths['data']['raw_train']
        test_data_path = paths['data']['raw_test']
        intermediate_data_path = paths['data']['intermediate']
        stratify_by = 'HasDetections'
        train_sample_path = os.path.join(intermediate_data_path, "train_sample.csv")
        test_sample_path = os.path.join(intermediate_data_path, "test_sample.csv")

        # Generate and save sample datasets
        generate_and_save_samples(train_data_path, test_data_path, intermediate_data_path, stratify_by)

        # Validate the generated samples
        validate_samples(train_data_path, test_data_path, train_sample_path, test_sample_path, stratify_by)
    except Exception as e:
        print(f"Error in main function: {e}")

if __name__ == "__main__":
    main()

