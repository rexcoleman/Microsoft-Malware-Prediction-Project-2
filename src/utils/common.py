import pandas as pd
import json
import yaml
import os
import numpy as np

def save_dataframe(df, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    df.to_csv(path, index=False)

def load_yaml(file_path):
    with open(file_path, 'r') as file:
        return yaml.safe_load(file)

def save_yaml(data, file_path):
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    with open(file_path, 'w') as file:
        yaml.safe_dump(data, file)

def update_feature_metadata(feature_metadata, feature, updates):
    if feature not in feature_metadata["features"]:
        feature_metadata["features"][feature] = {}
    for key, value in updates.items():
        if isinstance(value, dict):
            if key not in feature_metadata["features"][feature]:
                feature_metadata["features"][feature][key] = {}
            for sub_key, sub_value in value.items():
                feature_metadata["features"][feature][key][sub_key] = sub_value
        else:
            feature_metadata["features"][feature][key] = value
    return feature_metadata

def initialize_feature_metadata(schema_path):
    schema = load_yaml(schema_path)
    feature_metadata = {"features": {}}
    for attribute, default_value in schema["default_attributes"].items():
        feature_metadata[attribute] = default_value
    return feature_metadata

def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
    tables_dir = os.path.join(report_dir, 'tables')
    os.makedirs(tables_dir, exist_ok=True)

    train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
    test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

    with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
        yaml.safe_dump(imputation_strategies, file)

def ensure_directories_exist(config):
    directories = [
        config['data']['raw_train'],
        config['data']['raw_test'],
        config['data']['processed_train'],
        config['data']['processed_test'],
        config['reports']['univariate_numerical_summary'],
        config['reports']['univariate_numerical_plots'],
        config['reports']['univariate_categorical_summary'],
        config['reports']['univariate_categorical_plots'],
        config['reports']['figures']['missing_values']
    ]

    for directory in directories:
        os.makedirs(os.path.dirname(directory), exist_ok=True)

def load_json_file(filepath):
    try:
        with open(filepath, 'r') as file:
            return json.load(file)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from file {filepath}: {e}")
        return None
    except FileNotFoundError:
        return {}

def save_json_file(data, filepath):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w') as file:
        json.dump(data, file, indent=4, default=convert_to_native_types)

def clean_balance_format(data):
    if isinstance(data, dict):
        for feature, details in data.items():
            if isinstance(details, dict) and 'balance' in details:
                if isinstance(details['balance'], dict) and 'balance' in details['balance']:
                    details['balance'] = details['balance']['balance']
    return data

def clean_json_file(filepath):
    data = load_json_file(filepath)
    if data:
        cleaned_data = clean_balance_format(data)
        save_json_file(cleaned_data, filepath)

def convert_to_native_types(data):
    if isinstance(data, np.integer):
        return int(data)
    elif isinstance(data, np.floating):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif isinstance(data, dict):
        return {k: convert_to_native_types(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [convert_to_native_types(v) for v in data]
    else:
        return data

def save_missing_values_summary(df, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    df.to_csv(path, index=False)

def save_missing_values_correlation(data, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    save_json_file(data, path)

def save_missing_count_per_row(data, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    save_json_file(data, path)

def save_feature_importance(data, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    data.to_json(path, orient='records', lines=True)




# # src/utils/common.py

# import pandas as pd
# import json
# import yaml
# import os
# import numpy as np

# def save_dataframe(df, path):
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     df.to_csv(path, index=False)

# def load_yaml(file_path):
#     with open(file_path, 'r') as file:
#         return yaml.safe_load(file)

# def save_yaml(data, file_path):
#     os.makedirs(os.path.dirname(file_path), exist_ok=True)
#     with open(file_path, 'w') as file:
#         yaml.safe_dump(data, file)

# def update_feature_metadata(feature_metadata, feature, updates):
#     if feature not in feature_metadata["features"]:
#         feature_metadata["features"][feature] = {}
#     for key, value in updates.items():
#         if isinstance(value, dict):
#             if key not in feature_metadata["features"][feature]:
#                 feature_metadata["features"][feature][key] = {}
#             for sub_key, sub_value in value.items():
#                 feature_metadata["features"][feature][key][sub_key] = sub_value
#         else:
#             feature_metadata["features"][feature][key] = value
#     return feature_metadata

# def initialize_feature_metadata(schema_path):
#     schema = load_yaml(schema_path)
#     feature_metadata = {"features": {}}
#     for attribute, default_value in schema["default_attributes"].items():
#         feature_metadata[attribute] = default_value
#     return feature_metadata

# def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
#     tables_dir = os.path.join(report_dir, 'tables')
#     os.makedirs(tables_dir, exist_ok=True)

#     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
#     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

#     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
#         yaml.safe_dump(imputation_strategies, file)

# def ensure_directories_exist(config):
#     directories = [
#         config['data']['raw_train'],
#         config['data']['raw_test'],
#         config['data']['processed_train'],
#         config['data']['processed_test'],
#         config['reports']['univariate_numerical_summary'],
#         config['reports']['univariate_numerical_plots'],
#         config['reports']['univariate_categorical_summary'],
#         config['reports']['univariate_categorical_plots'],
#         config['reports']['figures']['missing_values']
#     ]

#     for directory in directories:
#         os.makedirs(os.path.dirname(directory), exist_ok=True)

# def load_json_file(filepath):
#     try:
#         with open(filepath, 'r') as file:
#             return json.load(file)
#     except json.JSONDecodeError as e:
#         print(f"Error decoding JSON from file {filepath}: {e}")
#         return None
#     except FileNotFoundError:
#         return {}

# def save_json_file(data, filepath):
#     os.makedirs(os.path.dirname(filepath), exist_ok=True)
#     with open(filepath, 'w') as file:
#         json.dump(data, file, indent=4)

# def clean_balance_format(data):
#     if isinstance(data, dict):
#         for feature, details in data.items():
#             if isinstance(details, dict) and 'balance' in details:
#                 if isinstance(details['balance'], dict) and 'balance' in details['balance']:
#                     details['balance'] = details['balance']['balance']
#     return data

# def clean_json_file(filepath):
#     data = load_json_file(filepath)
#     if data:
#         cleaned_data = clean_balance_format(data)
#         save_json_file(cleaned_data, filepath)

# def convert_to_native_types(data):
#     if isinstance(data, np.integer):
#         return int(data)
#     elif isinstance(data, np.floating):
#         return float(data)
#     elif isinstance(data, np.ndarray):
#         return data.tolist()
#     elif isinstance(data, dict):
#         return {k: convert_to_native_types(v) for k, v in data.items()}
#     elif isinstance(data, list):
#         return [convert_to_native_types(v) for v in data]
#     else:
#         return data

# # Clean the JSON file after generating the analysis results
# analysis_results_dir = 'reports/analysis_results'
# feature_balance_file = os.path.join(analysis_results_dir, 'feature_balance.json')
# clean_json_file(feature_balance_file)

# def save_missing_values_summary(df, path):
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     df.to_csv(path, index=False)

# def save_missing_values_correlation(data, path):
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     save_json_file(data, path)

# def save_missing_count_per_row(data, path):
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     save_json_file(data, path)

# def save_feature_importance(df, path):
#     os.makedirs(os.path.dirname(path), exist_ok=True)
#     df.to_csv(path, index=False)




# # # src/utils/common.py

# # import pandas as pd
# # import json
# # import yaml
# # import os
# # import numpy as np

# # def save_dataframe(df, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     df.to_csv(path, index=False)

# # def load_yaml(file_path):
# #     with open(file_path, 'r') as file:
# #         return yaml.safe_load(file)

# # def save_yaml(data, file_path):
# #     os.makedirs(os.path.dirname(file_path), exist_ok=True)
# #     with open(file_path, 'w') as file:
# #         yaml.safe_dump(data, file)

# # def update_feature_metadata(feature_metadata, feature, updates):
# #     if feature not in feature_metadata["features"]:
# #         feature_metadata["features"][feature] = {}
# #     for key, value in updates.items():
# #         if isinstance(value, dict):
# #             if key not in feature_metadata["features"][feature]:
# #                 feature_metadata["features"][feature][key] = {}
# #             for sub_key, sub_value in value.items():
# #                 feature_metadata["features"][feature][key][sub_key] = sub_value
# #         else:
# #             feature_metadata["features"][feature][key] = value
# #     return feature_metadata

# # def initialize_feature_metadata(schema_path):
# #     schema = load_yaml(schema_path)
# #     feature_metadata = {"features": {}}
# #     for attribute, default_value in schema["default_attributes"].items():
# #         feature_metadata[attribute] = default_value
# #     return feature_metadata

# # def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
# #     tables_dir = os.path.join(report_dir, 'tables')
# #     os.makedirs(tables_dir, exist_ok=True)

# #     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
# #     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

# #     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
# #         yaml.safe_dump(imputation_strategies, file)

# # def ensure_directories_exist(config):
# #     directories = [
# #         config['data']['raw_train'],
# #         config['data']['raw_test'],
# #         config['data']['processed_train'],
# #         config['data']['processed_test'],
# #         config['reports']['univariate_numerical_summary'],
# #         config['reports']['univariate_numerical_plots'],
# #         config['reports']['univariate_categorical_summary'],
# #         config['reports']['univariate_categorical_plots'],
# #         config['reports']['figures']['missing_values']
# #     ]

# #     for directory in directories:
# #         os.makedirs(os.path.dirname(directory), exist_ok=True)

# # def load_json_file(filepath):
# #     try:
# #         with open(filepath, 'r') as file:
# #             return json.load(file)
# #     except json.JSONDecodeError as e:
# #         print(f"Error decoding JSON from file {filepath}: {e}")
# #         return None
# #     except FileNotFoundError:
# #         return {}

# # def save_json_file(data, filepath):
# #     os.makedirs(os.path.dirname(filepath), exist_ok=True)
# #     with open(filepath, 'w') as file:
# #         json.dump(data, file, indent=4)

# # def clean_balance_format(data):
# #     if isinstance(data, dict):
# #         for feature, details in data.items():
# #             if isinstance(details, dict) and 'balance' in details:
# #                 if isinstance(details['balance'], dict) and 'balance' in details['balance']:
# #                     details['balance'] = details['balance']['balance']
# #     return data

# # def clean_json_file(filepath):
# #     data = load_json_file(filepath)
# #     if data:
# #         cleaned_data = clean_balance_format(data)
# #         save_json_file(cleaned_data, filepath)

# # def convert_to_native_types(data):
# #     if isinstance(data, np.integer):
# #         return int(data)
# #     elif isinstance(data, np.floating):
# #         return float(data)
# #     elif isinstance(data, np.ndarray):
# #         return data.tolist()
# #     elif isinstance(data, dict):
# #         return {k: convert_to_native_types(v) for k, v in data.items()}
# #     elif isinstance(data, list):
# #         return [convert_to_native_types(v) for v in data]
# #     else:
# #         return data

# # # Clean the JSON file after generating the analysis results
# # analysis_results_dir = 'reports/analysis_results'
# # feature_balance_file = os.path.join(analysis_results_dir, 'feature_balance.json')
# # clean_json_file(feature_balance_file)

# # def save_missing_values_summary(df, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     df.to_csv(path, index=False)

# # def save_missing_values_correlation(data, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     save_json_file(data, path)

# # def save_missing_count_per_row(data, path):
# #     os.makedirs(os.path.dirname(path), exist_ok=True)
# #     save_json_file(data, path)




# # # # src/utils/common.py

# # # import pandas as pd
# # # import json
# # # import yaml
# # # import os
# # # import numpy as np

# # # def save_dataframe(df, path):
# # #     df.to_csv(path, index=False)

# # # def load_yaml(file_path):
# # #     with open(file_path, 'r') as file:
# # #         return yaml.safe_load(file)

# # # def save_yaml(data, file_path):
# # #     with open(file_path, 'w') as file:
# # #         yaml.safe_dump(data, file)

# # # def update_feature_metadata(feature_metadata, feature, updates):
# # #     if feature not in feature_metadata["features"]:
# # #         feature_metadata["features"][feature] = {}
# # #     for key, value in updates.items():
# # #         if isinstance(value, dict):
# # #             if key not in feature_metadata["features"][feature]:
# # #                 feature_metadata["features"][feature][key] = {}
# # #             for sub_key, sub_value in value.items():
# # #                 feature_metadata["features"][feature][key][sub_key] = sub_value
# # #         else:
# # #             feature_metadata["features"][feature][key] = value
# # #     return feature_metadata

# # # def initialize_feature_metadata(schema_path):
# # #     schema = load_yaml(schema_path)
# # #     feature_metadata = {"features": {}}
# # #     for attribute, default_value in schema["default_attributes"].items():
# # #         feature_metadata[attribute] = default_value
# # #     return feature_metadata

# # # def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
# # #     tables_dir = os.path.join(report_dir, 'tables')
# # #     os.makedirs(tables_dir, exist_ok=True)

# # #     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
# # #     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

# # #     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
# # #         yaml.safe_dump(imputation_strategies, file)

# # # def ensure_directories_exist(config):
# # #     directories = [
# # #         config['data']['raw_train'],
# # #         config['data']['raw_test'],
# # #         config['data']['processed_train'],
# # #         config['data']['processed_test'],
# # #         config['reports']['univariate_numerical_summary'],
# # #         config['reports']['univariate_numerical_plots'],
# # #         config['reports']['univariate_categorical_summary'],
# # #         config['reports']['univariate_categorical_plots'],
# # #         config['reports']['figures']['missing_values']
# # #     ]

# # #     for directory in directories:
# # #         os.makedirs(os.path.dirname(directory), exist_ok=True)

# # # def load_json_file(filepath):
# # #     try:
# # #         with open(filepath, 'r') as file:
# # #             return json.load(file)
# # #     except json.JSONDecodeError as e:
# # #         print(f"Error decoding JSON from file {filepath}: {e}")
# # #         return None
# # #     except FileNotFoundError:
# # #         return {}

# # # def save_json_file(data, filepath):
# # #     with open(filepath, 'w') as file:
# # #         json.dump(data, file, indent=4)

# # # def clean_balance_format(data):
# # #     if isinstance(data, dict):
# # #         for feature, details in data.items():
# # #             if isinstance(details, dict) and 'balance' in details:
# # #                 if isinstance(details['balance'], dict) and 'balance' in details['balance']:
# # #                     details['balance'] = details['balance']['balance']
# # #     return data

# # # def clean_json_file(filepath):
# # #     data = load_json_file(filepath)
# # #     if data:
# # #         cleaned_data = clean_balance_format(data)
# # #         save_json_file(cleaned_data, filepath)

# # # def convert_to_native_types(data):
# # #     if isinstance(data, np.integer):
# # #         return int(data)
# # #     elif isinstance(data, np.floating):
# # #         return float(data)
# # #     elif isinstance(data, np.ndarray):
# # #         return data.tolist()
# # #     elif isinstance(data, dict):
# # #         return {k: convert_to_native_types(v) for k, v in data.items()}
# # #     elif isinstance(data, list):
# # #         return [convert_to_native_types(v) for v in data]
# # #     else:
# # #         return data

# # # # Clean the JSON file after generating the analysis results
# # # analysis_results_dir = 'reports/analysis_results'
# # # feature_balance_file = os.path.join(analysis_results_dir, 'feature_balance.json')
# # # clean_json_file(feature_balance_file)

# # # def save_missing_values_summary(df, path):
# # #     df.to_csv(path, index=False)

# # # def save_missing_values_correlation(data, path):
# # #     save_json_file(data, path)

# # # def save_missing_count_per_row(data, path):
# # #     save_json_file(data, path)



# # # # # src/utils/common.py

# # # # import pandas as pd
# # # # import json
# # # # import yaml
# # # # import os
# # # # import numpy as np

# # # # def save_dataframe(df, path):
# # # #     df.to_csv(path, index=False)

# # # # def load_yaml(file_path):
# # # #     with open(file_path, 'r') as file:
# # # #         return yaml.safe_load(file)

# # # # def save_yaml(data, file_path):
# # # #     with open(file_path, 'w') as file:
# # # #         yaml.safe_dump(data, file)

# # # # def update_feature_metadata(feature_metadata, feature, updates):
# # # #     if feature not in feature_metadata["features"]:
# # # #         feature_metadata["features"][feature] = {}
# # # #     for key, value in updates.items():
# # # #         if isinstance(value, dict):
# # # #             if key not in feature_metadata["features"][feature]:
# # # #                 feature_metadata["features"][feature][key] = {}
# # # #             for sub_key, sub_value in value.items():
# # # #                 feature_metadata["features"][feature][key][sub_key] = sub_value
# # # #         else:
# # # #             feature_metadata["features"][feature][key] = value
# # # #     return feature_metadata

# # # # def initialize_feature_metadata(schema_path):
# # # #     schema = load_yaml(schema_path)
# # # #     feature_metadata = {"features": {}}
# # # #     for attribute, default_value in schema["default_attributes"].items():
# # # #         feature_metadata[attribute] = default_value
# # # #     return feature_metadata

# # # # def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
# # # #     tables_dir = os.path.join(report_dir, 'tables')
# # # #     os.makedirs(tables_dir, exist_ok=True)

# # # #     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
# # # #     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

# # # #     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
# # # #         yaml.safe_dump(imputation_strategies, file)

# # # # def ensure_directories_exist(config):
# # # #     directories = [
# # # #         config['data']['raw_train'],
# # # #         config['data']['raw_test'],
# # # #         config['data']['processed_train'],
# # # #         config['data']['processed_test'],
# # # #         config['reports']['univariate_numerical_summary'],
# # # #         config['reports']['univariate_numerical_plots'],
# # # #         config['reports']['univariate_categorical_summary'],
# # # #         config['reports']['univariate_categorical_plots'],
# # # #         config['reports']['figures']['missing_values']
# # # #     ]

# # # #     for directory in directories:
# # # #         os.makedirs(os.path.dirname(directory), exist_ok=True)

# # # # def load_json_file(filepath):
# # # #     try:
# # # #         with open(filepath, 'r') as file:
# # # #             return json.load(file)
# # # #     except json.JSONDecodeError as e:
# # # #         print(f"Error decoding JSON from file {filepath}: {e}")
# # # #         return None
# # # #     except FileNotFoundError:
# # # #         return {}

# # # # def save_json_file(data, filepath):
# # # #     with open(filepath, 'w') as file:
# # # #         json.dump(data, file, indent=4)

# # # # def clean_balance_format(data):
# # # #     if isinstance(data, dict):
# # # #         for feature, details in data.items():
# # # #             if isinstance(details, dict) and 'balance' in details:
# # # #                 if isinstance(details['balance'], dict) and 'balance' in details['balance']:
# # # #                     details['balance'] = details['balance']['balance']
# # # #     return data

# # # # def clean_json_file(filepath):
# # # #     data = load_json_file(filepath)
# # # #     if data:
# # # #         cleaned_data = clean_balance_format(data)
# # # #         save_json_file(cleaned_data, filepath)

# # # # def convert_to_native_types(data):
# # # #     if isinstance(data, np.integer):
# # # #         return int(data)
# # # #     elif isinstance(data, np.floating):
# # # #         return float(data)
# # # #     elif isinstance(data, np.ndarray):
# # # #         return data.tolist()
# # # #     elif isinstance(data, dict):
# # # #         return {k: convert_to_native_types(v) for k, v in data.items()}
# # # #     elif isinstance(data, list):
# # # #         return [convert_to_native_types(v) for v in data]
# # # #     else:
# # # #         return data

# # # # # Clean the JSON file after generating the analysis results
# # # # analysis_results_dir = 'reports/analysis_results'
# # # # feature_balance_file = os.path.join(analysis_results_dir, 'feature_balance.json')
# # # # clean_json_file(feature_balance_file)

# # # # def save_missing_values_summary(df, path):
# # # #     df.to_csv(path, index=False)

# # # # def save_missing_values_correlation(data, path):
# # # #     save_json_file(data, path)

# # # # def save_missing_count_per_row(data, path):
# # # #     save_json_file(data, path)




# # # # # # src/utils/common.py

# # # # # import pandas as pd
# # # # # import json
# # # # # import yaml
# # # # # import os
# # # # # import numpy as np

# # # # # def save_dataframe(df, path):
# # # # #     df.to_csv(path, index=False)

# # # # # def load_yaml(file_path):
# # # # #     with open(file_path, 'r') as file:
# # # # #         return yaml.safe_load(file)

# # # # # def save_yaml(data, file_path):
# # # # #     with open(file_path, 'w') as file:
# # # # #         yaml.safe_dump(data, file)

# # # # # def update_feature_metadata(feature_metadata, feature, updates):
# # # # #     if feature not in feature_metadata["features"]:
# # # # #         feature_metadata["features"][feature] = {}
# # # # #     for key, value in updates.items():
# # # # #         if isinstance(value, dict):
# # # # #             if key not in feature_metadata["features"][feature]:
# # # # #                 feature_metadata["features"][feature][key] = {}
# # # # #             for sub_key, sub_value in value.items():
# # # # #                 feature_metadata["features"][feature][key][sub_key] = sub_value
# # # # #         else:
# # # # #             feature_metadata["features"][feature][key] = value
# # # # #     return feature_metadata

# # # # # def initialize_feature_metadata(schema_path):
# # # # #     schema = load_yaml(schema_path)
# # # # #     feature_metadata = {"features": {}}
# # # # #     for attribute, default_value in schema["default_attributes"].items():
# # # # #         feature_metadata[attribute] = default_value
# # # # #     return feature_metadata

# # # # # def save_analysis_results(train_summary_stats, test_summary_stats, imputation_strategies, report_dir):
# # # # #     tables_dir = os.path.join(report_dir, 'tables')
# # # # #     os.makedirs(tables_dir, exist_ok=True)

# # # # #     train_summary_stats.to_csv(os.path.join(tables_dir, 'train_summary_statistics.csv'), index=False)
# # # # #     test_summary_stats.to_csv(os.path.join(tables_dir, 'test_summary_statistics.csv'), index=False)

# # # # #     with open(os.path.join(tables_dir, 'imputation_strategies.yaml'), 'w') as file:
# # # # #         yaml.safe_dump(imputation_strategies, file)

# # # # # def ensure_directories_exist(config):
# # # # #     directories = [
# # # # #         config['data']['raw_train'],
# # # # #         config['data']['raw_test'],
# # # # #         config['data']['processed_train'],
# # # # #         config['data']['processed_test'],
# # # # #         config['reports']['univariate_numerical_summary'],
# # # # #         config['reports']['univariate_numerical_plots'],
# # # # #         config['reports']['univariate_categorical_summary'],
# # # # #         config['reports']['univariate_categorical_plots']
# # # # #     ]

# # # # #     for directory in directories:
# # # # #         os.makedirs(os.path.dirname(directory), exist_ok=True)

# # # # # def load_json_file(filepath):
# # # # #     try:
# # # # #         with open(filepath, 'r') as file:
# # # # #             return json.load(file)
# # # # #     except json.JSONDecodeError as e:
# # # # #         print(f"Error decoding JSON from file {filepath}: {e}")
# # # # #         return None
# # # # #     except FileNotFoundError:
# # # # #         return {}

# # # # # def save_json_file(data, filepath):
# # # # #     with open(filepath, 'w') as file:
# # # # #         json.dump(data, file, indent=4)

# # # # # def clean_balance_format(data):
# # # # #     if isinstance(data, dict):
# # # # #         for feature, details in data.items():
# # # # #             if isinstance(details, dict) and 'balance' in details:
# # # # #                 if isinstance(details['balance'], dict) and 'balance' in details['balance']:
# # # # #                     details['balance'] = details['balance']['balance']
# # # # #     return data

# # # # # def clean_json_file(filepath):
# # # # #     data = load_json_file(filepath)
# # # # #     if data:
# # # # #         cleaned_data = clean_balance_format(data)
# # # # #         save_json_file(cleaned_data, filepath)

# # # # # def convert_to_native_types(data):
# # # # #     if isinstance(data, np.integer):
# # # # #         return int(data)
# # # # #     elif isinstance(data, np.floating):
# # # # #         return float(data)
# # # # #     elif isinstance(data, np.ndarray):
# # # # #         return data.tolist()
# # # # #     elif isinstance(data, dict):
# # # # #         return {k: convert_to_native_types(v) for k, v in data.items()}
# # # # #     elif isinstance(data, list):
# # # # #         return [convert_to_native_types(v) for v in data]
# # # # #     else:
# # # # #         return data

# # # # # # Clean the JSON file after generating the analysis results
# # # # # analysis_results_dir = 'reports/analysis_results'
# # # # # feature_balance_file = os.path.join(analysis_results_dir, 'feature_balance.json')
# # # # # clean_json_file(feature_balance_file)


