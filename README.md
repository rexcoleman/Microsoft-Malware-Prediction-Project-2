# Microsoft Malware Prediction Project

## Overview
This project aims to perform a comprehensive exploratory data analysis (EDA) and predictive modeling on the Microsoft Malware Prediction dataset. The goal is to identify significant patterns and build robust predictive models for malware detection.

## Project Structure
```plaintext
├── README.md
├── config/
│   ├── dtypes.yaml
│   ├── feature_metadata.yaml
│   ├── models.yaml
│   ├── paths.yaml
│   └── preprocessing.yaml
├── data/
│   ├── external/
│   ├── processed/
│   ├── raw/
│   │   ├── sample_submission.csv
│   │   ├── test.csv
│   │   ├── train.csv
├── notebooks/
│   ├── 00_initial_analysis.ipynb
├── reports/
│   └── figures/
├── requirements.txt
└── src/
    ├── __init__.py
    ├── config_loader.py
    ├── data/
    │   ├── __init__.py
    │   ├── clean_data.py
    │   ├── load_data.py
    ├── features/
    │   ├── __init__.py
    │   ├── build_features.py
    │   └── scale_features.py
    ├── initial_analysis/
    │   ├── __init__.py
    │   └── initial_analysis.py
    ├── tests/
    │   ├── __init__.py
    │   ├── test_clean_data.py
    │   ├── test_data.py
    │   ├── test_features.py
    │   └── test_visualize.py
    ├── validation/
    │   ├── __init__.py
    │   └── validate.py
    └── visualization/
        ├── __init__.py
        └── visualize.py

```

Here is how to distinguish between the notebooks based on their purposes in the comprehensive EDA approach:

00_initial_analysis.ipynb
Purpose: Initial Data Understanding and Integration

Tasks:
Examine basic properties like the number of features, records, types of variables, and initial missing data assessment.
Perform initial data loading and sampling.
Generate and print summary statistics for the train and test datasets.
Perform correlation analysis to understand feature relationships.
Suggest initial imputation strategies based on the summary statistics and correlation analysis.
01_data_exploration.ipynb
Purpose: Exploratory Data Analysis (EDA)

Tasks:
Univariate Analysis: Analyze the distribution of each variable including central tendency, variance, and outliers.
Bivariate and Multivariate Analysis: Explore relationships between features and the target variable (HasDetections).
Time Series Exploration: Analyze time-related features to identify trends and seasonal effects.
Visualize data distributions, relationships, and patterns using various plots and charts.
02_data_cleaning.ipynb
Purpose: Data Cleaning

Tasks:
Handle missing values using initial imputation strategies.
Correct noise and errors in the data.
Remove duplicates, especially concerning the unique MachineIdentifier.
Save the cleaned data for further analysis.
02a_iterative_cleaning.ipynb
Purpose: Iterative Data Cleaning and Validation

Tasks:
Refine imputation strategies (e.g., using KNN imputation for numeric columns).
Validate the imputation by performing post-imputation checks to ensure no missing values remain.
Conduct cross-validation to ensure model performance is not degraded by imputation.
Iterate on imputation strategies as needed based on new insights or data.
Update the config/imputation_strategies.yaml file with refined imputation strategies.
Comprehensive EDA Approach Implementation
Initial Data Understanding and Integration (00_initial_analysis.ipynb)

Examine basic properties, perform initial analysis, and suggest imputation strategies.
Exploratory Data Analysis (01_data_exploration.ipynb)

Conduct univariate, bivariate, and multivariate analysis, including time series exploration and visualization.
Data Cleaning (02_data_cleaning.ipynb)

Handle missing values, correct noise, and remove duplicates based on initial imputation strategies.
Iterative Data Cleaning and Validation (02a_iterative_cleaning.ipynb)

Refine and validate imputation strategies, ensuring data quality and updating the config as necessary.








## Data Understanding and Initial Analysis

### Objective
To gain a preliminary understanding of the dataset, identify any issues with data quality, and suggest strategies for handling missing values.

### Configuration and Data Loading
- **Configuration Files**: Configuration files for paths, feature metadata, and other settings were loaded successfully.
- **Data Loading**: A subset of the training and test datasets (100,000 rows each) was loaded for initial analysis.

### Summary Statistics
- **Count and Unique Values**: Understanding the number of observations and unique entries for categorical features.
- **Top Frequent Values**: Identifying the most common values in categorical features.
- **Statistical Measures**: Mean, standard deviation, minimum, maximum, and quartile values for numerical features.
- **Missing Values**: The number and percentage of missing values for each feature.

#### Key Findings
- **Uniqueness**: Features like `MachineIdentifier` have unique values for each record, confirming the uniqueness of each entry.
- **Categorical Features**: Features like `ProductName` and `EngineVersion` have a limited set of unique values, indicating potential for feature encoding.
- **Missing Values**: Numerical features like `Census_IsAlwaysOnAlwaysConnectedCapable` and `Wdft_IsGamer` have missing values that need to be addressed.

### Correlation Analysis
- **Correlation Matrix**: A correlation matrix was generated to identify relationships between features and the target variable (`HasDetections`).
- **Multicollinearity**: Identifying any multicollinearity issues which might need to be addressed in further analysis.

### Imputation Strategies
Based on the summary statistics and correlation analysis, imputation strategies were suggested and implemented for handling missing values. The strategies include using mean, median, and mode imputation for different features based on their type and importance.

#### Imputation Strategies
```yaml
imputation_strategies:
  RtpStateBitfield: mean
  DefaultBrowsersIdentifier: mean
  AVProductStatesIdentifier: median
  AVProductsInstalled: median
  AVProductsEnabled: mean
  CityIdentifier: mean
  OrganizationIdentifier: mean
  GeoNameIdentifier: mean
  OsBuildLab: mode
  IsProtected: mean
  PuaMode: mode
  SMode: mean
  IeVerIdentifier: mean
  SmartScreen: mode
  Firewall: mean
  UacLuaenable: mean
  Census_OEMNameIdentifier: mean
  Census_OEMModelIdentifier: mean
  Census_ProcessorCoreCount: mean
  Census_ProcessorManufacturerIdentifier: mean
  Census_ProcessorModelIdentifier: mean
  Census_ProcessorClass: mode
  Census_PrimaryDiskTotalCapacity: mean
  Census_PrimaryDiskTypeName: mode
  Census_SystemVolumeTotalCapacity: mean
  Census_TotalPhysicalRAM: mean
  Census_ChassisTypeName: mode
  Census_InternalPrimaryDiagonalDisplaySizeInInches: mean
  Census_InternalPrimaryDisplayResolutionHorizontal: mean
  Census_InternalPrimaryDisplayResolutionVertical: mean
  Census_InternalBatteryType: mode
  Census_InternalBatteryNumberOfCharges: mean
  Census_OSInstallLanguageIdentifier: mean
  Census_IsFlightingInternal: mean
  Census_IsFlightsDisabled: mean
  Census_ThresholdOptIn: mean
  Census_FirmwareManufacturerIdentifier: mean
  Census_FirmwareVersionIdentifier: mean
  Census_IsWIMBootEnabled: mean
  Census_IsVirtualDevice: mean
  Census_IsAlwaysOnAlwaysConnectedCapable: mean
  Wdft_IsGamer: mean
  Wdft_RegionIdentifier: mean
```




### 00_initial_analysis.ipynb

**Purpose**: Initial Data Analysis and Understanding

**Tasks**:
1. **Data Loading**:
   - Load a sample of the training and test datasets for initial analysis.
   - Define data types to avoid mixed type warnings during loading.

2. **Summary Statistics**:
   - Generate summary statistics for the training and test datasets.
   - Provide a high-level overview of each feature, including counts, unique values, top values, frequency, mean, standard deviation, min, max, and percentiles.

3. **Correlation Analysis**:
   - Perform correlation analysis to identify relationships between features.
   - Create a correlation matrix to visualize the strength and direction of relationships between numerical features.

4. **Imputation Strategy**:
   - Suggest imputation strategies for handling missing values based on summary statistics and correlation analysis.
   - Update the imputation strategies configuration file with the suggested strategies.

5. **Initial Cleaning**:
   - Apply initial cleaning steps to handle missing values and prepare the dataset for further exploration.

6. **Save Results**:
   - Save the summary statistics and updated imputation strategies for reference in subsequent steps.

**Outcome**: Gain an initial understanding of the dataset, identify key characteristics, and prepare for detailed Exploratory Data Analysis (EDA) and data cleaning.

### 01_data_exploration.ipynb

**Purpose**: Exploratory Data Analysis (EDA)

**Tasks**:
1. **Univariate Analysis**:
   - Analyze the distribution of each variable.
   - Examine measures of central tendency (mean, median, mode) and dispersion (variance, standard deviation).
   - Identify outliers and extreme values.
   - Assess the skewness and kurtosis of distributions.

2. **Bivariate and Multivariate Analysis**:
   - Explore relationships between pairs of features using scatter plots, correlation matrices, and pair plots.
   - Investigate the interaction between features and the target variable (`HasDetections`).
   - Perform cross-tabulations for categorical features and the target variable.
   - Use heatmaps to visualize correlations between multiple features.

3. **Time Series Exploration**:
   - Analyze time-related features to identify trends, seasonality, and cyclical patterns.
   - Use line plots and seasonal decomposition to visualize temporal changes.

4. **Visualization**:
   - Create various plots and charts (histograms, bar charts, box plots, scatter plots, heatmaps, etc.) to visualize data distributions, relationships, and patterns.
   - Use visualization libraries like Matplotlib and Seaborn to generate insightful graphics.

5. **Feature Importance**:
   - Use statistical tests and feature importance rankings to identify significant features.
   - Visualize the importance of different features in predicting the target variable.

**Outcome**: Generate a comprehensive understanding of the dataset, uncover hidden patterns, and gain insights that inform subsequent data cleaning and modeling steps.

### 02_data_cleaning.ipynb

**Purpose**: Data Cleaning

**Tasks**:
1. **Handle Missing Values**:
   - Apply imputation strategies identified during EDA to fill in missing values.
   - Use mean, median, mode, or more advanced methods like K-Nearest Neighbors (KNN) imputation as appropriate.

2. **Correct Noise and Errors**:
   - Identify and correct inconsistent, incorrect, or noisy data entries.
   - Standardize categorical values, fix typos, and ensure consistency in the data.

3. **Remove Duplicates**:
   - Identify and remove duplicate records, especially focusing on the `MachineIdentifier` which should be unique for each entry.
   - Ensure that removing duplicates does not result in the loss of significant information.

4. **Outlier Treatment**:
   - Detect and handle outliers using statistical methods (e.g., z-score, IQR) or domain knowledge.
   - Decide whether to remove outliers or transform them to minimize their impact.

5. **Feature Engineering Adjustments**:
   - Modify or create new features based on insights from EDA.
   - Normalize or scale features if necessary to prepare for modeling.

6. **Data Quality Checks**:
   - Perform final checks to ensure data quality, consistency, and readiness for further analysis.
   - Document all cleaning steps for reproducibility and transparency.




# Microsoft Malware Prediction Project

## Overview

This project aims to predict the likelihood of a machine being infected by malware, using data provided by Microsoft. The process involves data understanding, exploratory data analysis, data cleaning, feature engineering, modeling, and evaluation.

## Notebooks

### 00_initial_analysis.ipynb
**Purpose:** Initial Data Understanding

**Tasks:**
- Load and inspect the raw data.
- Generate summary statistics.
- Perform initial correlation analysis.
- Suggest imputation strategies for missing values.
- Handle missing values based on suggested strategies.
- Save the cleaned and preprocessed data for further analysis.

**Output:**
- Cleaned training data saved to `../data/processed/train_cleaned.csv`
- Cleaned test data saved to `../data/processed/test_cleaned.csv`

### 01_univariate_bivariate_analysis.ipynb
**Purpose:** Univariate and Bivariate Analysis

**Tasks:**
- Analyze the distribution of each variable (univariate analysis).
- Explore relationships between features and the target variable (bivariate analysis).
- Save visualizations and analysis results.

### 02_multivariate_time_series_analysis.ipynb
**Purpose:** Multivariate and Time Series Analysis

**Tasks:**
- Explore relationships involving multiple variables (multivariate analysis).
- Analyze time-related features for trends and seasonal effects (time series analysis).
- Assess feature importance using machine learning models.
- Save visualizations and analysis results.

### 03_scaling_up_analysis.ipynb
**Purpose:** Scaling Up Analysis to Full Dataset

**Tasks:**
- Apply refined data cleaning and analysis methods to the full dataset.
- Perform initial data analysis on the full dataset.
- Conduct univariate, bivariate, multivariate, and time series analyses on the full dataset.
- Evaluate feature importance on the full dataset.
- Save visualizations and analysis results.

7. **Save Cleaned Data**:
   - Save the cleaned dataset in a suitable format (e.g., CSV, Parquet) for subsequent analysis and modeling.

**Outcome**: Produce a high-quality, clean dataset that is free of inconsistencies, ready for detailed analysis and model development.



### Key Findings from Initial Analysis

#### Summary Statistics
- **Train Summary Statistics:**
  ![Train Summary Statistics](../reports/figures/train_summary_statistics.csv)
- **Test Summary Statistics:**
  ![Test Summary Statistics](../reports/figures/test_summary_statistics.csv)

#### Correlation Heatmap
- **Correlation Matrix for Training Data:**
  ![Train Correlation Heatmap](../reports/figures/train_correlation_heatmap.png)

#### Missing Values
- **Missing Values in Training Data:**
  ![Train Missing Values](../reports/figures/train_missing_values.csv)
- **Missing Values in Test Data:**
  ![Test Missing Values](../reports/figures/test_missing_values.csv)

#### Imputation Strategies
- **Imputation Strategies:**
  ![Imputation Strategies](../reports/figures/imputation_strategies.csv)

