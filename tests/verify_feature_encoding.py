# tests/verify_feature_encoding.py


import sys
import os
import pandas as pd
import yaml

# Ensure the working directory is the project root
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
os.chdir(project_root)

# Print the current working directory to verify
print(f"Current Working Directory: {os.getcwd()}")

# Ensure the project root and src directory are in sys.path
src_path = os.path.join(project_root, 'src')
if project_root not in sys.path:
    sys.path.append(project_root)
if src_path not in sys.path:
    sys.path.append(src_path)

# Import necessary functions
from config_loader import load_paths
from utils import load_yaml, save_yaml
from feature_engineering.encoding import encode_categorical_features_test

# Load paths
paths = load_paths()

# Load feature groups
feature_groups = load_yaml('config/feature_groups.yaml')

# Load cleaned data
train_cleaned = pd.read_csv(paths['data']['processed_train'])
test_cleaned = pd.read_csv(paths['data']['processed_test'])

# Drop MachineIdentifier as it should not be encoded
train_cleaned = train_cleaned.drop(columns=['MachineIdentifier'])
test_cleaned = test_cleaned.drop(columns=['MachineIdentifier'])

# Ensure 'HasDetections' is present in both datasets
test_cleaned['HasDetections'] = 0  # Adding a placeholder for the test dataset

# Check unique values for binary features
updated_binary_features = []
non_binary_features = []

for feature in feature_groups['binary_features']:
    unique_values = train_cleaned[feature].unique()
    if len(unique_values) > 2:
        non_binary_features.append(feature)
    else:
        updated_binary_features.append(feature)

# Update feature groups based on unique value check
feature_groups['binary_features'] = updated_binary_features
if 'categorical_features' not in feature_groups:
    feature_groups['categorical_features'] = []
feature_groups['categorical_features'].extend(non_binary_features)

# Save updated feature groups
save_yaml(feature_groups, 'config/feature_groups.yaml')

# Encode categorical variables
train_encoded, test_encoded, encoders = encode_categorical_features_test(train_cleaned, test_cleaned, feature_groups)

# Summary of encoded features
encoded_features_summary = []
for feature, encoder in encoders['label_encoders'].items():
    encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'Label Encoding'})
    
for feature, encoder in encoders['onehot_encoders'].items():
    encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'One-Hot Encoding'})
    
for feature, encoder in encoders['target_encoders'].items():
    encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'Target Encoding'})

encoded_features_df = pd.DataFrame(encoded_features_summary)

# Load feature metadata
feature_metadata = load_yaml('config/feature_metadata.yaml')

# Update feature metadata with encoding information
for feature, encoder in encoders['label_encoders'].items():
    updates = {
        'encoding_type': 'Label Encoding',
        'example_values': train_cleaned[feature].unique().tolist()[:5],
        'summary_statistics': train_cleaned[feature].describe().to_dict(),
        'data_type': 'integer'
    }
    feature_metadata = update_feature_metadata(feature_metadata, feature, updates)
    
for feature, encoder in encoders['onehot_encoders'].items():
    updates = {
        'encoding_type': 'One-Hot Encoding',
        'example_values': train_cleaned[feature].unique().tolist()[:5],
        'summary_statistics': train_cleaned[feature].describe().to_dict(),
        'data_type': 'binary'
    }
    feature_metadata = update_feature_metadata(feature_metadata, feature, updates)
    
for feature, encoder in encoders['target_encoders'].items():
    updates = {
        'encoding_type': 'Target Encoding',
        'example_values': train_cleaned[feature].unique().tolist()[:5],
        'summary_statistics': train_cleaned[feature].describe().to_dict(),
        'data_type': 'float'
    }
    feature_metadata = update_feature_metadata(feature_metadata, feature, updates)

# Save updated feature metadata
save_yaml(feature_metadata, 'config/feature_metadata.yaml')

print("Feature metadata updated and saved.")

# Compare with config/feature_groups.yaml
expected_categorical_features = set(feature_groups['categorical_features'])
expected_binary_features = set(feature_groups['binary_features'])

encoded_features = set(encoded_features_df['Feature'])

# Verify that all expected features are encoded
missing_categorical = expected_categorical_features - encoded_features
missing_binary = expected_binary_features - encoded_features

# Output results
print("Summary of Encoded Features:")
print(encoded_features_df)
print(f"Total Features Encoded: {len(encoded_features_df)}")

print("\nMissing Categorical Features:")
print(missing_categorical)

print("\nMissing Binary Features:")
print(missing_binary)

# Check the properties of missing binary features
for feature in missing_binary:
    print(f"\nAnalyzing Missing Binary Feature: {feature}")
    if feature in train_cleaned.columns:
        print(f"Data Type: {train_cleaned[feature].dtype}")
        print(f"Unique Values: {train_cleaned[feature].unique()}")
        print(f"Missing Values: {train_cleaned[feature].isnull().sum()}")

# Save results to a file for further analysis
with open('reports/encoding_verification_report.yaml', 'w') as file:
    yaml.safe_dump({
        'encoded_features': encoded_features_summary,
        'missing_categorical_features': list(missing_categorical),
        'missing_binary_features': list(missing_binary)
    }, file)

print("Verification report saved to 'reports/encoding_verification_report.yaml'")





# # tests/verify_feature_encoding.py

# import sys
# import os
# import pandas as pd
# import yaml

# # Ensure the working directory is the project root
# project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
# os.chdir(project_root)

# # Print the current working directory to verify
# print(f"Current Working Directory: {os.getcwd()}")

# # Ensure the project root and src directory are in sys.path
# src_path = os.path.join(project_root, 'src')
# if project_root not in sys.path:
#     sys.path.append(project_root)
# if src_path not in sys.path:
#     sys.path.append(src_path)

# # Import necessary functions
# from config_loader import load_paths
# from utils import load_yaml
# from feature_engineering.encoding import encode_categorical_features_test

# # Load paths
# paths = load_paths()

# # Load feature groups
# feature_groups = load_yaml('config/feature_groups.yaml')

# # Load cleaned data
# train_cleaned = pd.read_csv(paths['data']['processed_train'])
# test_cleaned = pd.read_csv(paths['data']['processed_test'])

# # Drop MachineIdentifier as it should not be encoded
# train_cleaned = train_cleaned.drop(columns=['MachineIdentifier'])
# test_cleaned = test_cleaned.drop(columns=['MachineIdentifier'])

# # Ensure 'HasDetections' is present in both datasets
# test_cleaned['HasDetections'] = 0  # Adding a placeholder for the test dataset

# # Encode categorical variables
# train_encoded, test_encoded, encoders = encode_categorical_features_test(train_cleaned, test_cleaned, feature_groups)

# # Summary of encoded features
# encoded_features_summary = []
# for feature, encoder in encoders['label_encoders'].items():
#     encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'Label Encoding'})
    
# for feature, encoder in encoders['onehot_encoders'].items():
#     encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'One-Hot Encoding'})
    
# for feature, encoder in encoders['target_encoders'].items():
#     encoded_features_summary.append({'Feature': feature, 'Encoding Type': 'Target Encoding'})

# encoded_features_df = pd.DataFrame(encoded_features_summary)

# # Load feature metadata
# feature_metadata = load_yaml('config/feature_metadata.yaml')

# # Compare with config/feature_groups.yaml
# expected_categorical_features = set(feature_groups['categorical_features'])
# expected_binary_features = set(feature_groups['binary_features'])

# encoded_features = set(encoded_features_df['Feature'])

# # Verify that all expected features are encoded
# missing_categorical = expected_categorical_features - encoded_features
# missing_binary = expected_binary_features - encoded_features

# # Output results
# print("Summary of Encoded Features:")
# print(encoded_features_df)
# print(f"Total Features Encoded: {len(encoded_features_df)}")

# print("\nMissing Categorical Features:")
# print(missing_categorical)

# print("\nMissing Binary Features:")
# print(missing_binary)

# # Check the properties of missing binary features
# for feature in missing_binary:
#     print(f"\nAnalyzing Missing Binary Feature: {feature}")
#     if feature in train_cleaned.columns:
#         print(f"Data Type: {train_cleaned[feature].dtype}")
#         print(f"Unique Values: {train_cleaned[feature].unique()}")
#         print(f"Missing Values: {train_cleaned[feature].isnull().sum()}")

# # Save results to a file for further analysis
# with open('reports/encoding_verification_report.yaml', 'w') as file:
#     yaml.safe_dump({
#         'encoded_features': encoded_features_summary,
#         'missing_categorical_features': list(missing_categorical),
#         'missing_binary_features': list(missing_binary)
#     }, file)

# print("Verification report saved to 'reports/encoding_verification_report.yaml'")





